{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FInal_xlnet_model_for_ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilDhull/emphasis_selection/blob/master/model/FInal_xlnet_model_for_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPnH9VOrfSCu",
        "colab_type": "code",
        "outputId": "6a6cb541-7923-4151-837e-f4036a943988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install config"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: config in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJeeb2ifU7X",
        "colab_type": "code",
        "outputId": "cd7d13dc-aa8b-4ec8-9e87-74f2fd10b3ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import XLNetConfig, XLNetLMHeadModel, XLNetModel, XLNetTokenizer\n",
        "from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import codecs\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQVuhZmdfXji",
        "colab_type": "code",
        "outputId": "a9d5b914-3f53-45a6-ca00-f3bdfd19d481",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9BBaiMfbcF",
        "colab_type": "code",
        "outputId": "0860c501-9b67-46c1-9737-4d0e9824c38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/datasets/train.txt'\n",
        "dev_file = 'drive/My Drive/datasets/dev.txt'\n",
        "test_file = 'drive/My Drive/datasets/test.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNIJVncgI4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased', do_lower_case = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyhUJlsjlKAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_token_map(file,word_index = 1,prob_index = 4, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  token_labels = []\n",
        "  sent_length = []\n",
        "\n",
        "  xlnet_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  labels = []\n",
        "\n",
        "  xlnet_tokens.append(\"<s>\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      label = feats[prob_index].lower() if caseless else feats[prob_index]\n",
        "      labels.append((float)(label))\n",
        "      orig_to_tok_map.append(len(xlnet_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        xlnet_tokens[-1] = xlnet_tokens[-1] +\"n\"\n",
        "\n",
        "      xlnet_tokens.extend(tokenizer.tokenize(word))\n",
        "     \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      xlnet_tokens.append(\"</s>\")\n",
        "      tokenized_texts.append(xlnet_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      token_labels.append(labels)\n",
        "      sent_length.append(len(labels))\n",
        "      xlnet_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      labels = []\n",
        "      length = 0\n",
        "      xlnet_tokens.append(\"<s>\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    xlnet_tokens.append(\"</s>\")\n",
        "    tokenized_texts.append(xlnet_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    token_labels.append(labels)\n",
        "    sent_length.append(len(labels))\n",
        "  \n",
        "  return tokenized_texts, token_map, token_labels, sent_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6CFT8tKJh9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_test_token_map(file,word_index = 1, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  sent_length = []\n",
        "\n",
        "  xlnet_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  \n",
        "  xlnet_tokens.append(\"<s>\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      orig_to_tok_map.append(len(xlnet_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        xlnet_tokens[-1] = xlnet_tokens[-1] +\"n\"\n",
        "\n",
        "      xlnet_tokens.extend(tokenizer.tokenize(word))\n",
        "     \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      xlnet_tokens.append(\"</s>\")\n",
        "      tokenized_texts.append(xlnet_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      sent_length.append(len(orig_to_tok_map))\n",
        "      xlnet_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      length = 0\n",
        "      xlnet_tokens.append(\"<s>\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    xlnet_tokens.append(\"</s>\")\n",
        "    tokenized_texts.append(xlnet_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    sent_length.append(len(orig_to_tok_map))\n",
        "  \n",
        "  return tokenized_texts, token_map, sent_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPE6ZIIl-Z_",
        "colab_type": "code",
        "outputId": "44736f9a-dc2f-4f02-f62c-69f42071647d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "t_tokenized_texts, t_token_map, t_token_label, t_sent_length = read_token_map(train_file)\n",
        "print(t_tokenized_texts[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])\n",
        "print(t_sent_length[100])\n",
        "\n",
        "d_tokenized_texts, d_token_map, d_token_label, d_sent_length = read_token_map(dev_file)\n",
        "print(d_tokenized_texts[0])\n",
        "print(d_token_map[0])\n",
        "print(d_token_label[0])\n",
        "print(d_sent_length[0])\n",
        "\n",
        "f_tokenized_texts, f_token_map, f_sent_length = read_test_token_map(test_file)\n",
        "print(f_tokenized_texts[50])\n",
        "print(f_token_map[50])\n",
        "print(f_sent_length[50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<s>', '▁Ha', 'ppi', 'ness', '▁consists', '▁in', '▁realizing', '▁it', '▁is', '▁all', '▁a', '▁great', '▁strange', '▁dream', '▁', '.', '</s>']\n",
            "[1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n",
            "12\n",
            "['<s>', '▁Life', '▁is', '▁defined', '▁more', '▁by', '▁its', '▁risks', '▁than', '▁by', '▁its', '▁same', 'ness', 'es', '▁', '.', '</s>']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14]\n",
            "[0.4444444444444444, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 1.0, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.7777777777777778, 0.1111111111111111]\n",
            "12\n",
            "['<s>', '▁In', '▁the', '▁practice', '▁of', '▁tolerance', '▁', ',', '▁one', '▁', \"'\", 's', '▁enemy', '▁is', '▁the', '▁best', '▁teacher', '▁', '.', '</s>']\n",
            "[1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 15, 16, 17]\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HExaYvEmDIS",
        "colab_type": "code",
        "outputId": "5c339a75-5b23-480f-c079-8836c3a966fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "MAX_LEN = 72\n",
        "\n",
        "# Use the xlnet tokenizer to convert the tokens to their index numbers in the xlnet vocabulary\n",
        "t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(t_input_ids[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    1  2541 18458   680  3765    25 15444    36    27    71    24   312\n",
            "  4572  2986    17     9     2     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  4  5  6  7  8  9 10 11 12 13 14  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n",
            " 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusk7aXcmHIH",
        "colab_type": "code",
        "outputId": "6ca4d84d-97cb-4fb3-a285-8cd944fdd19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(d_input_ids[0])\n",
        "print(d_token_map[0])\n",
        "print(d_token_label[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1 2782   27 3790   70   37   81 4398  100   37   81  219  680  202\n",
            "   17    9    2    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 14  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.44444444 0.11111111 0.22222222 0.11111111 0.11111111 0.11111111\n",
            " 1.         0.11111111 0.11111111 0.11111111 0.77777778 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgQGRhi3IEu5",
        "colab_type": "code",
        "outputId": "affea7c5-3d0c-482e-cda3-4feddcd62147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "f_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in f_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "f_input_ids = pad_sequences(f_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "f_token_map = pad_sequences(f_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(f_input_ids[50])\n",
        "print(f_token_map[50])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    1    67    18  1211    20 12316    17    19    65    17    26    23\n",
            "  3854    27    18   252  2804    17     9     2     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  8  9 12 13 14 15 16 17  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCgv6Er9mKTn",
        "colab_type": "code",
        "outputId": "e819a067-10c9-40c0-cd0b-cf2ed5b46f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "t_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in t_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  t_attention_masks.append(seq_mask)\n",
        "print(t_attention_masks[100])\n",
        "\n",
        "d_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in d_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  d_attention_masks.append(seq_mask)\n",
        "print(d_attention_masks[0])\n",
        "\n",
        "f_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in f_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  f_attention_masks.append(seq_mask)\n",
        "print(f_attention_masks[50])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzs4KzUCmNGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_input_ids = torch.tensor(t_input_ids)\n",
        "t_token_map = torch.tensor(t_token_map )\n",
        "t_token_label = torch.tensor(t_token_label)\n",
        "t_attention_masks = torch.tensor(t_attention_masks)\n",
        "t_sent_length = torch.tensor(t_sent_length)\n",
        "\n",
        "d_input_ids = torch.tensor(d_input_ids)\n",
        "d_token_map = torch.tensor(d_token_map )\n",
        "d_token_label = torch.tensor(d_token_label)\n",
        "d_attention_masks = torch.tensor(d_attention_masks)\n",
        "d_sent_length = torch.tensor(d_sent_length)\n",
        "\n",
        "f_input_ids = torch.tensor(f_input_ids)\n",
        "f_token_map = torch.tensor(f_token_map )\n",
        "f_attention_masks = torch.tensor(f_attention_masks)\n",
        "f_sent_length = torch.tensor(f_sent_length)\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "# print(t_token_labels)\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks, t_sent_length)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks, d_sent_length)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size, shuffle = False)\n",
        "test_data = TensorDataset(f_input_ids, f_token_map, f_attention_masks, f_sent_length)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size,shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T64VOgLFK0AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_for_output(file,word_index = 1):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  words_lsts = []\n",
        "  word_ids_lsts = []\n",
        "  words = []\n",
        "  ids = []\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      words.append(feats[word_index])\n",
        "      ids.append(feats[0])\n",
        "     \n",
        "    elif len(words) > 0:\n",
        "      words_lsts.append(words)\n",
        "      word_ids_lsts.append(ids)\n",
        "      words = []\n",
        "      ids = []\n",
        "          \n",
        "  if len(words) > 0:\n",
        "    words_lsts.append(words)\n",
        "    word_ids_lsts.append(ids)\n",
        "    words = []\n",
        "    ids = []\n",
        "  \n",
        "  return words_lsts , word_ids_lsts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhtYp8UKM6-p",
        "colab_type": "code",
        "outputId": "fe4a9754-ef31-41c2-f6e2-74b5e6711673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "dev_words, dev_word_ids = read_for_output(dev_file)\n",
        "test_words, test_word_ids = read_for_output(test_file)\n",
        "\n",
        "print(dev_words[0])\n",
        "print(dev_word_ids[0])\n",
        "print(test_words[50])\n",
        "print(test_word_ids[50])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Life', 'is', 'defined', 'more', 'by', 'its', 'risks', 'than', 'by', 'its', 'samenesses', '.']\n",
            "['Q_0_0', 'Q_0_1', 'Q_0_2', 'Q_0_3', 'Q_0_4', 'Q_0_5', 'Q_0_6', 'Q_0_7', 'Q_0_8', 'Q_0_9', 'Q_0_10', 'Q_0_11']\n",
            "['In', 'the', 'practice', 'of', 'tolerance', ',', 'one', \"'s\", 'enemy', 'is', 'the', 'best', 'teacher', '.']\n",
            "['Q_50_0', 'Q_50_1', 'Q_50_2', 'Q_50_3', 'Q_50_4', 'Q_50_5', 'Q_50_6', 'Q_50_7', 'Q_50_8', 'Q_50_9', 'Q_50_10', 'Q_50_11', 'Q_50_12', 'Q_50_13']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz4BGjpUsDSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3\n",
        "\n",
        "def fix_padding(scores_numpy, label_probs,  mask_numpy):\n",
        "    #if len(scores_numpy) != len(mask_numpy):\n",
        "    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n",
        "    #assert len(scores_numpy) == len(mask_numpy)\n",
        "    #if len(label_probs) != len(mask_numpy):\n",
        "    #    print(\"len(label_probs) != len(mask_numpy)\")\n",
        "    #assert len(label_probs) == len(mask_numpy)\n",
        "\n",
        "    all_scores_no_padd = []\n",
        "    all_labels_no_pad = []\n",
        "    for i in range(len(mask_numpy)):\n",
        "        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n",
        "        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n",
        "\n",
        "    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n",
        "    return all_scores_no_padd, all_labels_no_pad\n",
        "\n",
        "def match_M(batch_scores_no_padd, batch_labels_no_pad):\n",
        "\n",
        "    top_m = [1, 2, 3, 4]\n",
        "    batch_num_m=[]\n",
        "    batch_score_m=[]\n",
        "    for m in top_m:\n",
        "        intersects_lst = []\n",
        "        # exact_lst = []\n",
        "        score_lst = []\n",
        "        ############################################### computing scores:\n",
        "        for s in batch_scores_no_padd:\n",
        "            if len(s) <=m:\n",
        "                continue\n",
        "            h = m\n",
        "            # if len(s) > h:\n",
        "            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n",
        "            #         h += 1\n",
        "\n",
        "            # s = np.asarray(s.cpu())\n",
        "            s = np.asarray(s)\n",
        "            #ind_score = np.argsort(s)[-h:]\n",
        "            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n",
        "            score_lst.append(ind_score)\n",
        "\n",
        "        ############################################### computing labels:\n",
        "        label_lst = []\n",
        "        for l in batch_labels_no_pad:\n",
        "            if len(l) <=m:\n",
        "                continue\n",
        "            # if it contains several top values with the same amount\n",
        "            h = m\n",
        "            # l = l.cpu()\n",
        "            if len(l) > h:\n",
        "                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n",
        "                    h += 1\n",
        "            l = np.asarray(l)\n",
        "            ind_label = np.argsort(l)[-h:]\n",
        "            label_lst.append(ind_label)\n",
        "\n",
        "        ############################################### :\n",
        "\n",
        "        for i in range(len(score_lst)):\n",
        "            intersect = intersection(score_lst[i], label_lst[i])\n",
        "            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n",
        "            # sorted_score_lst = sorted(score_lst[i])\n",
        "            # sorted_label_lst =  sorted(label_lst[i])\n",
        "            # if sorted_score_lst==sorted_label_lst:\n",
        "            #     exact_lst.append(1)\n",
        "            # else:\n",
        "            #     exact_lst.append(0)\n",
        "        batch_num_m.append(len(score_lst))\n",
        "        batch_score_m.append(sum(intersects_lst))\n",
        "    return batch_num_m, batch_score_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X8RL3dgOKAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model):\n",
        "  print(\"\")\n",
        "  print(\"Running test...\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  iii = 0\n",
        "\n",
        "  s = \"\"\n",
        "  sentence_id = \"\"\n",
        "\n",
        "  for batch in test_dataloader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      v_input_ids = batch[0].to(device)\n",
        "      v_input_mask = batch[2].to(device)\n",
        "      v_token_starts = batch[1].to(device)\n",
        "      v_sent_length = batch[3]\n",
        "            \n",
        "      # Telling the model not to compute or store gradients, saving memory and\n",
        "      # speeding up validation\n",
        "      with torch.no_grad():        \n",
        "          output = model(v_input_ids, v_input_mask, v_token_starts, v_sent_length)\n",
        "      \n",
        "      pred_labels = output[1]\n",
        "\n",
        "      pred_labels = pred_labels.detach().cpu().numpy()\n",
        "\n",
        "      for i in range(v_input_ids.size()[0]):\n",
        "        for j in range(len(test_words[iii])):\n",
        "          if sentence_id == iii:\n",
        "            s = s + \"{}\\t{}\\t{}\\t\".format(test_word_ids[iii][j], test_words[iii][j], pred_labels[i][j]) + \"\\n\"\n",
        "          else:\n",
        "            s = s + \"\\n\" + \"{}\\t{}\\t{}\\t\".format(test_word_ids[iii][j], test_words[iii][j], pred_labels[i][j]) + \"\\n\"\n",
        "            sentence_id = iii\n",
        "        iii = iii + 1\n",
        "      s = s +\"\\n\"\n",
        "      \n",
        "  print(\"testing complete\\n\")\n",
        "  # print(s)\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB21vKHz4BRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_all(x):\n",
        "  print(\"\\nSaving...\\n\")\n",
        "  save_path = 'drive/My Drive/datasets/ensemble/xlnet/xlnet_900_40/'\n",
        "  os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "  val_path = 'val'+str(x)+'.txt'\n",
        "  test_path = 'test'+str(x)+'.txt'\n",
        "  max_path = 'max'+str(x)+'.txt'\n",
        "\n",
        "  with open(save_path + val_path, \"w\") as text_file:\n",
        "    text_file.write(val_out)\n",
        "\n",
        "  with open(save_path + test_path, \"w\") as text_file:\n",
        "    text_file.write(test_out)\n",
        "\n",
        "  with open(save_path + max_path, \"w\") as text_file:\n",
        "    text_file.write(str(max_accuracy)+\"\\n\"+str(max_match))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waw_HPZ3sJza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model):\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  num_m = [0, 0, 0, 0]\n",
        "  score_m = [0, 0, 0, 0]\n",
        "\n",
        "  iii = 0\n",
        "\n",
        "  s = \"\"\n",
        "  sentence_id = \"\"\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      v_input_ids = batch[0].to(device)\n",
        "      v_input_mask = batch[3].to(device)\n",
        "      v_token_starts = batch[1].to(device)\n",
        "      v_labels = batch[2].to(device)\n",
        "      v_sent_length = batch[4]\n",
        "            \n",
        "      # Telling the model not to compute or store gradients, saving memory and\n",
        "      # speeding up validation\n",
        "      with torch.no_grad():        \n",
        "          output = model(v_input_ids, v_input_mask, v_token_starts, v_sent_length, v_labels)\n",
        "      \n",
        "      pred_labels = output[1]\n",
        "\n",
        "      pred_labels = pred_labels.detach().cpu().numpy()\n",
        "      v_labels = v_labels.to('cpu').numpy()\n",
        "\n",
        "      for i in range(v_input_ids.size()[0]):\n",
        "        for j in range(len(dev_words[iii])):\n",
        "          if sentence_id == iii:\n",
        "            s = s + \"{}\\t{}\\t{}\\t{}\".format(dev_word_ids[iii][j], dev_words[iii][j], pred_labels[i][j],v_labels[i][j]) + \"\\n\"\n",
        "          else:\n",
        "            s = s + \"\\n\" + \"{}\\t{}\\t{}\\t{}\".format(dev_word_ids[iii][j], dev_words[iii][j], pred_labels[i][j],v_labels[i][j]) + \"\\n\"\n",
        "            sentence_id = iii\n",
        "        iii = iii + 1\n",
        "      s = s +\"\\n\"\n",
        "      \n",
        "      pred_labels, v_labels = fix_padding(pred_labels, v_labels, v_sent_length)\n",
        "\n",
        "      batch_num_m, batch_score_m = match_M(pred_labels, v_labels)\n",
        "      num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n",
        "      score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n",
        "  \n",
        "  m_score = [i/j for i,j in zip(score_m, num_m)]\n",
        "  \n",
        "  print(\"Validation Accuracy: \")\n",
        "  print(m_score)\n",
        "  v_score = np.mean(m_score)\n",
        "  print(v_score)\n",
        "  print()\n",
        "  # print(s)\n",
        "\n",
        "  return v_score,m_score,s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLkMdFoNsRMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_accuracy = 0\n",
        "max_match = [0,0,0,0]\n",
        "val_out = \"\"\n",
        "test_out = \"\"\n",
        "ind = 10\n",
        "\n",
        "def train(model,  optimizer, scheduler, tokenizer, max_epochs, save_path, device, val_freq = 10):\n",
        "  \n",
        "  bestpoint_dir = os.path.join(save_path)\n",
        "  os.makedirs(bestpoint_dir, exist_ok=True)\n",
        "\n",
        "  global max_accuracy \n",
        "  global max_match \n",
        "  global val_out \n",
        "  global test_out \n",
        "  \n",
        "  for epoch_i in range(0, max_epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, max_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):    \n",
        "\n",
        "        print(\"batch\",step,\"out of\",len(train_dataloader))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[3].to(device)\n",
        "        b_token_starts = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_sent_length = batch[4]\n",
        "\n",
        "        model.zero_grad()   \n",
        "        model.train()     \n",
        "\n",
        "        output = model(b_input_ids, b_input_mask, b_token_starts,b_sent_length,b_labels)\n",
        "        loss = output[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "          accuracy, match_m, outs = validation(model)\n",
        "          if(accuracy > max_accuracy):\n",
        "            max_accuracy = accuracy\n",
        "            max_match = match_m\n",
        "            val_out = outs\n",
        "            test_out = test(model)\n",
        "            save_all(ind)\n",
        "\n",
        "            # model.save_pretrained(bestpoint_dir)  \n",
        "            # print(\"Saving model bestpoint to \", bestpoint_dir)\n",
        "          print(\"Best accuracy = \"+str(max_accuracy))\n",
        "          print(\"\")\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  \n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZIU8zV-mQt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class transformer_model(nn.Module):\n",
        "  def __init__(self, model_name, drop_prob = 0.3):\n",
        "    super(transformer_model, self).__init__()\n",
        "\n",
        "    config = XLNetConfig.from_pretrained('xlnet-large-cased', output_hidden_states=True)\n",
        "    self.xlnet = XLNetModel.from_pretrained('xlnet-large-cased', config = config)\n",
        "    \n",
        "    # the commented lines freezes layers of the model\n",
        "    # cnt=0\n",
        "    # for child in xlnet.xlnet.children():\n",
        "    #   cnt = cnt + 1\n",
        "    #   if cnt<=23:\n",
        "    #     for param in child.parameters():\n",
        "    #       param.requires_grad = False\n",
        "\n",
        "    xlnet_dim = 25*1024\n",
        "    hidden_dim1 = 1000\n",
        "    hidden_dim2 = 40\n",
        "    final_size = 1\n",
        "\n",
        "    self.fc1 = nn.Linear(xlnet_dim, hidden_dim1)\n",
        "    self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "    self.fc3 = nn.Linear(hidden_dim2, final_size)\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def avg(self, a, st, end):\n",
        "    k = a\n",
        "    lis = []\n",
        "    for i in range(st,end):\n",
        "      lis.append(a[i])\n",
        "    x = torch.mean(torch.stack(lis),dim=0)\n",
        "    return x\n",
        "        \n",
        "  def forward(self, xlnet_ids, xlnet_mask, xlnet_token_starts, lm_lengths = None, labels = None):\n",
        "    \n",
        "    batch_size = xlnet_ids.size()[0]\n",
        "    pad_size = xlnet_ids.size()[1]\n",
        "    # print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n",
        "\n",
        "    output = self.xlnet(xlnet_ids, attention_mask = xlnet_mask)\n",
        "\n",
        "    xlnet_out = output[-1][0]\n",
        "    for layers in range(1,25,1):\n",
        "      xlnet_out = torch.cat((xlnet_out, output[-1][layers]), dim=2)\n",
        "    \n",
        "    pred_logits = torch.relu(self.fc1(self.dropout(xlnet_out)))\n",
        "    pred_logits = torch.relu(self.fc2(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.sigmoid(self.fc3(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.squeeze(pred_logits,2)\n",
        "\n",
        "    pred_labels = torch.tensor(np.zeros(xlnet_token_starts.size()),dtype = torch.float64).to(device)\n",
        "\n",
        "    # print(pred_logits[0])\n",
        "    # print(pred_labels[0])\n",
        "    # print(labels[0])\n",
        "    # print(xlnet_token_starts[0])\n",
        "\n",
        "    for b in range(batch_size):\n",
        "      for w in range(pad_size):\n",
        "        if(xlnet_token_starts[b][w]!=0):\n",
        "          if(xlnet_token_starts[b][w]>=pad_size):\n",
        "            print(xlnet_token_starts[b])\n",
        "          else:\n",
        "            st = xlnet_token_starts[b][w]\n",
        "            end = xlnet_token_starts[b][w+1]\n",
        "            if(end==0):\n",
        "              end = st+1\n",
        "              while(xlnet_mask[b][end]!=0):\n",
        "                end = end+1\n",
        "            # pred_labels[b][w] = self.avg(pred_logits[b],st,end)\n",
        "            pred_labels[b][w] = pred_logits[b][xlnet_token_starts[b][w]]\n",
        "\n",
        "    # print(pred_labels[0])\n",
        "\n",
        "    if(labels != None):\n",
        "      lm_lengths, lm_sort_ind = lm_lengths.sort(dim=0, descending=True)\n",
        "      scores = labels[lm_sort_ind]\n",
        "      targets = pred_labels[lm_sort_ind]\n",
        "      scores = pack_padded_sequence(scores, lm_lengths, batch_first=True).data\n",
        "      targets = pack_padded_sequence(targets, lm_lengths, batch_first=True).data\n",
        "\n",
        "      # print(targets,scores)\n",
        "\n",
        "      loss_fn = nn.BCELoss().to(device) \n",
        "      loss = loss_fn(targets,scores)\n",
        "\n",
        "      return loss, pred_labels \n",
        "\n",
        "    else:\n",
        "      return 0.0, pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyCLOk5srSvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = transformer_model('xlnet-large-cased').to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Ob6wRjr3rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 20\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB-7PRyzsZiU",
        "colab_type": "code",
        "outputId": "01a63316-ccb4-4e97-f4a6-ab8f479259a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "save_path = 'drive/My Drive/datasets/results/xlnet_large/'\n",
        "train(model,  optimizer, scheduler, tokenizer, epochs, save_path, device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.461734693877551, 0.6657824933687002, 0.7490530303030305, 0.7878787878787878]\n",
            "0.6661122513570175\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.6661122513570175\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.49744897959183676, 0.7042440318302388, 0.7698863636363638, 0.8053030303030303]\n",
            "0.6942206013403673\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.6942206013403673\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5331632653061225, 0.7161803713527851, 0.78125, 0.8181818181818182]\n",
            "0.7121938637101815\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7121938637101815\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5841836734693877, 0.7400530503978779, 0.8077651515151516, 0.8318181818181818]\n",
            "0.7409550143001498\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7409550143001498\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5918367346938775, 0.7493368700265252, 0.8068181818181818, 0.8424242424242424]\n",
            "0.7476040072407066\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7476040072407066\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5994897959183674, 0.7453580901856764, 0.8077651515151516, 0.8424242424242424]\n",
            "0.7487593200108594\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7487593200108594\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6326530612244898, 0.7559681697612732, 0.8153409090909091, 0.8386363636363636]\n",
            "0.7606496259282589\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7606496259282589\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6428571428571429, 0.7572944297082228, 0.8172348484848485, 0.8409090909090909]\n",
            "0.7645738779898262\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7645738779898262\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.7599469496021221, 0.8153409090909091, 0.8462121212121212]\n",
            "0.768640301098737\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.768640301098737\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "======== Epoch 2 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7599469496021221, 0.8153409090909091, 0.8507575757575757]\n",
            "0.7704144198371415\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7704144198371415\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.7705570291777188, 0.8276515151515152, 0.8431818181818181]\n",
            "0.7780771824644978\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7780771824644978\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7838196286472149, 0.831439393939394, 0.8590909090909091]\n",
            "0.7844038094499917\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6479591836734694, 0.786472148541114, 0.8371212121212122, 0.8606060606060606]\n",
            "0.783039651235464\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7745358090185677, 0.838068181818182, 0.8568181818181818]\n",
            "0.7831718696943452\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.7785145888594165, 0.8352272727272729, 0.8560606060606061]\n",
            "0.7807159230342728\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7904509283819628, 0.8371212121212122, 0.8560606060606061]\n",
            "0.7835357376613533\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7851458885941645, 0.8352272727272726, 0.853030303030303]\n",
            "0.7822539273124248\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.786472148541114, 0.8342803030303031, 0.8515151515151516]\n",
            "0.7813322068940911\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.49\n",
            "\n",
            "======== Epoch 3 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6683673469387755, 0.7838196286472149, 0.831439393939394, 0.8537878787878788]\n",
            "0.7843535620783157\n",
            "\n",
            "Best accuracy = 0.7844038094499917\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6658163265306123, 0.7824933687002652, 0.8399621212121212, 0.8568181818181818]\n",
            "0.7862724995652951\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7862724995652951\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.7705570291777188, 0.8323863636363638, 0.8590909090909091]\n",
            "0.7832381673129827\n",
            "\n",
            "Best accuracy = 0.7862724995652951\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.673469387755102, 0.7705570291777188, 0.8285984848484849, 0.8553030303030303]\n",
            "0.781981983021084\n",
            "\n",
            "Best accuracy = 0.7862724995652951\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6785714285714286, 0.7758620689655172, 0.8352272727272727, 0.8590909090909091]\n",
            "0.7871879198387819\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7871879198387819\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6607142857142857, 0.7877984084880637, 0.8390151515151516, 0.8621212121212121]\n",
            "0.7874122644596784\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7874122644596784\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6683673469387755, 0.7904509283819628, 0.8371212121212122, 0.8545454545454545]\n",
            "0.7876212354968513\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7876212354968513\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6785714285714286, 0.7931034482758621, 0.8333333333333335, 0.8598484848484849]\n",
            "0.7912141737572772\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7912141737572772\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6836734693877551, 0.7997347480106101, 0.8428030303030304, 0.8621212121212121]\n",
            "0.7970831149556519\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.7970831149556519\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.48\n",
            "\n",
            "======== Epoch 4 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.7944297082228117, 0.8437500000000001, 0.8613636363636363]\n",
            "0.7926154279833467\n",
            "\n",
            "Best accuracy = 0.7970831149556519\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6913265306122449, 0.7904509283819628, 0.8390151515151516, 0.8598484848484849]\n",
            "0.7951602738394611\n",
            "\n",
            "Best accuracy = 0.7970831149556519\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7944297082228117, 0.8418560606060607, 0.8621212121212121]\n",
            "0.8025354187069089\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6836734693877551, 0.7970822281167109, 0.8352272727272727, 0.8598484848484849]\n",
            "0.7939578637700558\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6811224489795918, 0.7891246684350133, 0.8446969696969698, 0.8628787878787879]\n",
            "0.7944557187475907\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6887755102040817, 0.7997347480106101, 0.8456439393939394, 0.8606060606060606]\n",
            "0.798690064553673\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6938775510204082, 0.7944297082228117, 0.8437500000000001, 0.8636363636363636]\n",
            "0.798923405719896\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7944297082228117, 0.838068181818182, 0.8621212121212121]\n",
            "0.8015884490099392\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7904509283819628, 0.8418560606060607, 0.8621212121212121]\n",
            "0.8021784788487374\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "======== Epoch 5 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7984084880636605, 0.8428030303030304, 0.8583333333333333]\n",
            "0.8009066210882714\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6989795918367347, 0.7917771883289124, 0.840909090909091, 0.8621212121212121]\n",
            "0.7984467707989875\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7891246684350133, 0.8409090909090909, 0.8613636363636363]\n",
            "0.800145267294282\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6887755102040817, 0.7877984084880637, 0.8361742424242423, 0.8643939393939394]\n",
            "0.7942855251275818\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6938775510204082, 0.7944297082228117, 0.8371212121212122, 0.8613636363636363]\n",
            "0.7966980269320171\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6989795918367347, 0.7997347480106101, 0.8409090909090909, 0.8583333333333333]\n",
            "0.7994891910224423\n",
            "\n",
            "Best accuracy = 0.8025354187069089\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7997347480106101, 0.8409090909090909, 0.8621212121212121]\n",
            "0.803624936229616\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.8010610079575596, 0.8390151515151515, 0.8590909090909091]\n",
            "0.8001744202021295\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7984084880636605, 0.8371212121212122, 0.8598484848484849]\n",
            "0.7998649544216047\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.47\n",
            "\n",
            "======== Epoch 6 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6989795918367347, 0.7957559681697612, 0.8361742424242423, 0.8613636363636363]\n",
            "0.7980683596985937\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7984084880636605, 0.8390151515151516, 0.8583333333333333]\n",
            "0.7993218962892609\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7904509283819628, 0.8342803030303031, 0.8575757575757575]\n",
            "0.7965971554102712\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7798408488063661, 0.8333333333333335, 0.8613636363636363]\n",
            "0.7940171076870585\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6989795918367347, 0.7904509283819628, 0.8361742424242425, 0.8560606060606061]\n",
            "0.7954163421758865\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.786472148541114, 0.8361742424242425, 0.8598484848484849]\n",
            "0.7960063720146848\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6913265306122449, 0.786472148541114, 0.8371212121212122, 0.8643939393939394]\n",
            "0.7948284576671276\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6862244897959183, 0.7957559681697612, 0.8428030303030304, 0.8681818181818182]\n",
            "0.798241326612632\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.8023872679045093, 0.8418560606060607, 0.8666666666666667]\n",
            "0.7954570906310439\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.46\n",
            "\n",
            "======== Epoch 7 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6887755102040817, 0.8037135278514589, 0.84375, 0.8674242424242424]\n",
            "0.8009158201199458\n",
            "\n",
            "Best accuracy = 0.803624936229616\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.8076923076923077, 0.8437500000000001, 0.8621212121212121]\n",
            "0.8037735330146045\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6938775510204082, 0.7997347480106101, 0.840909090909091, 0.8583333333333333]\n",
            "0.7982136808183606\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6913265306122449, 0.7997347480106101, 0.8446969696969698, 0.8583333333333333]\n",
            "0.7985228954132896\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.8023872679045093, 0.8380681818181818, 0.8598484848484849]\n",
            "0.8017341469081001\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.8010610079575596, 0.8390151515151516, 0.8598484848484849]\n",
            "0.8016393243456051\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6887755102040817, 0.8037135278514589, 0.84375, 0.8643939393939394]\n",
            "0.8001582443623699\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7944297082228117, 0.8399621212121212, 0.8651515151515151]\n",
            "0.8028195096159998\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7957559681697612, 0.8352272727272729, 0.8643939393939394]\n",
            "0.8024157236441719\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "======== Epoch 8 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7997347480106101, 0.8390151515151516, 0.8621212121212121]\n",
            "0.800600430972968\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7984084880636605, 0.8399621212121212, 0.8621212121212121]\n",
            "0.8030566288186363\n",
            "\n",
            "Best accuracy = 0.8037735330146045\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7997347480106101, 0.8428030303030305, 0.8628787878787879]\n",
            "0.8049255701195356\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.8050397877984085, 0.8428030303030302, 0.8628787878787879]\n",
            "0.8037008096583219\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7997347480106101, 0.838068181818182, 0.8636363636363636]\n",
            "0.8026557417336359\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7957559681697612, 0.8418560606060607, 0.8628787878787879]\n",
            "0.8017808674289585\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6989795918367347, 0.7970822281167109, 0.8399621212121214, 0.8666666666666667]\n",
            "0.8006726519580585\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7931034482758621, 0.8418560606060607, 0.8681818181818182]\n",
            "0.8030812501332821\n",
            "\n",
            "Best accuracy = 0.8049255701195356\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7997347480106101, 0.8428030303030304, 0.8643939393939394]\n",
            "0.8053043579983235\n",
            "\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "\n",
            "\n",
            "Saving...\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "======== Epoch 9 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.8010610079575596, 0.8399621212121214, 0.8628787878787879]\n",
            "0.8032713976294642\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7970822281167109, 0.8399621212121212, 0.8598484848484849]\n",
            "0.8002436167075946\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7997347480106101, 0.8418560606060607, 0.8613636363636363]\n",
            "0.801759019408342\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.8050397877984085, 0.8465909090909091, 0.8590909090909091]\n",
            "0.8030630545562811\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7970822281167109, 0.8446969696969698, 0.8636363636363636]\n",
            "0.8030120536278172\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6964285714285714, 0.7904509283819628, 0.8399621212121211, 0.8621212121212121]\n",
            "0.7972407082859669\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6913265306122449, 0.7944297082228117, 0.8437500000000001, 0.865909090909091]\n",
            "0.7988538324360368\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6964285714285714, 0.7944297082228117, 0.8418560606060606, 0.8674242424242424]\n",
            "0.8000346456704215\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7917771883289124, 0.8371212121212122, 0.8689393939393939]\n",
            "0.7998421016586041\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.45\n",
            "\n",
            "======== Epoch 10 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6913265306122449, 0.7917771883289124, 0.8380681818181818, 0.8689393939393939]\n",
            "0.7975278236746832\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6938775510204082, 0.7917771883289124, 0.8342803030303031, 0.8598484848484849]\n",
            "0.7949458818070272\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7904509283819628, 0.8333333333333333, 0.8621212121212121]\n",
            "0.7981345317244333\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7957559681697612, 0.8361742424242423, 0.8606060606060606]\n",
            "0.799792231065322\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7931034482758621, 0.8342803030303031, 0.8575757575757575]\n",
            "0.7985357955878276\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7877984084880637, 0.8380681818181818, 0.8553030303030303]\n",
            "0.7969505684176251\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7931034482758621, 0.8418560606060606, 0.8560606060606061]\n",
            "0.7987754368988974\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7904509283819628, 0.84375, 0.8575757575757575]\n",
            "0.7996023347547362\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7917771883289124, 0.840909090909091, 0.8583333333333333]\n",
            "0.7987753113060996\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 11 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7904509283819628, 0.8371212121212124, 0.8575757575757575]\n",
            "0.7966696275809577\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7811671087533156, 0.8342803030303032, 0.8560606060606061]\n",
            "0.7932596575222807\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.786472148541114, 0.8352272727272727, 0.8590909090909091]\n",
            "0.7968557458551302\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7168367346938775, 0.7904509283819628, 0.8352272727272729, 0.8590909090909091]\n",
            "0.8004014612235055\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7904509283819628, 0.8352272727272729, 0.8575757575757575]\n",
            "0.7993849182426769\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7168367346938775, 0.7891246684350133, 0.8371212121212124, 0.8606060606060606]\n",
            "0.8009221689640409\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7904509283819628, 0.8371212121212124, 0.8628787878787879]\n",
            "0.8005464055648785\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7193877551020408, 0.7877984084880637, 0.8409090909090909, 0.8575757575757575]\n",
            "0.8014177530187382\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7944297082228117, 0.8342803030303031, 0.8598484848484849]\n",
            "0.7994355423927468\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 12 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7917771883289124, 0.8361742424242425, 0.8583333333333333]\n",
            "0.7995048644910099\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.786472148541114, 0.838068181818182, 0.8568181818181818]\n",
            "0.7982733015137573\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7193877551020408, 0.7891246684350133, 0.8380681818181818, 0.8598484848484849]\n",
            "0.8016072725509301\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7891246684350133, 0.8333333333333335, 0.8583333333333333]\n",
            "0.7962182419386854\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7891246684350133, 0.838068181818182, 0.8598484848484849]\n",
            "0.7996940072448078\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.786472148541114, 0.8361742424242423, 0.8560606060606061]\n",
            "0.7969726676238374\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.701530612244898, 0.7970822281167109, 0.840909090909091, 0.8575757575757575]\n",
            "0.7992744222116144\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7917771883289124, 0.8409090909090909, 0.8575757575757575]\n",
            "0.7985859173667055\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7891246684350133, 0.8399621212121211, 0.8545454545454545]\n",
            "0.7969284692114125\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 13 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7904509283819628, 0.8380681818181818, 0.8568181818181818]\n",
            "0.7979924862698877\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7904509283819628, 0.8418560606060606, 0.8575757575757575]\n",
            "0.7991288499062513\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7944297082228117, 0.8390151515151516, 0.8568181818181818]\n",
            "0.7985861685523016\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7917771883289124, 0.8361742424242425, 0.8606060606060606]\n",
            "0.8000730463091916\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7168367346938775, 0.7891246684350133, 0.8352272727272727, 0.8575757575757575]\n",
            "0.7996911083579803\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7168367346938775, 0.7851458885941645, 0.8314393939393941, 0.8575757575757575]\n",
            "0.7977494437007984\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7838196286472149, 0.8390151515151516, 0.8553030303030303]\n",
            "0.7961926158816554\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7877984084880637, 0.8361742424242423, 0.8606060606060606]\n",
            "0.797165086042857\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.786472148541114, 0.8295454545454546, 0.8545454545454545]\n",
            "0.7955744378773936\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 14 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7040816326530612, 0.7904509283819628, 0.8295454545454547, 0.853030303030303]\n",
            "0.7942770796526955\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7904509283819628, 0.8352272727272727, 0.8560606060606061]\n",
            "0.7977306201598072\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7944297082228117, 0.8342803030303031, 0.8553030303030303]\n",
            "0.7982991787563832\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7066326530612245, 0.7944297082228117, 0.8333333333333336, 0.8575757575757575]\n",
            "0.7979928630482818\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7904509283819628, 0.8342803030303031, 0.8560606060606061]\n",
            "0.7974938777355649\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7931034482758621, 0.8361742424242425, 0.8590909090909091]\n",
            "0.7993880683151005\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7891246684350133, 0.8390151515151515, 0.8575757575757575]\n",
            "0.7987248127488275\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7891246684350133, 0.8352272727272729, 0.8568181818181818]\n",
            "0.7982262042145049\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7891246684350133, 0.8342803030303031, 0.8568181818181818]\n",
            "0.7986272168923032\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 15 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7891246684350133, 0.8333333333333335, 0.8560606060606061]\n",
            "0.7982010805286668\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7904509283819628, 0.8295454545454546, 0.8545454545454545]\n",
            "0.7972068879396466\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7193877551020408, 0.7904509283819628, 0.8285984848484849, 0.853030303030303]\n",
            "0.7978668678406978\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7168367346938775, 0.7931034482758621, 0.8276515151515152, 0.8537878787878788]\n",
            "0.7978448942272833\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7917771883289124, 0.8295454545454547, 0.853030303030303]\n",
            "0.797159665047596\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7877984084880637, 0.8304924242424243, 0.853030303030303]\n",
            "0.7964017125116264\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7877984084880637, 0.831439393939394, 0.853030303030303]\n",
            "0.7966384549358688\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7851458885941645, 0.8323863636363636, 0.8545454545454545]\n",
            "0.7953153450613426\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7877984084880637, 0.8323863636363638, 0.8583333333333333]\n",
            "0.7969254447317872\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.44\n",
            "\n",
            "======== Epoch 16 / 20 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.786472148541114, 0.831439393939394, 0.8583333333333333]\n",
            "0.7976326475248889\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7771883289124668, 0.831439393939394, 0.8545454545454545]\n",
            "0.7937269678187167\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7824933687002652, 0.8276515151515151, 0.853030303030303]\n",
            "0.7930897150878677\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7117346938775511, 0.7851458885941645, 0.8267045454545454, 0.8522727272727273]\n",
            "0.7939644637997472\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7851458885941645, 0.8285984848484849, 0.8492424242424242]\n",
            "0.7930426177886153\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7091836734693877, 0.7851458885941645, 0.8276515151515152, 0.85]\n",
            "0.7929952693037668\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.7142857142857143, 0.7838196286472149, 0.8323863636363636, 0.8522727272727273]\n",
            "0.795691108460505\n",
            "\n",
            "Best accuracy = 0.8053043579983235\n",
            "\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3b5ee2dcc005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/My Drive/datasets/results/xlnet_large/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-dcc9d8c14d50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, tokenizer, max_epochs, save_path, device, val_freq)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m           \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mmax_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e47a1c4409b1>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m# speeding up validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_token_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_sent_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0d9d0ecc382c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xlnet_ids, xlnet_mask, xlnet_token_starts, lm_lengths, labels)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlnet_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlnet_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mxlnet_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    880\u001b[0m                 \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m             )\n\u001b[1;32m    884\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output_h, output_g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mmems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mtarget_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         )\n\u001b[1;32m    446\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# core attention ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             attn_vec = self.rel_attn_core(\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mq_head_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_head_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_mat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseg_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             )\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# position based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ibnd,jbnd->bnij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_head\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_r_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel_shift_bnij\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;31m# segment based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_xlnet.py\u001b[0m in \u001b[0;36mrel_shift_bnij\u001b[0;34m(x, klen)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m#       However, tracing doesn't like the nature of the slice, and if klen changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m#       during the run then it'll fail, whereas index_select will be fine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;31m# x = x[:, :, :, :klen]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaYMXOt5KgNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(max_accuracy, \"\\n\", max_match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2bssHl9ECiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
