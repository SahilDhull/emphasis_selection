{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_largebert_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6992133a0fd84260959b88f9b9b62090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ba5825a6ee85422daf383210457efb2e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_562169c40f9e4c5a840fb280bd962087",
              "IPY_MODEL_8f6817f45edf4c23a378ec06d01b67a3"
            ]
          }
        },
        "ba5825a6ee85422daf383210457efb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "562169c40f9e4c5a840fb280bd962087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_638aad3f26f74e1f910e1b1be7b8973b",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f28abe934fca4b8ebdc431a63dc29530"
          }
        },
        "8f6817f45edf4c23a378ec06d01b67a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66a0951e2b1a4e3d9d48dc0b42524e94",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 213k/213k [00:00&lt;00:00, 328kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2ac177fb42140298d695cbed0636ec8"
          }
        },
        "638aad3f26f74e1f910e1b1be7b8973b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f28abe934fca4b8ebdc431a63dc29530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66a0951e2b1a4e3d9d48dc0b42524e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2ac177fb42140298d695cbed0636ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c63a1095912a40e498b483fa9d4821fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00c0e2efc12c44a19b46ad33e5131c18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b90b35a84ad64f969743e9811ea7574e",
              "IPY_MODEL_63d5ae5b47d0463490a5b2c243721bee"
            ]
          }
        },
        "00c0e2efc12c44a19b46ad33e5131c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b90b35a84ad64f969743e9811ea7574e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c90a7950593942dc8bc111aaf825ae7e",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 569,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 569,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e400ea7aad0b4adba293669234e77a92"
          }
        },
        "63d5ae5b47d0463490a5b2c243721bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aff240f99bd145369f63e948d12953c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 569/569 [00:00&lt;00:00, 20.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d72dde8dbff7474aafa0397baf7788e4"
          }
        },
        "c90a7950593942dc8bc111aaf825ae7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e400ea7aad0b4adba293669234e77a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aff240f99bd145369f63e948d12953c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d72dde8dbff7474aafa0397baf7788e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8dd62028df53447b8500ca31679de659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61fb34fc61834b96b559220f5b9420b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8e0b8f74320a485eb29ea4f7350cea9a",
              "IPY_MODEL_a13b75d5c9eb4f978be6f80c84a9c553"
            ]
          }
        },
        "61fb34fc61834b96b559220f5b9420b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e0b8f74320a485eb29ea4f7350cea9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c6462ba09a845fc9fa75a5657215bd1",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1338740706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1338740706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86809f7b293546f788b4815e1a1c246f"
          }
        },
        "a13b75d5c9eb4f978be6f80c84a9c553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eaf7e95bb72f434ebe057e0cac93a384",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1.34G/1.34G [01:53&lt;00:00, 11.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d703550163e34576a0138741865fbaab"
          }
        },
        "1c6462ba09a845fc9fa75a5657215bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86809f7b293546f788b4815e1a1c246f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaf7e95bb72f434ebe057e0cac93a384": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d703550163e34576a0138741865fbaab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilDhull/emphasis_selection/blob/master/model/final_largebert_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPnH9VOrfSCu",
        "colab_type": "code",
        "outputId": "4a77c336-5511-48c8-8b2c-9d60de5366df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install config"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 29.7MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 23.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 16.2MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 18.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 15.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 15.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 15.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 35.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 44.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 51.0MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 56.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 61.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 55.3MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 56.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 56.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 58.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 58.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 58.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 58.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 58.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 58.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 62.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=4a0993b26150e1867d74173a8b1003fee09ed13708eb622c4e959e06886890a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n",
            "Collecting config\n",
            "  Downloading https://files.pythonhosted.org/packages/59/6c/4ab0d80b22dca3baab49670b75ae2183b59649e9f27c11018075e509048e/config-0.4.2.tar.gz\n",
            "Building wheels for collected packages: config\n",
            "  Building wheel for config (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for config: filename=config-0.4.2-cp36-none-any.whl size=15135 sha256=de01294ae5840563fccbb6d2a0f8c37abeda3523d10aa9036c24e1e29d72b5f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/7d/db/0e38d2ec57843d00cc39f8df3686984ccec689694f7bc78a38\n",
            "Successfully built config\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJeeb2ifU7X",
        "colab_type": "code",
        "outputId": "65834287-a866-4bed-b2a2-6b82eb63b769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import BertTokenizer, BertConfig , BertForMaskedLM , BertModel\n",
        "# from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
        "# from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizer\n",
        "# from transformers import XLNetConfig, XLNetModel , XLNetTokenizer\n",
        "from transformers import WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import codecs\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQVuhZmdfXji",
        "colab_type": "code",
        "outputId": "276ae136-cc57-4c83-ed8a-ae2a8e3d8932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9BBaiMfbcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b905815c-e4e7-41a5-db3e-aa78b090d9ff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/datasets/train.txt'\n",
        "dev_file = 'drive/My Drive/datasets/dev.txt'\n",
        "test_file = 'drive/My Drive/datasets/test.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPNIJVncgI4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6992133a0fd84260959b88f9b9b62090",
            "ba5825a6ee85422daf383210457efb2e",
            "562169c40f9e4c5a840fb280bd962087",
            "8f6817f45edf4c23a378ec06d01b67a3",
            "638aad3f26f74e1f910e1b1be7b8973b",
            "f28abe934fca4b8ebdc431a63dc29530",
            "66a0951e2b1a4e3d9d48dc0b42524e94",
            "c2ac177fb42140298d695cbed0636ec8"
          ]
        },
        "outputId": "cc1d78f6-b50f-4919-f18a-cb7f7555a19c"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-cased', do_lower_case = False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6992133a0fd84260959b88f9b9b62090",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyhUJlsjlKAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_token_map(file,word_index = 1,prob_index = 4, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  token_labels = []\n",
        "  sent_length = []\n",
        "\n",
        "  bert_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  labels = []\n",
        "\n",
        "  bert_tokens.append(\"[CLS]\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      label = feats[prob_index].lower() if caseless else feats[prob_index]\n",
        "      labels.append((float)(label))\n",
        "      orig_to_tok_map.append(len(bert_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        if(bert_tokens[-1] != \"won\"):\n",
        "          bert_tokens[-1] = bert_tokens[-1] +\"n\"\n",
        "      if(word == \"wo\"):\n",
        "        word = \"won\"\n",
        "\n",
        "      bert_tokens.extend(tokenizer.tokenize(word))\n",
        "     \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      bert_tokens.append(\"[SEP]\")\n",
        "      tokenized_texts.append(bert_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      token_labels.append(labels)\n",
        "      sent_length.append(len(labels))\n",
        "      bert_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      labels = []\n",
        "      length = 0\n",
        "      bert_tokens.append(\"[CLS]\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    bert_tokens.append(\"[SEP]\")\n",
        "    tokenized_texts.append(bert_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    token_labels.append(labels)\n",
        "    sent_length.append(len(labels))\n",
        "  \n",
        "  return tokenized_texts, token_map, token_labels, sent_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6CFT8tKJh9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_test_token_map(file,word_index = 1, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  sent_length = []\n",
        "\n",
        "  bert_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  \n",
        "  bert_tokens.append(\"[CLS]\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      orig_to_tok_map.append(len(bert_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        if(bert_tokens[-1] != \"won\"):\n",
        "          bert_tokens[-1] = bert_tokens[-1] +\"n\"\n",
        "      if(word == \"wo\"):\n",
        "        word = \"won\"\n",
        "\n",
        "      bert_tokens.extend(tokenizer.tokenize(word))\n",
        "     \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      bert_tokens.append(\"[SEP]\")\n",
        "      tokenized_texts.append(bert_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      sent_length.append(len(orig_to_tok_map))\n",
        "      bert_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      length = 0\n",
        "      bert_tokens.append(\"[CLS]\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    bert_tokens.append(\"[SEP]\")\n",
        "    tokenized_texts.append(bert_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    sent_length.append(len(orig_to_tok_map))\n",
        "  \n",
        "  return tokenized_texts, token_map, sent_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPE6ZIIl-Z_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "88bacf26-c58d-4636-aa5f-5ec04b6767ac"
      },
      "source": [
        "t_tokenized_texts, t_token_map, t_token_label, t_sent_length = read_token_map(train_file)\n",
        "print(t_tokenized_texts[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])\n",
        "print(t_sent_length[100])\n",
        "\n",
        "d_tokenized_texts, d_token_map, d_token_label, d_sent_length = read_token_map(dev_file)\n",
        "print(d_tokenized_texts[0])\n",
        "print(d_token_map[0])\n",
        "print(d_token_label[0])\n",
        "print(d_sent_length[0])\n",
        "\n",
        "f_tokenized_texts, f_token_map, f_sent_length = read_test_token_map(test_file)\n",
        "print(f_tokenized_texts[50])\n",
        "print(f_token_map[50])\n",
        "print(f_sent_length[50])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Happiness', 'consists', 'in', 'realizing', 'it', 'is', 'all', 'a', 'great', 'strange', 'dream', '.', '[SEP]']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n",
            "12\n",
            "['[CLS]', 'Life', 'is', 'defined', 'more', 'by', 'its', 'risks', 'than', 'by', 'its', 'same', '##ness', '##es', '.', '[SEP]']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14]\n",
            "[0.4444444444444444, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 1.0, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111, 0.7777777777777778, 0.1111111111111111]\n",
            "12\n",
            "['[CLS]', 'In', 'the', 'practice', 'of', 'tolerance', ',', 'one', \"'\", 's', 'enemy', 'is', 'the', 'best', 'teacher', '.', '[SEP]']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15]\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HExaYvEmDIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "61b8901a-5265-4956-8c52-69c55afb7ccd"
      },
      "source": [
        "MAX_LEN = 72\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(t_input_ids[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 25410  2923  1107 10459  1122  1110  1155   170  1632  4020  4185\n",
            "   119   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n",
            " 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusk7aXcmHIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fe8d0c43-5ffd-4657-be20-fa7c34090ee7"
      },
      "source": [
        "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(d_input_ids[0])\n",
        "print(d_token_map[0])\n",
        "print(d_token_label[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101  2583  1110  3393  1167  1118  1157 11040  1190  1118  1157  1269\n",
            "  1757  1279   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 14  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.44444444 0.11111111 0.22222222 0.11111111 0.11111111 0.11111111\n",
            " 1.         0.11111111 0.11111111 0.11111111 0.77777778 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgQGRhi3IEu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "23fc1464-d209-4025-820b-f302f26c6f96"
      },
      "source": [
        "f_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in f_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "f_input_ids = pad_sequences(f_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "f_token_map = pad_sequences(f_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(f_input_ids[50])\n",
        "print(f_token_map[50])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101  1130  1103  2415  1104 15745   117  1141   112   188  3437  1110\n",
            "  1103  1436  3218   119   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  7  8 10 11 12 13 14 15  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCgv6Er9mKTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5f956a22-26ee-4040-b835-c17d9ae89755"
      },
      "source": [
        "t_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in t_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  t_attention_masks.append(seq_mask)\n",
        "print(t_attention_masks[100])\n",
        "\n",
        "d_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in d_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  d_attention_masks.append(seq_mask)\n",
        "print(d_attention_masks[0])\n",
        "\n",
        "f_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in f_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  f_attention_masks.append(seq_mask)\n",
        "print(f_attention_masks[50])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzs4KzUCmNGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_input_ids = torch.tensor(t_input_ids)\n",
        "t_token_map = torch.tensor(t_token_map )\n",
        "t_token_label = torch.tensor(t_token_label)\n",
        "t_attention_masks = torch.tensor(t_attention_masks)\n",
        "t_sent_length = torch.tensor(t_sent_length)\n",
        "\n",
        "d_input_ids = torch.tensor(d_input_ids)\n",
        "d_token_map = torch.tensor(d_token_map )\n",
        "d_token_label = torch.tensor(d_token_label)\n",
        "d_attention_masks = torch.tensor(d_attention_masks)\n",
        "d_sent_length = torch.tensor(d_sent_length)\n",
        "\n",
        "f_input_ids = torch.tensor(f_input_ids)\n",
        "f_token_map = torch.tensor(f_token_map )\n",
        "f_attention_masks = torch.tensor(f_attention_masks)\n",
        "f_sent_length = torch.tensor(f_sent_length)\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "# print(t_token_labels)\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks, t_sent_length)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks, d_sent_length)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size, shuffle = False)\n",
        "test_data = TensorDataset(f_input_ids, f_token_map, f_attention_masks, f_sent_length)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size,shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T64VOgLFK0AI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_for_output(file,word_index = 1):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  words_lsts = []\n",
        "  word_ids_lsts = []\n",
        "  words = []\n",
        "  ids = []\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      words.append(feats[word_index])\n",
        "      ids.append(feats[0])\n",
        "     \n",
        "    elif len(words) > 0:\n",
        "      words_lsts.append(words)\n",
        "      word_ids_lsts.append(ids)\n",
        "      words = []\n",
        "      ids = []\n",
        "          \n",
        "  if len(words) > 0:\n",
        "    words_lsts.append(words)\n",
        "    word_ids_lsts.append(ids)\n",
        "    words = []\n",
        "    ids = []\n",
        "  \n",
        "  return words_lsts , word_ids_lsts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhtYp8UKM6-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "189b68e6-763f-48c0-d9c4-81ce23e7a444"
      },
      "source": [
        "dev_words, dev_word_ids = read_for_output(dev_file)\n",
        "test_words, test_word_ids = read_for_output(test_file)\n",
        "\n",
        "print(dev_words[0])\n",
        "print(dev_word_ids[0])\n",
        "print(test_words[50])\n",
        "print(test_word_ids[50])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Life', 'is', 'defined', 'more', 'by', 'its', 'risks', 'than', 'by', 'its', 'samenesses', '.']\n",
            "['Q_0_0', 'Q_0_1', 'Q_0_2', 'Q_0_3', 'Q_0_4', 'Q_0_5', 'Q_0_6', 'Q_0_7', 'Q_0_8', 'Q_0_9', 'Q_0_10', 'Q_0_11']\n",
            "['In', 'the', 'practice', 'of', 'tolerance', ',', 'one', \"'s\", 'enemy', 'is', 'the', 'best', 'teacher', '.']\n",
            "['Q_50_0', 'Q_50_1', 'Q_50_2', 'Q_50_3', 'Q_50_4', 'Q_50_5', 'Q_50_6', 'Q_50_7', 'Q_50_8', 'Q_50_9', 'Q_50_10', 'Q_50_11', 'Q_50_12', 'Q_50_13']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz4BGjpUsDSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3\n",
        "\n",
        "def fix_padding(scores_numpy, label_probs,  mask_numpy):\n",
        "    #if len(scores_numpy) != len(mask_numpy):\n",
        "    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n",
        "    #assert len(scores_numpy) == len(mask_numpy)\n",
        "    #if len(label_probs) != len(mask_numpy):\n",
        "    #    print(\"len(label_probs) != len(mask_numpy)\")\n",
        "    #assert len(label_probs) == len(mask_numpy)\n",
        "\n",
        "    all_scores_no_padd = []\n",
        "    all_labels_no_pad = []\n",
        "    for i in range(len(mask_numpy)):\n",
        "        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n",
        "        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n",
        "\n",
        "    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n",
        "    return all_scores_no_padd, all_labels_no_pad\n",
        "\n",
        "def match_M(batch_scores_no_padd, batch_labels_no_pad):\n",
        "\n",
        "    top_m = [1, 2, 3, 4]\n",
        "    batch_num_m=[]\n",
        "    batch_score_m=[]\n",
        "    for m in top_m:\n",
        "        intersects_lst = []\n",
        "        # exact_lst = []\n",
        "        score_lst = []\n",
        "        ############################################### computing scores:\n",
        "        for s in batch_scores_no_padd:\n",
        "            if len(s) <=m:\n",
        "                continue\n",
        "            h = m\n",
        "            # if len(s) > h:\n",
        "            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n",
        "            #         h += 1\n",
        "\n",
        "            # s = np.asarray(s.cpu())\n",
        "            s = np.asarray(s)\n",
        "            #ind_score = np.argsort(s)[-h:]\n",
        "            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n",
        "            score_lst.append(ind_score)\n",
        "\n",
        "        ############################################### computing labels:\n",
        "        label_lst = []\n",
        "        for l in batch_labels_no_pad:\n",
        "            if len(l) <=m:\n",
        "                continue\n",
        "            # if it contains several top values with the same amount\n",
        "            h = m\n",
        "            # l = l.cpu()\n",
        "            if len(l) > h:\n",
        "                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n",
        "                    h += 1\n",
        "            l = np.asarray(l)\n",
        "            ind_label = np.argsort(l)[-h:]\n",
        "            label_lst.append(ind_label)\n",
        "\n",
        "        ############################################### :\n",
        "\n",
        "        for i in range(len(score_lst)):\n",
        "            intersect = intersection(score_lst[i], label_lst[i])\n",
        "            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n",
        "            # sorted_score_lst = sorted(score_lst[i])\n",
        "            # sorted_label_lst =  sorted(label_lst[i])\n",
        "            # if sorted_score_lst==sorted_label_lst:\n",
        "            #     exact_lst.append(1)\n",
        "            # else:\n",
        "            #     exact_lst.append(0)\n",
        "        batch_num_m.append(len(score_lst))\n",
        "        batch_score_m.append(sum(intersects_lst))\n",
        "    return batch_num_m, batch_score_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X8RL3dgOKAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model):\n",
        "  print(\"\")\n",
        "  print(\"Running test...\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  iii = 0\n",
        "\n",
        "  s = \"\"\n",
        "  sentence_id = \"\"\n",
        "\n",
        "  for batch in test_dataloader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      v_input_ids = batch[0].to(device)\n",
        "      v_input_mask = batch[2].to(device)\n",
        "      v_token_starts = batch[1].to(device)\n",
        "      v_sent_length = batch[3]\n",
        "            \n",
        "      # Telling the model not to compute or store gradients, saving memory and\n",
        "      # speeding up validation\n",
        "      with torch.no_grad():        \n",
        "          output = model(v_input_ids, v_input_mask, v_token_starts, v_sent_length)\n",
        "      \n",
        "      pred_labels = output[1]\n",
        "\n",
        "      pred_labels = pred_labels.detach().cpu().numpy()\n",
        "\n",
        "      for i in range(v_input_ids.size()[0]):\n",
        "        for j in range(len(test_words[iii])):\n",
        "          if sentence_id == iii:\n",
        "            s = s + \"{}\\t{}\\t{}\\t\".format(test_word_ids[iii][j], test_words[iii][j], pred_labels[i][j]) + \"\\n\"\n",
        "          else:\n",
        "            s = s + \"\\n\" + \"{}\\t{}\\t{}\\t\".format(test_word_ids[iii][j], test_words[iii][j], pred_labels[i][j]) + \"\\n\"\n",
        "            sentence_id = iii\n",
        "        iii = iii + 1\n",
        "      s = s +\"\\n\"\n",
        "      \n",
        "  print(\"testing complete\")\n",
        "  # print(s)\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Waw_HPZ3sJza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model):\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  num_m = [0, 0, 0, 0]\n",
        "  score_m = [0, 0, 0, 0]\n",
        "\n",
        "  iii = 0\n",
        "\n",
        "  s = \"\"\n",
        "  sentence_id = \"\"\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      v_input_ids = batch[0].to(device)\n",
        "      v_input_mask = batch[3].to(device)\n",
        "      v_token_starts = batch[1].to(device)\n",
        "      v_labels = batch[2].to(device)\n",
        "      v_sent_length = batch[4]\n",
        "            \n",
        "      # Telling the model not to compute or store gradients, saving memory and\n",
        "      # speeding up validation\n",
        "      with torch.no_grad():        \n",
        "          output = model(v_input_ids, v_input_mask, v_token_starts, v_sent_length, v_labels)\n",
        "      \n",
        "      pred_labels = output[1]\n",
        "\n",
        "      pred_labels = pred_labels.detach().cpu().numpy()\n",
        "      v_labels = v_labels.to('cpu').numpy()\n",
        "\n",
        "      for i in range(v_input_ids.size()[0]):\n",
        "        for j in range(len(dev_words[iii])):\n",
        "          if sentence_id == iii:\n",
        "            s = s + \"{}\\t{}\\t{}\\t{}\".format(dev_word_ids[iii][j], dev_words[iii][j], pred_labels[i][j],v_labels[i][j]) + \"\\n\"\n",
        "          else:\n",
        "            s = s + \"\\n\" + \"{}\\t{}\\t{}\\t{}\".format(dev_word_ids[iii][j], dev_words[iii][j], pred_labels[i][j],v_labels[i][j]) + \"\\n\"\n",
        "            sentence_id = iii\n",
        "        iii = iii + 1\n",
        "      s = s +\"\\n\"\n",
        "      \n",
        "      pred_labels, v_labels = fix_padding(pred_labels, v_labels, v_sent_length)\n",
        "\n",
        "      batch_num_m, batch_score_m = match_M(pred_labels, v_labels)\n",
        "      num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n",
        "      score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n",
        "  \n",
        "  m_score = [i/j for i,j in zip(score_m, num_m)]\n",
        "  \n",
        "  print(\"Validation Accuracy: \")\n",
        "  print(m_score)\n",
        "  v_score = np.mean(m_score)\n",
        "  print(v_score)\n",
        "  # print(s)\n",
        "\n",
        "  return v_score, s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLkMdFoNsRMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model,  optimizer, scheduler, tokenizer, max_epochs, save_path, device, val_freq = 10):\n",
        "  \n",
        "  bestpoint_dir = os.path.join(save_path)\n",
        "  os.makedirs(bestpoint_dir, exist_ok=True)\n",
        "  max_accuracy = 0\n",
        "  val_out = \"\"\n",
        "  test_out = \"\"\n",
        "\n",
        "  for epoch_i in range(0, max_epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, max_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):    \n",
        "\n",
        "        print(\"batch\",step,\"out of\",len(train_dataloader))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[3].to(device)\n",
        "        b_token_starts = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_sent_length = batch[4]\n",
        "\n",
        "        model.zero_grad()   \n",
        "        model.train()     \n",
        "\n",
        "        output = model(b_input_ids, b_input_mask, b_token_starts,b_sent_length,b_labels)\n",
        "        loss = output[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        if step % 10 == 0:\n",
        "          accuracy, outs = validation(model)\n",
        "          if(accuracy > max_accuracy):\n",
        "            max_accuracy = accuracy\n",
        "            val_out = outs\n",
        "            test_out = test(model)\n",
        "\n",
        "            # model.save_pretrained(bestpoint_dir)  \n",
        "            # print(\"Saving model bestpoint to \", bestpoint_dir)\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  \n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  return max_accuracy ,val_out, test_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZIU8zV-mQt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class transformer_model(nn.Module):\n",
        "  def __init__(self, model_name, drop_prob = 0.3):\n",
        "    super(transformer_model, self).__init__()\n",
        "\n",
        "    config = BertConfig.from_pretrained(model_name, output_hidden_states=True)\n",
        "    self.bert = BertForMaskedLM.from_pretrained(model_name, config = config)\n",
        "    \n",
        "    # the commented lines freezes layers of the model\n",
        "    # cnt=0\n",
        "    # for child in bert.bert.children():\n",
        "    #   cnt = cnt + 1\n",
        "    #   if cnt<=23:\n",
        "    #     for param in child.parameters():\n",
        "    #       param.requires_grad = False\n",
        "\n",
        "    bert_dim = 25*1024\n",
        "    hidden_dim1 = 950\n",
        "    hidden_dim2 = 40\n",
        "    final_size = 1\n",
        "\n",
        "    self.fc1 = nn.Linear(bert_dim, hidden_dim1)\n",
        "    self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "    self.fc3 = nn.Linear(hidden_dim2, final_size)\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "  def avg(self, a, st, end):\n",
        "    k = a\n",
        "    lis = []\n",
        "    for i in range(st,end):\n",
        "      lis.append(a[i])\n",
        "    x = torch.mean(torch.stack(lis),dim=0)\n",
        "    return x\n",
        "\n",
        "  def save_pretrained(self, output_dir):\n",
        "    self.bert.save_pretrained(output_dir)\n",
        "    #please save the fc layers\n",
        "           \n",
        "  def forward(self, bert_ids, bert_mask, bert_token_starts, lm_lengths = None, labels = None):\n",
        "    \n",
        "    batch_size = bert_ids.size()[0]\n",
        "    pad_size = bert_ids.size()[1]\n",
        "    # print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n",
        "\n",
        "    output = self.bert(bert_ids, attention_mask = bert_mask)\n",
        "\n",
        "    bert_out = output[1][0]\n",
        "    for layers in range(1,25,1):\n",
        "      bert_out = torch.cat((bert_out, output[1][layers]), dim=2)\n",
        "    \n",
        "    pred_logits = torch.relu(self.fc1(self.dropout(bert_out)))\n",
        "    pred_logits = torch.relu(self.fc2(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.sigmoid(self.fc3(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.squeeze(pred_logits,2)\n",
        "\n",
        "    pred_labels = torch.tensor(np.zeros(bert_token_starts.size()),dtype = torch.float64).to(device)\n",
        "\n",
        "    # print(pred_logits[0])\n",
        "    # print(pred_labels[0])\n",
        "    # print(labels[0])\n",
        "    # print(bert_token_starts[0])\n",
        "\n",
        "    for b in range(batch_size):\n",
        "      for w in range(pad_size):\n",
        "        if(bert_token_starts[b][w]!=0):\n",
        "          if(bert_token_starts[b][w]>=pad_size):\n",
        "            print(bert_token_starts[b])\n",
        "          else:\n",
        "            st = bert_token_starts[b][w]\n",
        "            end = bert_token_starts[b][w+1]\n",
        "            if(end==0):\n",
        "              end = st+1\n",
        "              while(bert_mask[b][end]!=0):\n",
        "                end = end+1\n",
        "            # pred_labels[b][w] = self.avg(pred_logits[b],st,end)\n",
        "            pred_labels[b][w] = pred_logits[b][bert_token_starts[b][w]]\n",
        "\n",
        "    # print(pred_labels[0])\n",
        "\n",
        "    if(labels != None):\n",
        "      lm_lengths, lm_sort_ind = lm_lengths.sort(dim=0, descending=True)\n",
        "      scores = labels[lm_sort_ind]\n",
        "      targets = pred_labels[lm_sort_ind]\n",
        "      scores = pack_padded_sequence(scores, lm_lengths, batch_first=True).data\n",
        "      targets = pack_padded_sequence(targets, lm_lengths, batch_first=True).data\n",
        "\n",
        "      # print(targets,scores)\n",
        "\n",
        "      loss_fn = nn.BCELoss().to(device) \n",
        "      loss = loss_fn(targets,scores)\n",
        "\n",
        "      return loss, pred_labels \n",
        "\n",
        "    else:\n",
        "      return 0.0, pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyCLOk5srSvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c63a1095912a40e498b483fa9d4821fc",
            "00c0e2efc12c44a19b46ad33e5131c18",
            "b90b35a84ad64f969743e9811ea7574e",
            "63d5ae5b47d0463490a5b2c243721bee",
            "c90a7950593942dc8bc111aaf825ae7e",
            "e400ea7aad0b4adba293669234e77a92",
            "aff240f99bd145369f63e948d12953c8",
            "d72dde8dbff7474aafa0397baf7788e4",
            "8dd62028df53447b8500ca31679de659",
            "61fb34fc61834b96b559220f5b9420b6",
            "8e0b8f74320a485eb29ea4f7350cea9a",
            "a13b75d5c9eb4f978be6f80c84a9c553",
            "1c6462ba09a845fc9fa75a5657215bd1",
            "86809f7b293546f788b4815e1a1c246f",
            "eaf7e95bb72f434ebe057e0cac93a384",
            "d703550163e34576a0138741865fbaab"
          ]
        },
        "outputId": "aed8d6c4-ac50-4ce0-8a25-e485c02e85e1"
      },
      "source": [
        "model = transformer_model('bert-large-cased').to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c63a1095912a40e498b483fa9d4821fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=569, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dd62028df53447b8500ca31679de659",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=1338740706, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Ob6wRjr3rW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 30\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB-7PRyzsZiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92d56568-b67a-4d27-9f07-02007213b8a2"
      },
      "source": [
        "save_path = 'drive/My Drive/datasets/results/bert_large/'\n",
        "max_accuracy ,val_out, test_out = train(model,  optimizer, scheduler, tokenizer, epochs, save_path, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.3520408163265306, 0.5119363395225465, 0.5757575757575757, 0.6287878787878788]\n",
            "0.5171306525986329\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.4719387755102041, 0.6578249336870027, 0.7433712121212122, 0.7674242424242425]\n",
            "0.6601397909356653\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5127551020408163, 0.6949602122015915, 0.787878787878788, 0.8272727272727273]\n",
            "0.7057167073484808\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 21 out of 86\n",
            "batch 22 out of 86\n",
            "batch 23 out of 86\n",
            "batch 24 out of 86\n",
            "batch 25 out of 86\n",
            "batch 26 out of 86\n",
            "batch 27 out of 86\n",
            "batch 28 out of 86\n",
            "batch 29 out of 86\n",
            "batch 30 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5306122448979592, 0.726790450928382, 0.7926136363636364, 0.8318181818181818]\n",
            "0.7204586285020398\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 31 out of 86\n",
            "batch 32 out of 86\n",
            "batch 33 out of 86\n",
            "batch 34 out of 86\n",
            "batch 35 out of 86\n",
            "batch 36 out of 86\n",
            "batch 37 out of 86\n",
            "batch 38 out of 86\n",
            "batch 39 out of 86\n",
            "batch 40 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5357142857142857, 0.746684350132626, 0.7945075757575758, 0.8409090909090909]\n",
            "0.7294538256283946\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 41 out of 86\n",
            "batch 42 out of 86\n",
            "batch 43 out of 86\n",
            "batch 44 out of 86\n",
            "batch 45 out of 86\n",
            "batch 46 out of 86\n",
            "batch 47 out of 86\n",
            "batch 48 out of 86\n",
            "batch 49 out of 86\n",
            "batch 50 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5663265306122449, 0.7519893899204244, 0.800189393939394, 0.8469696969696969]\n",
            "0.74136875286044\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 51 out of 86\n",
            "batch 52 out of 86\n",
            "batch 53 out of 86\n",
            "batch 54 out of 86\n",
            "batch 55 out of 86\n",
            "batch 56 out of 86\n",
            "batch 57 out of 86\n",
            "batch 58 out of 86\n",
            "batch 59 out of 86\n",
            "batch 60 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5790816326530612, 0.7559681697612732, 0.8039772727272727, 0.8492424242424242]\n",
            "0.7470673748460078\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 61 out of 86\n",
            "batch 62 out of 86\n",
            "batch 63 out of 86\n",
            "batch 64 out of 86\n",
            "batch 65 out of 86\n",
            "batch 66 out of 86\n",
            "batch 67 out of 86\n",
            "batch 68 out of 86\n",
            "batch 69 out of 86\n",
            "batch 70 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6045918367346939, 0.7506631299734748, 0.8153409090909091, 0.8515151515151516]\n",
            "0.7555277568285573\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 71 out of 86\n",
            "batch 72 out of 86\n",
            "batch 73 out of 86\n",
            "batch 74 out of 86\n",
            "batch 75 out of 86\n",
            "batch 76 out of 86\n",
            "batch 77 out of 86\n",
            "batch 78 out of 86\n",
            "batch 79 out of 86\n",
            "batch 80 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6147959183673469, 0.7679045092838196, 0.8200757575757578, 0.8606060606060606]\n",
            "0.7658455614582462\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 81 out of 86\n",
            "batch 82 out of 86\n",
            "batch 83 out of 86\n",
            "batch 84 out of 86\n",
            "batch 85 out of 86\n",
            "\n",
            "  Average training loss: 0.52\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "batch 0 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6301020408163265, 0.7652519893899205, 0.819128787878788, 0.8568181818181818]\n",
            "0.7678252499758043\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 1 out of 86\n",
            "batch 2 out of 86\n",
            "batch 3 out of 86\n",
            "batch 4 out of 86\n",
            "batch 5 out of 86\n",
            "batch 6 out of 86\n",
            "batch 7 out of 86\n",
            "batch 8 out of 86\n",
            "batch 9 out of 86\n",
            "batch 10 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6326530612244898, 0.7824933687002652, 0.8200757575757577, 0.8492424242424242]\n",
            "0.7711161529357342\n",
            "\n",
            "Running test...\n",
            "testing complete\n",
            "batch 11 out of 86\n",
            "batch 12 out of 86\n",
            "batch 13 out of 86\n",
            "batch 14 out of 86\n",
            "batch 15 out of 86\n",
            "batch 16 out of 86\n",
            "batch 17 out of 86\n",
            "batch 18 out of 86\n",
            "batch 19 out of 86\n",
            "batch 20 out of 86\n",
            "\n",
            "Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.786472148541114, 0.8143939393939394, 0.8515151515151516]\n",
            "0.7769983710870411\n",
            "\n",
            "Running test...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaYMXOt5KgNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(max_accuracy ,val_out, test_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TmUEMs0G-JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}