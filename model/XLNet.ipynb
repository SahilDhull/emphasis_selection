{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XLNet.ipynb","provenance":[{"file_id":"13ly9q_likSxp2e3LNiPVcb19vtOLneT8","timestamp":1582735793779},{"file_id":"1PjtdDsvXQMtPdnuwQeq7BwB15v5AGKkE","timestamp":1582649473990},{"file_id":"https://github.com/SahilDhull/emphasis_selection/blob/master/model/bert_as_embedding_v3.ipynb","timestamp":1582481346645}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iFZ3HHuy1mx0","colab_type":"code","outputId":"82d1518d-9d29-48c6-c862-ed69f44a41c0","executionInfo":{"status":"ok","timestamp":1582742548815,"user_tz":-330,"elapsed":11873,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["!pip install transformers\n","!pip install config"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Requirement already satisfied: config in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oZkDAFPU1ps2","colab_type":"code","outputId":"7f165f11-8602-4075-ad4f-35c6d76d52c0","executionInfo":{"status":"ok","timestamp":1582742550737,"user_tz":-330,"elapsed":13732,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","#from sklearn.model_selection import train_test_spl\n","from transformers import XLNetModel, XLNetConfig, XLNetTokenizer\n","from transformers import RobertaModel, RobertaConfig, RobertaTokenizer\n","from transformers import GPT2Model, GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n","from transformers import BertTokenizer, BertConfig\n","from transformers import BertForMaskedLM , BertModel ,WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n","from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import codecs\n","from torch.nn.utils.rnn import pack_padded_sequence"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"nhNFcgUa1w1k","colab_type":"code","outputId":"9bc0112f-90da-41d9-bb90-b17d37ab8f6f","executionInfo":{"status":"ok","timestamp":1582742550741,"user_tz":-330,"elapsed":13674,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla P100-PCIE-16GB'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"kmLIQdgZ1zFP","colab_type":"code","outputId":"180720ff-7231-4679-ba4f-c3d0d6840ff3","executionInfo":{"status":"ok","timestamp":1582742550745,"user_tz":-330,"elapsed":13574,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","train_file = 'drive/My Drive/datasets/train.txt'\n","dev_file = 'drive/My Drive/datasets/dev.txt'\n","\n","quotes_file = 'drive/My Drive/datasets/all_quotes.txt'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IplzxoD111cP","colab_type":"code","colab":{}},"source":["tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased', do_lower_case = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RM2bAwze2Ezt","colab_type":"code","colab":{}},"source":["def read_token_map(file, word_index = 1,prob_index = 4, caseless = False):\n","  \n","  with codecs.open(file, 'r', 'utf-8') as f:\n","      lines = f.readlines()\n","\n","  tokenized_texts = []\n","  token_map = []\n","  token_labels = []\n","  sent_length = []\n","\n","  xlnet_tokens = []\n","  orig_to_tok_map = []\n","  labels = []\n","\n","  xlnet_tokens.append(\"<s>\")\n","  \n","  for line in lines:\n","    if not (line.isspace()):\n","      feats = line.strip().split()\n","      word = feats[word_index].lower() if caseless else feats[word_index]\n","      label = feats[prob_index].lower() if caseless else feats[prob_index]\n","      labels.append((float)(label))\n","      orig_to_tok_map.append(len(xlnet_tokens))\n","      \n","      if(word == \"n't\"):\n","        word = \"'t\"\n","        if(xlnet_tokens[-1] != \"won\"):\n","          xlnet_tokens[-1] = xlnet_tokens[-1] +\"n\"\n","      if(word == \"wo\"):\n","        word == \"won\"\n","\n","      xlnet_tokens.extend(tokenizer.tokenize(word))\n","\n","    elif len(orig_to_tok_map) > 0:\n","\n","      # lab = np.array(labels)\n","      # lab.sort()\n","      # if(len(labels)>=4):\n","      #   mini = lab[-4]\n","      # else:\n","      #   mini = lab[0]\n"," \n","      # for l in range(len(labels)):\n","      #   if(labels[l]<mini):\n","      #     labels[l] = 0.0\n","\n","      xlnet_tokens.append(\"</s>\")\n","      tokenized_texts.append(xlnet_tokens)\n","      token_map.append(orig_to_tok_map)\n","      token_labels.append(labels)\n","      sent_length.append(len(labels))\n","      xlnet_tokens = []\n","      orig_to_tok_map = []\n","      labels = []\n","      length = 0\n","      xlnet_tokens.append(\"<s>\")\n","          \n","  if len(orig_to_tok_map) > 0:\n","    xlnet_tokens.append(\"</s>\")\n","    tokenized_texts.append(xlnet_tokens)\n","    token_map.append(orig_to_tok_map)\n","    token_labels.append(labels)\n","    sent_length.append(len(labels))\n","  \n","  return tokenized_texts, token_map, token_labels, sent_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IflGdsPR2LmX","colab_type":"code","outputId":"c54922f2-e962-4425-f28e-95921d780306","executionInfo":{"status":"ok","timestamp":1582742553937,"user_tz":-330,"elapsed":16572,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["t_tokenized_texts, t_token_map, t_token_label, t_sent_length = read_token_map(train_file)\n","print(t_tokenized_texts[100])\n","print(t_token_map[100])\n","print(t_token_label[100])\n","print(t_sent_length[100])\n","\n","d_tokenized_texts, d_token_map, d_token_label, d_sent_length = read_token_map(dev_file)\n","print(d_tokenized_texts[50])\n","print(d_token_map[50])\n","print(d_token_label[50])\n","print(d_sent_length[50])\n","print(tokenizer.tokenize(\"Hello, my dog is cute\", add_prefix_space = True))\n","print(tokenizer.tokenize(\"won't\"))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['<s>', '▁Ha', 'ppi', 'ness', '▁consists', '▁in', '▁realizing', '▁it', '▁is', '▁all', '▁a', '▁great', '▁strange', '▁dream', '▁', '.', '</s>']\n","[1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n","[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n","12\n","['<s>', '▁', '\"', '▁Fa', 's', 'cin', 'ating', '▁social', '▁media', '▁tip', '▁or', '▁fact', '▁to', '▁share', '▁', '.', '▁', '\"', '▁', '@', 'S', 'peak', 'er', '▁Name', '</s>']\n","[1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 23]\n","[0.0, 0.5555555555555556, 0.0, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.0, 0.2222222222222222, 0.2222222222222222]\n","13\n","['▁', 'Hello', ',', '▁my', '▁dog', '▁is', '▁cute']\n","['▁won', \"'\", 't']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q8IsOd0i2PnP","colab_type":"code","outputId":"288eed6a-a9c6-4c06-d232-af67add0e7e0","executionInfo":{"status":"ok","timestamp":1582742553940,"user_tz":-330,"elapsed":16486,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["MAX_LEN = 72\n","\n","# Use the XLNET tokenizer to convert the tokens to their index numbers in the XLNET vocabulary\n","t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n","\n","# Pad our input tokens\n","t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n","\n","print(t_input_ids[100])\n","print(t_token_map[100])\n","print(t_token_label[100])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[    1  2541 18458   680  3765    25 15444    36    27    71    24   312\n","  4572  2986    17     9     2     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0]\n","[ 1  4  5  6  7  8  9 10 11 12 13 14  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n","[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n"," 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Sllf5eX2TJg","colab_type":"code","outputId":"2782a10a-f505-4377-cfd3-4ac4e91f7c9d","executionInfo":{"status":"ok","timestamp":1582742553943,"user_tz":-330,"elapsed":16450,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n","\n","# Pad our input tokens\n","d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n","\n","print(d_input_ids[50])\n","print(d_token_map[50])\n","print(d_token_label[50])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[    1    17    12  3115    23  6650  2076   796   789  5149    49   648\n","    22   763    17     9    17    12    17 13304    83 10254   118  8861\n","     2     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0]\n","[ 1  3  7  8  9 10 11 12 13 14 16 18 23  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n","[0.         0.55555556 0.         0.11111111 0.22222222 0.11111111\n"," 0.11111111 0.         0.22222222 0.         0.         0.22222222\n"," 0.22222222 0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GWqYZ8vV2WYx","colab_type":"code","outputId":"d597f892-d586-4be4-be5a-5c461a7f4a2d","executionInfo":{"status":"ok","timestamp":1582742553946,"user_tz":-330,"elapsed":16409,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["t_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in t_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  t_attention_masks.append(seq_mask)\n","print(t_attention_masks[100])\n","\n","d_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in d_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  d_attention_masks.append(seq_mask)\n","print(d_attention_masks[50])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GtnslThr2ZnQ","colab_type":"code","colab":{}},"source":["t_input_ids = torch.tensor(t_input_ids)\n","t_token_map = torch.tensor(t_token_map )\n","t_token_label = torch.tensor(t_token_label)\n","t_attention_masks = torch.tensor(t_attention_masks)\n","t_sent_length = torch.tensor(t_sent_length)\n","\n","d_input_ids = torch.tensor(d_input_ids)\n","d_token_map = torch.tensor(d_token_map )\n","d_token_label = torch.tensor(d_token_label)\n","d_attention_masks = torch.tensor(d_attention_masks)\n","d_sent_length = torch.tensor(d_sent_length)\n","\n","# Select a batch size for training. \n","batch_size = 32\n","# print(t_token_labels)\n","# Create an iterator of our data with torch DataLoader \n","train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks, t_sent_length)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks, d_sent_length)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODH9sTED18Zf","colab_type":"code","colab":{}},"source":["class xlnet_model(nn.Module):\n","  def __init__(self, final_size, drop_prob, data_parallel=True):\n","    super(xlnet_model, self).__init__()\n","\n","    config = XLNetConfig.from_pretrained('xlnet-large-cased', output_hidden_states=True)\n","    xlnet = XLNetModel.from_pretrained('xlnet-large-cased', output_hidden_states=True)\n","    \n","    #cnt=0\n","    #for child in xlnet.children():\n","    #  cnt = cnt + 1\n","    #  if cnt<=12:\n","    #    for param in child.parameters():\n","    #      param.requires_grad = False\n","\n","    if data_parallel:\n","        self.xlnet = nn.DataParallel(xlnet)\n","    else:\n","        self.xlnet = xlnet\n","    xlnet_dim = 24*1024\n","    hidden_dim1 = 1000\n","    hidden_dim2 = 40\n","    hidden_dim3 = 20\n","\n","    self.fc1 = nn.Linear(xlnet_dim, hidden_dim1)\n","    self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n","    #self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n","    self.fc4 = nn.Linear(hidden_dim2, final_size)\n","    self.dropout1 = nn.Dropout(p=drop_prob)\n","    self.dropout2 = nn.Dropout(p=drop_prob)\n","    self.dropout3 = nn.Dropout(p=drop_prob)\n","    self.dropout4 = nn.Dropout(p=drop_prob)\n","           \n","  def forward(self, xlnet_ids, xlnet_mask, labels = None, xlnet_token_starts = None,lm_lengths = None):\n","    \n","    batch_size = xlnet_ids.size()[0]\n","    pad_size = xlnet_ids.size()[1]\n","    #print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n","\n","    if(xlnet_token_starts == None):\n","      output = self.xlnet(xlnet_ids, attention_mask = xlnet_mask, masked_lm_labels=labels)\n","      return output\n","    \n","    output = self.xlnet(xlnet_ids, attention_mask = xlnet_mask)\n","    #print(len(hiddden_states))\n","    #print(len(hidden_states[1]))\n","    #print(hidden_states[1][0].size())\n","    #print(np.shape(output))\n","    #print(np.shape(output[0]))\n","    #print(np.shape(output[0][0]))\n","    #print(np.shape(output[1]))\n","    #print(np.shape(output[1][0]))\n","    #print(np.shape(output[2]))\n","    #print(np.shape(output[2][0]))\n","    #print(len(output[3][0]))\n","    #print(len(output[3][1]))\n","    #print(len(output[3][2]))\n","    #print(len(output[3][0][0]))\n","    #print(len(output[3][0][0][0]))\n","    #print(len(output))\n","    #print(len(output[1]))\n","    #print(output[1][0].size())\n","\n","    xlnet_out = output[1][1]\n","    for layers in range(2,25,1):\n","      xlnet_out = torch.cat((xlnet_out, output[1][layers]), dim=2)\n","    \n","    #print(xlnet_out.size())\n","    # bert_last_layer = output[1][0]\n","    # bert_second_last_layer = output[1][1]\n","    # bert_third_last_layer = output[1][2]\n","    # bert_fourth_last_layer = output[1][3]\n","    # bert_fifth_last_layer = output[1][4]\n","    # bert_sixth_last_layer = output[1][5]\n","\n","    # bert_out = torch.cat((bert_last_layer, bert_second_last_layer, bert_third_last_layer, bert_fourth_last_layer, bert_fifth_last_layer, bert_sixth_last_layer), dim=2)\n","    \n","    pred_logits = torch.relu(self.fc1(self.dropout1(xlnet_out)))\n","    pred_logits = torch.relu(self.fc2(self.dropout2(pred_logits)))\n","    #pred_logits = torch.relu(self.fc3(self.dropout3(pred_logits)))\n","    pred_logits = torch.sigmoid(self.fc4(self.dropout4(pred_logits)))\n","    pred_logits = torch.squeeze(pred_logits,2)\n","    # print(pred_logits.size())\n","    # print(labels.size())\n","    # print(pred_logits[1])\n","    # print(labels[1])\n","    # print(bert_token_starts[1])\n","    # print(\"\\n\")\n","\n","    pred_labels = labels.clone()\n","    # print(pred_labels[1])\n","    # print(\"\\n\")\n","    \n","    for b in range(batch_size):\n","      for w in range(pad_size):\n","        if(xlnet_token_starts[b][w]!=0):\n","          if(xlnet_token_starts[b][w]>=pad_size):\n","            print(xlnet_token_starts[b])\n","          else:\n","            pred_labels[b][w] = pred_logits[b][xlnet_token_starts[b][w]]\n","\n","    # print(pred_labels[1])\n","    # print(labels[1])\n","    # print(\"\\n\")\n","\n","    lm_lengths, lm_sort_ind = lm_lengths.sort(dim=0, descending=True)\n","    scores = labels[lm_sort_ind]\n","    targets = pred_labels[lm_sort_ind]\n","    scores = pack_padded_sequence(scores, lm_lengths, batch_first=True).data\n","    targets = pack_padded_sequence(targets, lm_lengths, batch_first=True).data\n","    \n","    # mask = pred_labels!=0\n","    # total = mask[mask].size()[0]\n","\n","    # loss_fn = nn.BCELoss(reduction='sum').to(device) \n","    loss_fn = nn.BCELoss().to(device) \n","    loss = loss_fn(targets,scores)\n","    # print(loss)\n","\n","    # loss /= total \n","    # print(loss) \n","    return loss, pred_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"56hwBPs_2dUM","colab_type":"code","colab":{}},"source":["model = xlnet_model(1,0.3,True).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJSJ0eki2gWU","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n","\n","epochs = 30\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-F1P6at2kGa","colab_type":"code","colab":{}},"source":["\n","def intersection(lst1, lst2):\n","    lst3 = [value for value in lst1 if value in lst2]\n","    return lst3\n","\n","def fix_padding(scores_numpy, label_probs,  mask_numpy):\n","    #if len(scores_numpy) != len(mask_numpy):\n","    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n","    #assert len(scores_numpy) == len(mask_numpy)\n","    #if len(label_probs) != len(mask_numpy):\n","    #    print(\"len(label_probs) != len(mask_numpy)\")\n","    #assert len(label_probs) == len(mask_numpy)\n","\n","    all_scores_no_padd = []\n","    all_labels_no_pad = []\n","    for i in range(len(mask_numpy)):\n","        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n","        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n","\n","    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n","    return all_scores_no_padd, all_labels_no_pad\n","\n","def match_M(batch_scores_no_padd, batch_labels_no_pad):\n","\n","    top_m = [1, 2, 3, 4]\n","    batch_num_m=[]\n","    batch_score_m=[]\n","    for m in top_m:\n","        intersects_lst = []\n","        # exact_lst = []\n","        score_lst = []\n","        ############################################### computing scores:\n","        for s in batch_scores_no_padd:\n","            if len(s) <=m:\n","                continue\n","            h = m\n","            # if len(s) > h:\n","            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n","            #         h += 1\n","\n","            # s = np.asarray(s.cpu())\n","            s = np.asarray(s)\n","            #ind_score = np.argsort(s)[-h:]\n","            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n","            score_lst.append(ind_score)\n","\n","        ############################################### computing labels:\n","        label_lst = []\n","        for l in batch_labels_no_pad:\n","            if len(l) <=m:\n","                continue\n","            # if it contains several top values with the same amount\n","            h = m\n","            # l = l.cpu()\n","            if len(l) > h:\n","                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n","                    h += 1\n","            l = np.asarray(l)\n","            ind_label = np.argsort(l)[-h:]\n","            label_lst.append(ind_label)\n","\n","        ############################################### :\n","\n","        for i in range(len(score_lst)):\n","            intersect = intersection(score_lst[i], label_lst[i])\n","            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n","            # sorted_score_lst = sorted(score_lst[i])\n","            # sorted_label_lst =  sorted(label_lst[i])\n","            # if sorted_score_lst==sorted_label_lst:\n","            #     exact_lst.append(1)\n","            # else:\n","            #     exact_lst.append(0)\n","        batch_num_m.append(len(score_lst))\n","        batch_score_m.append(sum(intersects_lst))\n","    return batch_num_m, batch_score_m"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRM_nU783HIc","colab_type":"code","colab":{}},"source":["\n","def validation(model, validation_dataloader):\n","  print(\"\")\n","  print(\"Running Validation...\")\n","\n","  model.eval()\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  num_m = [0, 0, 0, 0]\n","  score_m = [0, 0, 0, 0]\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","      \n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      v_input_ids = batch[0].to(device)\n","      v_input_mask = batch[3].to(device)\n","      v_token_starts = batch[1].to(device)\n","      v_labels = batch[2].to(device)\n","      v_sent_length = batch[4]\n","            \n","      # Telling the model not to compute or store gradients, saving memory and\n","      # speeding up validation\n","      with torch.no_grad():        \n","          output = model(v_input_ids, v_input_mask, v_labels, v_token_starts, v_sent_length)\n","      \n","      pred_labels = output[1]\n","\n","      pred_labels = pred_labels.detach().cpu().numpy()\n","      v_labels = v_labels.to('cpu').numpy()\n","      # print(pred_labels[0])\n","      # print(v_labels[0])\n","      \n","      pred_labels, v_labels = fix_padding(pred_labels, v_labels, v_sent_length)\n","      # print(pred_labels[0])\n","      # print(v_labels[0])\n","\n","      batch_num_m, batch_score_m = match_M(pred_labels, v_labels)\n","      num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n","      score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n","  \n","  m_score = [i/j for i,j in zip(score_m, num_m)]\n","  print(\"Validation Accuracy: \")\n","  print(m_score)\n","  v_score = np.mean(m_score)\n","  print(v_score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMlk1zNN2ute","colab_type":"code","outputId":"14f9f6db-e289-46db-da1f-e4fcb95df817","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1582748002711,"user_tz":-330,"elapsed":3124759,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}}},"source":["\n","# import random\n","\n","# # Set the seed value all over the place to make this reproducible.\n","# seed_val = 42\n","\n","# random.seed(seed_val)\n","# np.random.seed(seed_val)\n","# torch.manual_seed(seed_val)\n","# torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","            \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[3].to(device)\n","        b_token_starts = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        b_sent_length = batch[4]\n","\n","        model.zero_grad()   \n","        model.train()     \n","\n","        output = model(b_input_ids, b_input_mask, b_labels, b_token_starts,b_sent_length)\n","        loss = output[0]\n","\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","        if step % 10 == 0:\n","          validation(model, validation_dataloader)\n","\n","    # Calculate the average loss over the training data.\n","    # print(\"total loss\",total_loss)\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.22959183673469388, 0.34748010610079577, 0.42329545454545453, 0.5015151515151515]\n","0.3754706372240239\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.48214285714285715, 0.6525198938992043, 0.7481060606060607, 0.7825757575757576]\n","0.6663361423059699\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.4923469387755102, 0.6830238726790451, 0.7490530303030302, 0.7909090909090909]\n","0.6788332331666691\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5255102040816326, 0.6962864721485411, 0.7765151515151515, 0.8068181818181818]\n","0.7012825023908767\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5816326530612245, 0.7307692307692307, 0.7926136363636364, 0.8212121212121212]\n","0.7315569103515532\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5918367346938775, 0.7387267904509284, 0.7964015151515152, 0.8265151515151515]\n","0.7383700479528682\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6096938775510204, 0.746684350132626, 0.8030303030303031, 0.8265151515151515]\n","0.7464809205572753\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6147959183673469, 0.753315649867374, 0.8115530303030304, 0.8333333333333334]\n","0.7532494829677712\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6122448979591837, 0.7586206896551724, 0.8077651515151515, 0.8333333333333334]\n","0.7529910181157102\n","\n","  Average training loss: 0.53\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6173469387755102, 0.7692307692307693, 0.8096590909090909, 0.8416666666666667]\n","0.7594758663955092\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6301020408163265, 0.7718832891246684, 0.8115530303030302, 0.853030303030303]\n","0.766642165818582\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.625, 0.7705570291777188, 0.8162878787878789, 0.8477272727272728]\n","0.7648930451732177\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6403061224489796, 0.7705570291777188, 0.8257575757575758, 0.853030303030303]\n","0.7724127576036443\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6301020408163265, 0.7745358090185677, 0.8210227272727273, 0.8484848484848485]\n","0.7685363563981176\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6709183673469388, 0.7771883289124668, 0.8219696969696971, 0.8507575757575757]\n","0.7802084922466695\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6607142857142857, 0.7811671087533156, 0.8200757575757577, 0.8553030303030303]\n","0.7793150455865974\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6632653061224489, 0.7851458885941645, 0.838068181818182, 0.8568181818181818]\n","0.7858243895882443\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6709183673469388, 0.7838196286472149, 0.8285984848484849, 0.853030303030303]\n","0.7840916959682354\n","\n","  Average training loss: 0.50\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.673469387755102, 0.7851458885941645, 0.831439393939394, 0.8575757575757575]\n","0.7869076069661045\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6785714285714286, 0.7838196286472149, 0.8352272727272729, 0.8545454545454545]\n","0.7880409461228427\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6785714285714286, 0.7771883289124668, 0.8352272727272727, 0.8515151515151516]\n","0.7856255454315799\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6836734693877551, 0.7811671087533156, 0.8371212121212124, 0.8545454545454545]\n","0.7891268112019344\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6760204081632653, 0.7838196286472149, 0.838068181818182, 0.8568181818181818]\n","0.7886816001117111\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6785714285714286, 0.7785145888594165, 0.838068181818182, 0.8553030303030303]\n","0.7876143073880144\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6836734693877551, 0.773209549071618, 0.8380681818181818, 0.8583333333333333]\n","0.788321133402722\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7838196286472149, 0.8428030303030304, 0.8590909090909091]\n","0.7961732899694722\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7931034482758621, 0.8399621212121214, 0.8613636363636363]\n","0.7983521994220887\n","\n","  Average training loss: 0.49\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7917771883289124, 0.8399621212121214, 0.8636363636363636]\n","0.7985888162535331\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7824933687002652, 0.837121212121212, 0.8545454545454545]\n","0.7926471516988758\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7877984084880637, 0.8314393939393941, 0.8545454545454545]\n","0.7944662224064933\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7891246684350133, 0.8352272727272727, 0.8606060606060606]\n","0.7959843984012702\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7957559681697612, 0.8409090909090909, 0.8636363636363636]\n","0.8010957638420693\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7891246684350133, 0.8371212121212122, 0.8575757575757575]\n","0.7957003074921793\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.84375, 0.8537878787878788]\n","0.8012063854659297\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7957559681697612, 0.8390151515151515, 0.8651515151515151]\n","0.8010010668723723\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.7917771883289124, 0.8371212121212122, 0.8621212121212121]\n","0.7994130664081402\n","\n","  Average training loss: 0.47\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7997347480106101, 0.8352272727272727, 0.8613636363636363]\n","0.8045661081529307\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7877984084880637, 0.8229166666666667, 0.8507575757575757]\n","0.7933018361974642\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7970822281167109, 0.8295454545454546, 0.8553030303030303]\n","0.7977785966086459\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7984084880636605, 0.8333333333333335, 0.8545454545454545]\n","0.7963167169447958\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.701530612244898, 0.7944297082228117, 0.8314393939393938, 0.8515151515151516]\n","0.7947287164805638\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6938775510204082, 0.7917771883289124, 0.8333333333333333, 0.8522727272727273]\n","0.7928151999888453\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.8023872679045093, 0.8418560606060606, 0.8560606060606061]\n","0.7998208816019776\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6760204081632653, 0.7970822281167109, 0.8333333333333333, 0.8560606060606061]\n","0.7906241439184788\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7891246684350133, 0.8295454545454546, 0.8537878787878788]\n","0.7922216432992295\n","\n","  Average training loss: 0.47\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6938775510204082, 0.7931034482758621, 0.8333333333333333, 0.8568181818181818]\n","0.7942831286119464\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.8010610079575596, 0.8380681818181818, 0.8560606060606061]\n","0.7985423469182705\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.8010610079575596, 0.8352272727272727, 0.8606060606060606]\n","0.8021572587921109\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7970822281167109, 0.837121212121212, 0.853030303030303]\n","0.8010176194905259\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7891246684350133, 0.8361742424242423, 0.8537878787878788]\n","0.7970676157791305\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7824933687002652, 0.8276515151515152, 0.8484848484848485]\n","0.7919533514515041\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.786472148541114, 0.8295454545454544, 0.8522727272727273]\n","0.7930929907530893\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.701530612244898, 0.7904509283819628, 0.8333333333333335, 0.8553030303030303]\n","0.7951544760658062\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7824933687002652, 0.8304924242424243, 0.853030303030303]\n","0.790611166850391\n","\n","  Average training loss: 0.46\n","\n","======== Epoch 7 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7877984084880637, 0.8304924242424243, 0.8522727272727273]\n","0.7923857879599876\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6862244897959183, 0.7824933687002652, 0.8323863636363636, 0.8613636363636363]\n","0.7906169646240458\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.701530612244898, 0.7851458885941645, 0.8333333333333335, 0.8613636363636363]\n","0.795343367634008\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7891246684350133, 0.8304924242424243, 0.8613636363636363]\n","0.7994543659337379\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7851458885941645, 0.8304924242424243, 0.853030303030303]\n","0.7951008274361108\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6862244897959183, 0.786472148541114, 0.8285984848484848, 0.8537878787878788]\n","0.788770750493349\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6836734693877551, 0.7877984084880637, 0.8342803030303031, 0.8560606060606061]\n","0.790453196741682\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6836734693877551, 0.7904509283819628, 0.831439393939394, 0.8575757575757575]\n","0.7907848873212173\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7838196286472149, 0.8304924242424243, 0.8613636363636363]\n","0.7930260651704617\n","\n","  Average training loss: 0.45\n","\n","======== Epoch 8 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7944297082228117, 0.8276515151515151, 0.8598484848484849]\n","0.7965028352189683\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8257575757575757, 0.8537878787878788]\n","0.7954327692012422\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7944297082228117, 0.8285984848484849, 0.8560606060606061]\n","0.795792607946241\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7891246684350133, 0.8257575757575758, 0.8553030303030303]\n","0.7935667267871702\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7904509283819628, 0.8276515151515152, 0.8575757575757575]\n","0.7936644482364925\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7984084880636605, 0.8257575757575758, 0.8553030303030303]\n","0.7978009470004545\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7917771883289124, 0.8267045454545454, 0.8553030303030303]\n","0.7970176195930506\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8200757575757575, 0.853030303030303]\n","0.7954299959072126\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.7957559681697612, 0.8229166666666667, 0.8590909090909091]\n","0.7960990492471405\n","\n","  Average training loss: 0.45\n","\n","======== Epoch 9 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7931034482758621, 0.8295454545454546, 0.8560606060606061]\n","0.7937845200776236\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6964285714285714, 0.7851458885941645, 0.831439393939394, 0.8545454545454545]\n","0.7918898271268962\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.786472148541114, 0.8342803030303031, 0.8606060606060606]\n","0.7969977913096755\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.7891246684350133, 0.8304924242424243, 0.8553030303030303]\n","0.7953881940104232\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7824933687002652, 0.8295454545454547, 0.853030303030303]\n","0.7910121795281894\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7877984084880637, 0.8314393939393941, 0.8560606060606061]\n","0.7961205204893629\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6989795918367347, 0.7851458885941645, 0.8285984848484849, 0.8568181818181818]\n","0.7923855367743915\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7931034482758621, 0.8257575757575758, 0.8515151515151516]\n","0.7948899622544943\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7970822281167109, 0.8257575757575758, 0.8560606060606061]\n","0.7989342861571925\n","\n","  Average training loss: 0.45\n","\n","======== Epoch 10 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7944297082228117, 0.8276515151515152, 0.853030303030303]\n","0.7960737999685044\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7970822281167109, 0.8267045454545456, 0.8575757575757575]\n","0.7976365511541004\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7891246684350133, 0.8285984848484849, 0.8553030303030303]\n","0.7974657295701015\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7931034482758621, 0.8323863636363638, 0.8553030303030303]\n","0.7987696391252427\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7891246684350133, 0.8257575757575758, 0.8522727272727273]\n","0.7947224163357169\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.786472148541114, 0.8352272727272727, 0.8545454545454545]\n","0.7950816271167256\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7851458885941645, 0.8333333333333333, 0.8553030303030303]\n","0.7963792365270198\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.786472148541114, 0.8342803030303031, 0.8568181818181818]\n","0.7954130665106651\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.786472148541114, 0.8285984848484849, 0.8560606060606061]\n","0.7950787282298981\n","\n","  Average training loss: 0.44\n","\n","======== Epoch 11 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8276515151515152, 0.8590909090909091]\n","0.7975382017407879\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8285984848484849, 0.8575757575757575]\n","0.7973961562862425\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7891246684350133, 0.825757575757576, 0.8537878787878788]\n","0.794463449112464\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.786472148541114, 0.8323863636363638, 0.8545454545454545]\n","0.7988356855582841\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.786472148541114, 0.8333333333333335, 0.8553030303030303]\n","0.7998995770239613\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7931034482758621, 0.8323863636363636, 0.8515151515151516]\n","0.7997359347343954\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7346938775510204, 0.7891246684350133, 0.8304924242424243, 0.8598484848484849]\n","0.8035398637692357\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7917771883289124, 0.8285984848484849, 0.8522727272727273]\n","0.799284549092123\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7891246684350133, 0.8295454545454546, 0.8613636363636363]\n","0.8004931337135771\n","\n","  Average training loss: 0.44\n","\n","======== Epoch 12 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.786472148541114, 0.8285984848484849, 0.8590909090909091]\n","0.7990250794976781\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7904509283819628, 0.8257575757575757, 0.8560606060606061]\n","0.7998274816316687\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7321428571428571, 0.7931034482758621, 0.8229166666666667, 0.8568181818181818]\n","0.8012452884758919\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7944297082228117, 0.8229166666666667, 0.8537878787878788]\n","0.7976305021948495\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8285984848484849, 0.8560606060606061]\n","0.7995937636870518\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7891246684350133, 0.8323863636363638, 0.8522727272727273]\n","0.796379613305414\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.786472148541114, 0.8257575757575758, 0.8568181818181818]\n","0.7964711602026873\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8219696969696972, 0.8522727272727273]\n","0.7944132017407881\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7944297082228117, 0.819128787878788, 0.8507575757575757]\n","0.7940126914341816\n","\n","  Average training loss: 0.44\n","\n","======== Epoch 13 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7904509283819628, 0.8248106060606062, 0.853030303030303]\n","0.794368877735565\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7931034482758621, 0.8276515151515152, 0.8545454545454545]\n","0.7948455126564733\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8333333333333335, 0.8568181818181818]\n","0.7980842843527574\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7904509283819628, 0.8276515151515151, 0.8545454545454545]\n","0.7967334030911617\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7838196286472149, 0.8276515151515151, 0.853030303030303]\n","0.7946967902786869\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7798408488063661, 0.8219696969696972, 0.853030303030303]\n","0.7935571509771018\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.786472148541114, 0.8219696969696971, 0.8522727272727273]\n","0.7950255819713947\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7891246684350133, 0.8219696969696968, 0.8522727272727273]\n","0.7969642221489512\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7944297082228117, 0.8229166666666667, 0.8575757575757575]\n","0.7992152269938599\n","\n","  Average training loss: 0.44\n","\n","======== Epoch 14 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7917771883289124, 0.8238636363636364, 0.8560606060606061]\n","0.7996855617699213\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7931034482758621, 0.8229166666666669, 0.8606060606060606]\n","0.8002789928667393\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7891246684350133, 0.8257575757575758, 0.8628787878787879]\n","0.8012004620994768\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7957559681697612, 0.8210227272727271, 0.8553030303030303]\n","0.7991428804159715\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7944297082228117, 0.8248106060606062, 0.8560606060606061]\n","0.7986721688615162\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7944297082228117, 0.8248106060606062, 0.8560606060606061]\n","0.7973966586574345\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7957559681697612, 0.8238636363636366, 0.8598484848484849]\n","0.8016272264271034\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7931034482758621, 0.8219696969696971, 0.8553030303030303]\n","0.7987164928667393\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7891246684350133, 0.8248106060606062, 0.853030303030303]\n","0.7985015984631133\n","\n","  Average training loss: 0.44\n","\n","======== Epoch 15 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7295918367346939, 0.7877984084880637, 0.824810606060606, 0.8553030303030303]\n","0.7993759703965985\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7904509283819628, 0.8267045454545454, 0.8537878787878788]\n","0.7975827769316068\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7957559681697612, 0.8257575757575757, 0.853030303030303]\n","0.7965696352087978\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7904509283819628, 0.819128787878788, 0.8522727272727273]\n","0.7914835190466349\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.701530612244898, 0.7917771883289124, 0.8181818181818183, 0.8507575757575757]\n","0.7905617986283011\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8248106060606062, 0.853030303030303]\n","0.7950066328376059\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7944297082228117, 0.8210227272727271, 0.8492424242424242]\n","0.792194123097756\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.786472148541114, 0.8219696969696969, 0.8515151515151516]\n","0.7916474125217967\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7811671087533156, 0.819128787878788, 0.8522727272727273]\n","0.7917135845476364\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 16 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7838196286472149, 0.8200757575757577, 0.8522727272727273]\n","0.7932512120473945\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7824933687002652, 0.8248106060606062, 0.8583333333333333]\n","0.7949807555949797\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7798408488063661, 0.8248106060606062, 0.85]\n","0.7922342922881717\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7851458885941645, 0.8257575757575758, 0.85]\n","0.7937972946593637\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7838196286472149, 0.8210227272727274, 0.8507575757575757]\n","0.7918336563887672\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7798408488063661, 0.8210227272727274, 0.853030303030303]\n","0.7920448983487777\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7824933687002652, 0.8229166666666665, 0.853030303030303]\n","0.7931815131707373\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7838196286472149, 0.8219696969696969, 0.8575757575757575]\n","0.7963259646757184\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.786472148541114, 0.8191287878787878, 0.8507575757575757]\n","0.7932988117178388\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 17 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7838196286472149, 0.8238636363636364, 0.853030303030303]\n","0.794387575683758\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7851458885941645, 0.8267045454545454, 0.85]\n","0.7959473023897286\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7931034482758621, 0.824810606060606, 0.8462121212121212]\n","0.7965162377646984\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7891246684350133, 0.8267045454545454, 0.8484848484848485]\n","0.7965632094711529\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7904509283819628, 0.8229166666666667, 0.8515151515151516]\n","0.7967053805184963\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7891246684350133, 0.8238636363636364, 0.8492424242424242]\n","0.7954046210357786\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.786472148541114, 0.8219696969696969, 0.8575757575757575]\n","0.7963513395471523\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7785145888594165, 0.8219696969696969, 0.8568181818181818]\n","0.7928970454832523\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7891246684350133, 0.8257575757575758, 0.8515151515151516]\n","0.797721797906527\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 18 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7931034482758621, 0.8257575757575757, 0.8492424242424242]\n","0.7975105559465165\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7957559681697612, 0.8229166666666667, 0.8560606060606061]\n","0.7985302489997687\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7917771883289124, 0.8276515151515152, 0.85]\n","0.7959286044415355\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7931034482758621, 0.8323863636363638, 0.853030303030303]\n","0.7994769675111424\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7877984084880637, 0.8304924242424243, 0.853030303030303]\n","0.7970394676136672\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7944297082228117, 0.824810606060606, 0.8537878787878788]\n","0.7987417421453751\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7321428571428571, 0.7917771883289124, 0.8238636363636364, 0.8515151515151516]\n","0.7998247083376393\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7917771883289124, 0.8248106060606062, 0.8545454545454545]\n","0.7995435163153759\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7838196286472149, 0.8248106060606062, 0.8560606060606061]\n","0.7960196489676169\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 19 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7851458885941645, 0.8229166666666667, 0.8590909090909091]\n","0.7966353048634454\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7811671087533156, 0.824810606060606, 0.85]\n","0.7944791225810315\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7798408488063661, 0.824810606060606, 0.8545454545454545]\n","0.7952839212306577\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7811671087533156, 0.8257575757575758, 0.8568181818181818]\n","0.7951449002557377\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7811671087533156, 0.8267045454545454, 0.8560606060606061]\n","0.7958300038426269\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7785145888594165, 0.824810606060606, 0.853030303030303]\n","0.7920225479569691\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8219696969696969, 0.8537878787878788]\n","0.7947919896195759\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7877984084880637, 0.8210227272727273, 0.8515151515151516]\n","0.7949310105944958\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.786472148541114, 0.8200757575757577, 0.8515151515151516]\n","0.794362703183516\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 20 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7877984084880637, 0.8219696969696971, 0.853030303030303]\n","0.7942710306934445\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7931034482758621, 0.8248106060606062, 0.8545454545454545]\n","0.79732406089395\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7917771883289124, 0.8219696969696971, 0.8537878787878788]\n","0.798006140001214\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8229166666666667, 0.853030303030303]\n","0.7958086581932026\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.786472148541114, 0.8238636363636364, 0.8545454545454545]\n","0.7954294935360205\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7270408163265306, 0.7851458885941645, 0.8229166666666667, 0.8553030303030303]\n","0.7976016004725981\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7877984084880637, 0.8229166666666667, 0.8575757575757575]\n","0.7969196469581321\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7904509283819628, 0.824810606060606, 0.8553030303030303]\n","0.7981258350639509\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7970822281167109, 0.8267045454545454, 0.8560606060606061]\n","0.799171028581435\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 21 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7944297082228117, 0.8295454545454546, 0.8515151515151516]\n","0.7987195173463646\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7891246684350133, 0.8267045454545454, 0.8522727272727273]\n","0.7949591587599594\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.831439393939394, 0.8560606060606061]\n","0.8003039909597791\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7931034482758621, 0.8304924242424243, 0.8522727272727273]\n","0.797538578519182\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8267045454545456, 0.8507575757575757]\n","0.7971567661607686\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7931034482758621, 0.8267045454545454, 0.853030303030303]\n","0.7980565129656878\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7944297082228117, 0.8267045454545454, 0.8507575757575757]\n","0.7971821410322025\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7997347480106101, 0.8323863636363638, 0.853030303030303]\n","0.8017725475468702\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7944297082228117, 0.8295454545454546, 0.8522727272727273]\n","0.7982711561837177\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 22 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7997347480106101, 0.8295454545454546, 0.8522727272727273]\n","0.7989596610286265\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7984084880636605, 0.8267045454545454, 0.8545454545454545]\n","0.7984860505873437\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7970822281167109, 0.8304924242424242, 0.8560606060606061]\n","0.798842488074323\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7957559681697612, 0.8304924242424242, 0.8583333333333333]\n","0.7997168600078083\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7931034482758621, 0.8276515151515151, 0.8537878787878788]\n","0.7965693840232018\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8238636363636364, 0.8553030303030303]\n","0.7969451474223642\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.786472148541114, 0.8172348484848485, 0.8537878787878788]\n","0.7923073924228481\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7877984084880637, 0.8210227272727273, 0.8515151515151516]\n","0.7930177452883733\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7838196286472149, 0.8229166666666667, 0.853030303030303]\n","0.7922375679533932\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 23 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7040816326530612, 0.7838196286472149, 0.824810606060606, 0.8522727272727273]\n","0.7912461486584024\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.786472148541114, 0.8257575757575758, 0.8515151515151516]\n","0.7938698924228481\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7877984084880637, 0.8257575757575757, 0.8537878787878788]\n","0.7941318841257266\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7931034482758621, 0.8248106060606062, 0.8545454545454545]\n","0.7954107955878276\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8229166666666665, 0.853030303030303]\n","0.7945331479891209\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.7917771883289124, 0.8238636363636364, 0.8537878787878788]\n","0.794015339135413\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7917771883289124, 0.8238636363636364, 0.8537878787878788]\n","0.7946530942374539\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7957559681697612, 0.8229166666666667, 0.8545454545454545]\n","0.7962381958148583\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7931034482758621, 0.8219696969696971, 0.8537878787878788]\n","0.7945111743757065\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 24 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7957559681697612, 0.819128787878788, 0.8484848484848485]\n","0.7963270950109005\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7931034482758621, 0.8219696969696971, 0.8537878787878788]\n","0.7976999498859105\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8219696969696969, 0.8537878787878788]\n","0.797368384899173\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7295918367346939, 0.7917771883289124, 0.8219696969696969, 0.8515151515151516]\n","0.7987134683871137\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7295918367346939, 0.7944297082228117, 0.8210227272727273, 0.8507575757575757]\n","0.7989504619969521\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7917771883289124, 0.8219696969696969, 0.8507575757575757]\n","0.7972485642436381\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8200757575757577, 0.85]\n","0.7953101752516778\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7917771883289124, 0.8219696969696971, 0.8515151515151516]\n","0.7974379581830321\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8257575757575758, 0.853030303030303]\n","0.7981259606567488\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 25 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7957559681697612, 0.8248106060606062, 0.8492424242424242]\n","0.7972991883937081\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7944297082228117, 0.8267045454545454, 0.8507575757575757]\n","0.7984576512362842\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7244897959183674, 0.7917771883289124, 0.8248106060606062, 0.85]\n","0.7977693975769715\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7931034482758621, 0.8257575757575758, 0.8545454545454545]\n","0.7981985584202332\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8229166666666665, 0.8507575757575757]\n","0.7952404763750206\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7917771883289124, 0.8219696969696971, 0.85]\n","0.794508149896081\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8210227272727273, 0.8484848484848485]\n","0.7941988097083541\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7877984084880637, 0.8200757575757577, 0.8492424242424242]\n","0.7934883312500308\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.786472148541114, 0.819128787878788, 0.8507575757575757]\n","0.7907477913096755\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 26 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7877984084880637, 0.8210227272727274, 0.8507575757575757]\n","0.7928283513489794\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7091836734693877, 0.7891246684350133, 0.8238636363636364, 0.85]\n","0.7930429945670093\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7877984084880637, 0.8210227272727273, 0.85]\n","0.7932767125116263\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7877984084880637, 0.8238636363636364, 0.8492424242424242]\n","0.7937975458449597\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8257575757575758, 0.85]\n","0.7947919896195759\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7877984084880637, 0.8257575757575758, 0.853030303030303]\n","0.7952180003904142\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7066326530612245, 0.7904509283819628, 0.8238636363636364, 0.8522727272727273]\n","0.7933049862698878\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7917771883289124, 0.8248106060606062, 0.8537878787878788]\n","0.795527591763737\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8219696969696971, 0.8515151515151516]\n","0.7951931278901723\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 27 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8229166666666667, 0.8522727272727273]\n","0.7943437540497271\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7877984084880637, 0.8210227272727273, 0.8522727272727273]\n","0.7944826494318491\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7117346938775511, 0.7904509283819628, 0.8229166666666667, 0.8553030303030303]\n","0.7951013298073029\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7917771883289124, 0.8210227272727273, 0.8545454545454545]\n","0.7954077711082022\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7931034482758621, 0.8219696969696971, 0.8545454545454545]\n","0.7959760785191821\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7891246684350133, 0.8238636363636364, 0.853030303030303]\n","0.7950760805286667\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8238636363636364, 0.853030303030303]\n","0.7960454006174449\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7877984084880637, 0.8257575757575758, 0.8522727272727273]\n","0.7950286064510204\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7877984084880637, 0.8257575757575758, 0.8507575757575757]\n","0.7952875736742732\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 28 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.786472148541114, 0.8248106060606062, 0.8492424242424242]\n","0.7943404783845055\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7877984084880637, 0.8238636363636366, 0.85]\n","0.7946246948863945\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7891246684350133, 0.8248106060606062, 0.8515151515151516]\n","0.7955717901761621\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7904509283819628, 0.824810606060606, 0.853030303030303]\n","0.7956443879396465\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7142857142857143, 0.7904509283819628, 0.8267045454545456, 0.8522727272727273]\n","0.7959284788487375\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7904509283819628, 0.8238636363636366, 0.8515151515151516]\n","0.7956666127386571\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7891246684350133, 0.8229166666666667, 0.85]\n","0.7947195174488894\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7891246684350133, 0.8229166666666667, 0.85]\n","0.7947195174488894\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8238636363636366, 0.8522727272727273]\n","0.7961875716647884\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 29 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8248106060606062, 0.8515151515151516]\n","0.7962349201496369\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7931034482758621, 0.8229166666666667, 0.85]\n","0.7969897226131833\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7931034482758621, 0.8238636363636366, 0.8507575757575757]\n","0.796140348772738\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7891246684350133, 0.8238636363636366, 0.85]\n","0.7962317700772136\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7891246684350133, 0.8248106060606062, 0.8507575757575757]\n","0.7966579064408499\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7904509283819628, 0.8248106060606062, 0.8507575757575757]\n","0.7969894714275871\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8248106060606062, 0.8515151515151516]\n","0.7975104303537186\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8276515151515152, 0.8522727272727273]\n","0.7971345413617581\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7964243140890308\n","\n","  Average training loss: 0.43\n","\n","======== Epoch 30 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7970620691910717\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.825757575757576, 0.8515151515151516]\n","0.7971094176759203\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8248106060606062, 0.8515151515151516]\n","0.7975104303537186\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7976998242931126\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7219387755102041, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7976998242931126\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7970620691910717\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8248106060606062, 0.8522727272727273]\n","0.7970620691910717\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7193877551020408, 0.7917771883289124, 0.8248106060606062, 0.8515151515151516]\n","0.7968726752516777\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.7168367346938775, 0.7917771883289124, 0.8248106060606062, 0.8515151515151516]\n","0.7962349201496369\n","\n","  Average training loss: 0.42\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YyrVHMBg3AW4","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwLxg7wN-nhf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}