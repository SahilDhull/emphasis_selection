{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_with_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjvac60KJvBU6TDmy0ESId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfe85996b7cf4921bed6f59da7dbed16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53e4407fc6d6441cb92b079e55da9067",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffe2577a8733407986ebab46577ecf0c",
              "IPY_MODEL_14ff7d4366f44d39a0a62b1d03cd062a"
            ]
          }
        },
        "53e4407fc6d6441cb92b079e55da9067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffe2577a8733407986ebab46577ecf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5ae75b34feb479b9a8b9f0b6ac4a82c",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_485423dd5071411e908ed16672d17c34"
          }
        },
        "14ff7d4366f44d39a0a62b1d03cd062a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2edf5cbfd981485fa43eaa37553446b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 2.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e9f2da4d2b442a3b2b400f40478b487"
          }
        },
        "c5ae75b34feb479b9a8b9f0b6ac4a82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "485423dd5071411e908ed16672d17c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2edf5cbfd981485fa43eaa37553446b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e9f2da4d2b442a3b2b400f40478b487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7ba0d340bdc4432b7c4722e4cc7a7fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea5fa7491acb44a3b5d20d9f42e8fc42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e63deaf85e545b7ae4f61769bab6f39",
              "IPY_MODEL_4233fa5aa61e4e0fbab4df6060af0057"
            ]
          }
        },
        "ea5fa7491acb44a3b5d20d9f42e8fc42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e63deaf85e545b7ae4f61769bab6f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77b7a85cecf74249a8e3a5415542d0a0",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61342e29d732405d950f2d560022b286"
          }
        },
        "4233fa5aa61e4e0fbab4df6060af0057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19aef08606dc47a5b844a171a11a5db7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 9.38kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b809ea81313c4c1c90ecc1a4584eee2b"
          }
        },
        "77b7a85cecf74249a8e3a5415542d0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61342e29d732405d950f2d560022b286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19aef08606dc47a5b844a171a11a5db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b809ea81313c4c1c90ecc1a4584eee2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "500ced834572403893a970667c51b840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a435b27160954732a4173871278bb323",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d406a64469c4470a922327b96b21ce32",
              "IPY_MODEL_1162a5ebf8e142f794c3ea91beff8486"
            ]
          }
        },
        "a435b27160954732a4173871278bb323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d406a64469c4470a922327b96b21ce32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb839962f59d497ea02acaa476c34ab4",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1332a399161149ed9a6c9d85b9240e2b"
          }
        },
        "1162a5ebf8e142f794c3ea91beff8486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cc9ee443b3d4c24b807e1bbe6ee826a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:05&lt;00:00, 74.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a60c1cadda645ad9295ff25ef4fe4b6"
          }
        },
        "cb839962f59d497ea02acaa476c34ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1332a399161149ed9a6c9d85b9240e2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cc9ee443b3d4c24b807e1bbe6ee826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a60c1cadda645ad9295ff25ef4fe4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilDhull/emphasis_selection/blob/master/model/bert_with_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw-WHt68c4q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "107c4ba8-5cee-4d22-931a-6894d7127d54"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install config"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\r\u001b[K     |▊                               | 10kB 29.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 450kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 460kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 471kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 481kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 27.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=41a9dafad1097b5edcf5ff1cc5041a33f4e4a621f59644be95a395b648b96fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n",
            "Collecting config\n",
            "  Downloading https://files.pythonhosted.org/packages/59/6c/4ab0d80b22dca3baab49670b75ae2183b59649e9f27c11018075e509048e/config-0.4.2.tar.gz\n",
            "Building wheels for collected packages: config\n",
            "  Building wheel for config (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for config: filename=config-0.4.2-cp36-none-any.whl size=15134 sha256=69558f01574a41b4a7b5be372540fd62387455155ed45e8e8a9a9c2d31a6ddce\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/7d/db/0e38d2ec57843d00cc39f8df3686984ccec689694f7bc78a38\n",
            "Successfully built config\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m55-6V8SdEhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "2ffc71c6-0587-4d52-9ae6-0b85069388b0"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForMaskedLM , BertModel ,WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import codecs"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Kg45-AdHcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4eadc631-a0fb-49c5-8fe0-77bdc478e370"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ThL71gXdKlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "57b4e8cd-c857-4e56-884a-083b185d1f01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/datasets/train.txt'\n",
        "dev_file = 'drive/My Drive/datasets/dev.txt'\n",
        "\n",
        "quotes_file = 'drive/My Drive/datasets/all_quotes.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Oj5o9adYRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_sent(file, caseless = True):\n",
        "    \n",
        "    with codecs.open(file, 'r', 'utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    #print(lines)\n",
        "    sent = \"\"\n",
        "    sents = []\n",
        "    \n",
        "    for line in lines:\n",
        "        if not (line.isspace()):\n",
        "            feats = line.strip().split()\n",
        "            word = feats[0].lower() if caseless else feats[0]\n",
        "            if(word == \"n't\"):\n",
        "              word = \"'t\"\n",
        "              sent = sent + \"n\"\n",
        "            sent = sent + \" \" + word\n",
        "        elif len(sent) > 0:\n",
        "            sents.append(sent.strip())\n",
        "            sent = \"\"\n",
        "            \n",
        "    if len(sent) > 0:\n",
        "        sents.append(sent)\n",
        "    \n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOVwHCdUdj8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "bfe85996b7cf4921bed6f59da7dbed16",
            "53e4407fc6d6441cb92b079e55da9067",
            "ffe2577a8733407986ebab46577ecf0c",
            "14ff7d4366f44d39a0a62b1d03cd062a",
            "c5ae75b34feb479b9a8b9f0b6ac4a82c",
            "485423dd5071411e908ed16672d17c34",
            "2edf5cbfd981485fa43eaa37553446b7",
            "2e9f2da4d2b442a3b2b400f40478b487"
          ]
        },
        "outputId": "fd64d241-e6d4-4816-ae5a-d8091b60e47b"
      },
      "source": [
        "sentences = read_sent(quotes_file)\n",
        "print(sentences[0])\n",
        "print(sentences[100])\n",
        "\n",
        "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in sentences]\n",
        "print(sentences[0])\n",
        "print(sentences[100])\n",
        "\n",
        "# Tokenize with BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (tokenized_texts[0])\n",
        "print (tokenized_texts[100])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you know you 're in love when you can 't fall asleep because reality is finally better than your dreams .\n",
            "a half-read book is a half-finished love affair .\n",
            "[CLS] you know you 're in love when you can 't fall asleep because reality is finally better than your dreams . [SEP]\n",
            "[CLS] a half-read book is a half-finished love affair . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfe85996b7cf4921bed6f59da7dbed16",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['[CLS]', 'you', 'know', 'you', \"'\", 're', 'in', 'love', 'when', 'you', 'can', \"'\", 't', 'fall', 'asleep', 'because', 'reality', 'is', 'finally', 'better', 'than', 'your', 'dreams', '.', '[SEP]']\n",
            "['[CLS]', 'a', 'half', '-', 'read', 'book', 'is', 'a', 'half', '-', 'finished', 'love', 'affair', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63A92mIqdnZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df63ca06-8d93-4e98-d263-cad1e30cd9df"
      },
      "source": [
        "MAX_LEN = 36\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])\n",
        "print(input_ids[100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 101 2017 2113 2017 1005 2128 1999 2293 2043 2017 2064 1005 1056 2991\n",
            " 6680 2138 4507 2003 2633 2488 2084 2115 5544 1012  102    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "[ 101 1037 2431 1011 3191 2338 2003 1037 2431 1011 2736 2293 6771 1012\n",
            "  102    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic9QrWZ7fIhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6f5742bd-b1e4-4767-90b8-e916053ccfe1"
      },
      "source": [
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "print(attention_masks[0])\n",
        "print(attention_masks[100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPm_54FwfL0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs = train_test_split(input_ids, random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "                                             \n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# Select a batch size for training. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVqKx1jmVfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_tokens(inputs, tokenizer, mlm_probability = 0.15):\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "    labels = inputs.clone()\n",
        "    # print(inputs[0])\n",
        "\n",
        "    # We sample a few tokens in each sequence for masked-LM training (with probability mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    special_tokens_mask = [tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()]\n",
        "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        " \n",
        "    if tokenizer._pad_token is not None:\n",
        "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
        "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
        "\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrHN1mVqeUVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gU-4T0d4Jjr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "c7ba0d340bdc4432b7c4722e4cc7a7fd",
            "ea5fa7491acb44a3b5d20d9f42e8fc42",
            "1e63deaf85e545b7ae4f61769bab6f39",
            "4233fa5aa61e4e0fbab4df6060af0057",
            "77b7a85cecf74249a8e3a5415542d0a0",
            "61342e29d732405d950f2d560022b286",
            "19aef08606dc47a5b844a171a11a5db7",
            "b809ea81313c4c1c90ecc1a4584eee2b",
            "500ced834572403893a970667c51b840",
            "a435b27160954732a4173871278bb323",
            "d406a64469c4470a922327b96b21ce32",
            "1162a5ebf8e142f794c3ea91beff8486",
            "cb839962f59d497ea02acaa476c34ab4",
            "1332a399161149ed9a6c9d85b9240e2b",
            "2cc9ee443b3d4c24b807e1bbe6ee826a",
            "7a60c1cadda645ad9295ff25ef4fe4b6"
          ]
        },
        "outputId": "8adae11e-4986-4459-dfbf-93f4b2389ab7"
      },
      "source": [
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model = model.to(device)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7ba0d340bdc4432b7c4722e4cc7a7fd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "500ced834572403893a970667c51b840",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHyzgYhKG3WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 4\n",
        "max_steps = len(train_dataloader)*max_epochs\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
        "    ]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters,lr = 1e-4)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=max_steps/20, num_training_steps=max_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcGSLSve3DJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, tokenizer, validation_dataloader):\n",
        "  total_loss = 0\n",
        "  steps = len(validation_dataloader)\n",
        "  model.eval()\n",
        "  \n",
        "  corrects = 0\n",
        "  errors = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (val_inputs, val_masks) in enumerate(validation_dataloader):\n",
        "      inputs, labels = mask_tokens(val_inputs, tokenizer)\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      val_masks = val_masks.to(device)\n",
        "      \n",
        "      output = model(inputs,attention_mask = val_masks)\n",
        "      predict = output[0]\n",
        "\n",
        "      batch_size = predict.size()[0]\n",
        "\n",
        "      for bs in range(batch_size):\n",
        "        ii = 0\n",
        "        for ls in labels[bs]:\n",
        "          ls = ls.item()\n",
        "          if ls!=-100:\n",
        "            predicted = torch.argmax(predict[bs][ii]).item()\n",
        "            if(ls == predicted):\n",
        "              corrects = corrects + 1\n",
        "            else:\n",
        "              errors = errors + 1\n",
        "          ii = ii + 1\n",
        "\n",
        "  total = corrects + errors\n",
        "  accuracy = corrects/total\n",
        "  print(\"\\nvalidation accuracy = \",accuracy,\"\\t for\",total,\"masks on validation data\\n\")\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N4kQ8kXFOrfY",
        "colab": {}
      },
      "source": [
        "def train(train_dataloader,validation_dataloader, model, tokenizer, optimizer, scheduler, max_epochs, print_freq = 30,val_freq = 666):\n",
        "  \n",
        "  model.zero_grad()\n",
        "  steps = len(train_dataloader)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    \n",
        "    evaluate(model, tokenizer, validation_dataloader)\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (train_inputs, train_masks) in enumerate(train_dataloader):\n",
        "      inputs, labels = mask_tokens(train_inputs, tokenizer)\n",
        "      model.train()\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      train_masks = train_masks.to(device)\n",
        "      \n",
        "      output = model(inputs,attention_mask = train_masks, masked_lm_labels=labels)\n",
        "      loss = output[0]\n",
        "      total_loss = total_loss + loss\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      model.zero_grad()\n",
        "\n",
        "      if((i+1)%print_freq==0):\n",
        "        avg_loss = total_loss/print_freq\n",
        "        total_loss = 0\n",
        "        print(\"epoch:\",(epoch+1),\"out of\",max_epochs,\"\\t batch:\",(i+1),\"out of\",steps,\"\\t average loss:\",avg_loss)   \n",
        "      \n",
        "      if((i+1)%val_freq==0):\n",
        "        evaluate(model, tokenizer, validation_dataloader)\n",
        "  \n",
        "  evaluate(model, tokenizer, validation_dataloader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPRSboo07YL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ebd13693-1636-4120-cb22-1f976cb1f8bc"
      },
      "source": [
        "train(train_dataloader,validation_dataloader, model, tokenizer, optimizer, scheduler, max_epochs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation accuracy =  0.5178290108922128 \t for 59033 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 30 out of 6633 \t average loss: tensor(2.9850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 60 out of 6633 \t average loss: tensor(3.2516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 90 out of 6633 \t average loss: tensor(3.1796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 120 out of 6633 \t average loss: tensor(2.9389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 150 out of 6633 \t average loss: tensor(3.1702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 180 out of 6633 \t average loss: tensor(3.0323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 210 out of 6633 \t average loss: tensor(3.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 240 out of 6633 \t average loss: tensor(3.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 270 out of 6633 \t average loss: tensor(3.0121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 300 out of 6633 \t average loss: tensor(2.9277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 330 out of 6633 \t average loss: tensor(2.9679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 360 out of 6633 \t average loss: tensor(3.0710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 390 out of 6633 \t average loss: tensor(3.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 420 out of 6633 \t average loss: tensor(3.0046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 450 out of 6633 \t average loss: tensor(2.8625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 480 out of 6633 \t average loss: tensor(2.7701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 510 out of 6633 \t average loss: tensor(2.9267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 540 out of 6633 \t average loss: tensor(2.8532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 570 out of 6633 \t average loss: tensor(2.8804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 600 out of 6633 \t average loss: tensor(2.7332, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 630 out of 6633 \t average loss: tensor(2.7164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 660 out of 6633 \t average loss: tensor(2.7163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5455861810500494 \t for 58702 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 690 out of 6633 \t average loss: tensor(2.9412, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 720 out of 6633 \t average loss: tensor(2.6473, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 750 out of 6633 \t average loss: tensor(2.6569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 780 out of 6633 \t average loss: tensor(2.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 810 out of 6633 \t average loss: tensor(2.9112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 840 out of 6633 \t average loss: tensor(2.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 870 out of 6633 \t average loss: tensor(2.7702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 900 out of 6633 \t average loss: tensor(2.6348, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 930 out of 6633 \t average loss: tensor(2.7224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 960 out of 6633 \t average loss: tensor(2.6666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 990 out of 6633 \t average loss: tensor(2.6929, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1020 out of 6633 \t average loss: tensor(2.7276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1050 out of 6633 \t average loss: tensor(2.7718, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1080 out of 6633 \t average loss: tensor(2.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1110 out of 6633 \t average loss: tensor(2.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1140 out of 6633 \t average loss: tensor(2.6518, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1170 out of 6633 \t average loss: tensor(2.6742, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1200 out of 6633 \t average loss: tensor(2.7840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1230 out of 6633 \t average loss: tensor(2.6281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1260 out of 6633 \t average loss: tensor(2.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1290 out of 6633 \t average loss: tensor(2.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1320 out of 6633 \t average loss: tensor(2.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5618455052359581 \t for 58824 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 1350 out of 6633 \t average loss: tensor(2.6121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1380 out of 6633 \t average loss: tensor(2.6905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1410 out of 6633 \t average loss: tensor(2.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1440 out of 6633 \t average loss: tensor(2.7000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1470 out of 6633 \t average loss: tensor(2.6484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1500 out of 6633 \t average loss: tensor(2.6729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1530 out of 6633 \t average loss: tensor(2.6633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1560 out of 6633 \t average loss: tensor(2.7285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1590 out of 6633 \t average loss: tensor(2.6052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1620 out of 6633 \t average loss: tensor(2.5113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1650 out of 6633 \t average loss: tensor(2.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1680 out of 6633 \t average loss: tensor(2.5884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1710 out of 6633 \t average loss: tensor(2.5236, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1740 out of 6633 \t average loss: tensor(2.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1770 out of 6633 \t average loss: tensor(2.4626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1800 out of 6633 \t average loss: tensor(2.6458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1830 out of 6633 \t average loss: tensor(2.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1860 out of 6633 \t average loss: tensor(2.7140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1890 out of 6633 \t average loss: tensor(2.6229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1920 out of 6633 \t average loss: tensor(2.6206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1950 out of 6633 \t average loss: tensor(2.5043, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 1980 out of 6633 \t average loss: tensor(2.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5638458792936417 \t for 58837 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 2010 out of 6633 \t average loss: tensor(2.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2040 out of 6633 \t average loss: tensor(2.6075, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2070 out of 6633 \t average loss: tensor(2.4707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2100 out of 6633 \t average loss: tensor(2.6265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2130 out of 6633 \t average loss: tensor(2.5356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2160 out of 6633 \t average loss: tensor(2.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2190 out of 6633 \t average loss: tensor(2.6859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2220 out of 6633 \t average loss: tensor(2.4982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2250 out of 6633 \t average loss: tensor(2.5726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2280 out of 6633 \t average loss: tensor(2.5062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2310 out of 6633 \t average loss: tensor(2.5279, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2340 out of 6633 \t average loss: tensor(2.5928, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2370 out of 6633 \t average loss: tensor(2.5641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2400 out of 6633 \t average loss: tensor(2.5769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2430 out of 6633 \t average loss: tensor(2.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2460 out of 6633 \t average loss: tensor(2.6809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2490 out of 6633 \t average loss: tensor(2.5054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2520 out of 6633 \t average loss: tensor(2.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2550 out of 6633 \t average loss: tensor(2.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2580 out of 6633 \t average loss: tensor(2.5669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2610 out of 6633 \t average loss: tensor(2.4837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2640 out of 6633 \t average loss: tensor(2.5239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5650020286718961 \t for 59152 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 2670 out of 6633 \t average loss: tensor(2.4738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2700 out of 6633 \t average loss: tensor(2.4965, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2730 out of 6633 \t average loss: tensor(2.6106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2760 out of 6633 \t average loss: tensor(2.4472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2790 out of 6633 \t average loss: tensor(2.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2820 out of 6633 \t average loss: tensor(2.4691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2850 out of 6633 \t average loss: tensor(2.5331, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2880 out of 6633 \t average loss: tensor(2.6561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2910 out of 6633 \t average loss: tensor(2.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2940 out of 6633 \t average loss: tensor(2.5360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 2970 out of 6633 \t average loss: tensor(2.6650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3000 out of 6633 \t average loss: tensor(2.4401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3030 out of 6633 \t average loss: tensor(2.4174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3060 out of 6633 \t average loss: tensor(2.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3090 out of 6633 \t average loss: tensor(2.5617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3120 out of 6633 \t average loss: tensor(2.5679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3150 out of 6633 \t average loss: tensor(2.5457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3180 out of 6633 \t average loss: tensor(2.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3210 out of 6633 \t average loss: tensor(2.4148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3240 out of 6633 \t average loss: tensor(2.3720, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3270 out of 6633 \t average loss: tensor(2.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3300 out of 6633 \t average loss: tensor(2.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3330 out of 6633 \t average loss: tensor(2.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.566995936548957 \t for 58817 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 3360 out of 6633 \t average loss: tensor(2.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3390 out of 6633 \t average loss: tensor(2.5230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3420 out of 6633 \t average loss: tensor(2.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3450 out of 6633 \t average loss: tensor(2.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3480 out of 6633 \t average loss: tensor(2.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3510 out of 6633 \t average loss: tensor(2.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3540 out of 6633 \t average loss: tensor(2.5526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3570 out of 6633 \t average loss: tensor(2.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3600 out of 6633 \t average loss: tensor(2.6040, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3630 out of 6633 \t average loss: tensor(2.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3660 out of 6633 \t average loss: tensor(2.5142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3690 out of 6633 \t average loss: tensor(2.5904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3720 out of 6633 \t average loss: tensor(2.5764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3750 out of 6633 \t average loss: tensor(2.5275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3780 out of 6633 \t average loss: tensor(2.4509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3810 out of 6633 \t average loss: tensor(2.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3840 out of 6633 \t average loss: tensor(2.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3870 out of 6633 \t average loss: tensor(2.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3900 out of 6633 \t average loss: tensor(2.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3930 out of 6633 \t average loss: tensor(2.5048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3960 out of 6633 \t average loss: tensor(2.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 3990 out of 6633 \t average loss: tensor(2.5001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5646233132162474 \t for 58988 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 4020 out of 6633 \t average loss: tensor(2.4681, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4050 out of 6633 \t average loss: tensor(2.5392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4080 out of 6633 \t average loss: tensor(2.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4110 out of 6633 \t average loss: tensor(2.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4140 out of 6633 \t average loss: tensor(2.4403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4170 out of 6633 \t average loss: tensor(2.6428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4200 out of 6633 \t average loss: tensor(2.5391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4230 out of 6633 \t average loss: tensor(2.6867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4260 out of 6633 \t average loss: tensor(2.4389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4290 out of 6633 \t average loss: tensor(2.3144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4320 out of 6633 \t average loss: tensor(2.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4350 out of 6633 \t average loss: tensor(2.5734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4380 out of 6633 \t average loss: tensor(2.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4410 out of 6633 \t average loss: tensor(2.6345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4440 out of 6633 \t average loss: tensor(2.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4470 out of 6633 \t average loss: tensor(2.6166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4500 out of 6633 \t average loss: tensor(2.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4530 out of 6633 \t average loss: tensor(2.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4560 out of 6633 \t average loss: tensor(2.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4590 out of 6633 \t average loss: tensor(2.4488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4620 out of 6633 \t average loss: tensor(2.5085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4650 out of 6633 \t average loss: tensor(2.5189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5665384419853926 \t for 59011 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 4680 out of 6633 \t average loss: tensor(2.5108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4710 out of 6633 \t average loss: tensor(2.4756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4740 out of 6633 \t average loss: tensor(2.5795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4770 out of 6633 \t average loss: tensor(2.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4800 out of 6633 \t average loss: tensor(2.5105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4830 out of 6633 \t average loss: tensor(2.3450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4860 out of 6633 \t average loss: tensor(2.4266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4890 out of 6633 \t average loss: tensor(2.6825, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4920 out of 6633 \t average loss: tensor(2.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4950 out of 6633 \t average loss: tensor(2.5702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 4980 out of 6633 \t average loss: tensor(2.4251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5010 out of 6633 \t average loss: tensor(2.2857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5040 out of 6633 \t average loss: tensor(2.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5070 out of 6633 \t average loss: tensor(2.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5100 out of 6633 \t average loss: tensor(2.4730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5130 out of 6633 \t average loss: tensor(2.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5160 out of 6633 \t average loss: tensor(2.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5190 out of 6633 \t average loss: tensor(2.4126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5220 out of 6633 \t average loss: tensor(2.4977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5250 out of 6633 \t average loss: tensor(2.4411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5280 out of 6633 \t average loss: tensor(2.3962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5310 out of 6633 \t average loss: tensor(2.3234, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5669513730561132 \t for 58774 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 5340 out of 6633 \t average loss: tensor(2.3960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5370 out of 6633 \t average loss: tensor(2.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5400 out of 6633 \t average loss: tensor(2.4466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5430 out of 6633 \t average loss: tensor(2.4958, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5460 out of 6633 \t average loss: tensor(2.4332, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5490 out of 6633 \t average loss: tensor(2.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5520 out of 6633 \t average loss: tensor(2.4794, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5550 out of 6633 \t average loss: tensor(2.5074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5580 out of 6633 \t average loss: tensor(2.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5610 out of 6633 \t average loss: tensor(2.5905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5640 out of 6633 \t average loss: tensor(2.3934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5670 out of 6633 \t average loss: tensor(2.4564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5700 out of 6633 \t average loss: tensor(2.4524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5730 out of 6633 \t average loss: tensor(2.5470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5760 out of 6633 \t average loss: tensor(2.5138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5790 out of 6633 \t average loss: tensor(2.3270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5820 out of 6633 \t average loss: tensor(2.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5850 out of 6633 \t average loss: tensor(2.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5880 out of 6633 \t average loss: tensor(2.5722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5910 out of 6633 \t average loss: tensor(2.5654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5940 out of 6633 \t average loss: tensor(2.3130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 5970 out of 6633 \t average loss: tensor(2.5199, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5700245700245701 \t for 59015 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 6000 out of 6633 \t average loss: tensor(2.5883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6030 out of 6633 \t average loss: tensor(2.5836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6060 out of 6633 \t average loss: tensor(2.5059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6090 out of 6633 \t average loss: tensor(2.4304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6120 out of 6633 \t average loss: tensor(2.4749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6150 out of 6633 \t average loss: tensor(2.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6180 out of 6633 \t average loss: tensor(2.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6210 out of 6633 \t average loss: tensor(2.4131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6240 out of 6633 \t average loss: tensor(2.5158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6270 out of 6633 \t average loss: tensor(2.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6300 out of 6633 \t average loss: tensor(2.4340, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6330 out of 6633 \t average loss: tensor(2.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6360 out of 6633 \t average loss: tensor(2.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6390 out of 6633 \t average loss: tensor(2.4902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6420 out of 6633 \t average loss: tensor(2.4803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6450 out of 6633 \t average loss: tensor(2.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6480 out of 6633 \t average loss: tensor(2.3715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6510 out of 6633 \t average loss: tensor(2.5278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6540 out of 6633 \t average loss: tensor(2.5064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6570 out of 6633 \t average loss: tensor(2.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6600 out of 6633 \t average loss: tensor(2.4058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 6630 out of 6633 \t average loss: tensor(2.4693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5682992107192172 \t for 58661 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 30 out of 6633 \t average loss: tensor(2.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 60 out of 6633 \t average loss: tensor(2.4852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 90 out of 6633 \t average loss: tensor(2.4211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 120 out of 6633 \t average loss: tensor(2.4596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 150 out of 6633 \t average loss: tensor(2.5201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 180 out of 6633 \t average loss: tensor(2.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 210 out of 6633 \t average loss: tensor(2.4959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 240 out of 6633 \t average loss: tensor(2.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 270 out of 6633 \t average loss: tensor(2.5536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 300 out of 6633 \t average loss: tensor(2.4616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 330 out of 6633 \t average loss: tensor(2.4168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 360 out of 6633 \t average loss: tensor(2.4768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 390 out of 6633 \t average loss: tensor(2.3551, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 420 out of 6633 \t average loss: tensor(2.4366, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 450 out of 6633 \t average loss: tensor(2.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 480 out of 6633 \t average loss: tensor(2.4504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 510 out of 6633 \t average loss: tensor(2.3282, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 540 out of 6633 \t average loss: tensor(2.4288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 570 out of 6633 \t average loss: tensor(2.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 600 out of 6633 \t average loss: tensor(2.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 630 out of 6633 \t average loss: tensor(2.4586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 660 out of 6633 \t average loss: tensor(2.3965, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5659120946152021 \t for 59018 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 690 out of 6633 \t average loss: tensor(2.4654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 720 out of 6633 \t average loss: tensor(2.4441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 750 out of 6633 \t average loss: tensor(2.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 780 out of 6633 \t average loss: tensor(2.4998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 810 out of 6633 \t average loss: tensor(2.4569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 840 out of 6633 \t average loss: tensor(2.3908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 870 out of 6633 \t average loss: tensor(2.2746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 900 out of 6633 \t average loss: tensor(2.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 930 out of 6633 \t average loss: tensor(2.4098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 960 out of 6633 \t average loss: tensor(2.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 990 out of 6633 \t average loss: tensor(2.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1020 out of 6633 \t average loss: tensor(2.3212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1050 out of 6633 \t average loss: tensor(2.5452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1080 out of 6633 \t average loss: tensor(2.5444, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1110 out of 6633 \t average loss: tensor(2.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1140 out of 6633 \t average loss: tensor(2.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1170 out of 6633 \t average loss: tensor(2.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1200 out of 6633 \t average loss: tensor(2.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1230 out of 6633 \t average loss: tensor(2.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1260 out of 6633 \t average loss: tensor(2.4166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1290 out of 6633 \t average loss: tensor(2.3500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1320 out of 6633 \t average loss: tensor(2.4912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5698001831936764 \t for 58954 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 1350 out of 6633 \t average loss: tensor(2.4719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1380 out of 6633 \t average loss: tensor(2.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1410 out of 6633 \t average loss: tensor(2.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1440 out of 6633 \t average loss: tensor(2.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1470 out of 6633 \t average loss: tensor(2.5384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1500 out of 6633 \t average loss: tensor(2.3959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1530 out of 6633 \t average loss: tensor(2.5447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1560 out of 6633 \t average loss: tensor(2.5377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1590 out of 6633 \t average loss: tensor(2.4175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1620 out of 6633 \t average loss: tensor(2.4320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1650 out of 6633 \t average loss: tensor(2.5628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1680 out of 6633 \t average loss: tensor(2.3634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1710 out of 6633 \t average loss: tensor(2.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1740 out of 6633 \t average loss: tensor(2.4270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1770 out of 6633 \t average loss: tensor(2.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1800 out of 6633 \t average loss: tensor(2.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1830 out of 6633 \t average loss: tensor(2.4849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1860 out of 6633 \t average loss: tensor(2.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1890 out of 6633 \t average loss: tensor(2.5252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1920 out of 6633 \t average loss: tensor(2.4962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1950 out of 6633 \t average loss: tensor(2.5026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 1980 out of 6633 \t average loss: tensor(2.4171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.573990803975928 \t for 59156 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 2010 out of 6633 \t average loss: tensor(2.5106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2040 out of 6633 \t average loss: tensor(2.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2070 out of 6633 \t average loss: tensor(2.3391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2100 out of 6633 \t average loss: tensor(2.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2130 out of 6633 \t average loss: tensor(2.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2160 out of 6633 \t average loss: tensor(2.4966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2190 out of 6633 \t average loss: tensor(2.5152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2220 out of 6633 \t average loss: tensor(2.5151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2250 out of 6633 \t average loss: tensor(2.4831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2280 out of 6633 \t average loss: tensor(2.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2310 out of 6633 \t average loss: tensor(2.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2340 out of 6633 \t average loss: tensor(2.4300, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2370 out of 6633 \t average loss: tensor(2.4423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2400 out of 6633 \t average loss: tensor(2.5619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2430 out of 6633 \t average loss: tensor(2.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2460 out of 6633 \t average loss: tensor(2.5079, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2490 out of 6633 \t average loss: tensor(2.4594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2520 out of 6633 \t average loss: tensor(2.4682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2550 out of 6633 \t average loss: tensor(2.4868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2580 out of 6633 \t average loss: tensor(2.3996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2610 out of 6633 \t average loss: tensor(2.5192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2640 out of 6633 \t average loss: tensor(2.3029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5714673498125308 \t for 58943 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 2670 out of 6633 \t average loss: tensor(2.4879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2700 out of 6633 \t average loss: tensor(2.5927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2730 out of 6633 \t average loss: tensor(2.4894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2760 out of 6633 \t average loss: tensor(2.5257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2790 out of 6633 \t average loss: tensor(2.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2820 out of 6633 \t average loss: tensor(2.5341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2850 out of 6633 \t average loss: tensor(2.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2880 out of 6633 \t average loss: tensor(2.4470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2910 out of 6633 \t average loss: tensor(2.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2940 out of 6633 \t average loss: tensor(2.4491, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 2970 out of 6633 \t average loss: tensor(2.4048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3000 out of 6633 \t average loss: tensor(2.4022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3030 out of 6633 \t average loss: tensor(2.4960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3060 out of 6633 \t average loss: tensor(2.3699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3090 out of 6633 \t average loss: tensor(2.5441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3120 out of 6633 \t average loss: tensor(2.5519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3150 out of 6633 \t average loss: tensor(2.4509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3180 out of 6633 \t average loss: tensor(2.4403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3210 out of 6633 \t average loss: tensor(2.3666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3240 out of 6633 \t average loss: tensor(2.4439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3270 out of 6633 \t average loss: tensor(2.4797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3300 out of 6633 \t average loss: tensor(2.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3330 out of 6633 \t average loss: tensor(2.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5728740471622837 \t for 58903 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 3360 out of 6633 \t average loss: tensor(2.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3390 out of 6633 \t average loss: tensor(2.3725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3420 out of 6633 \t average loss: tensor(2.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3450 out of 6633 \t average loss: tensor(2.3961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3480 out of 6633 \t average loss: tensor(2.4971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3510 out of 6633 \t average loss: tensor(2.4442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3540 out of 6633 \t average loss: tensor(2.3671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3570 out of 6633 \t average loss: tensor(2.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3600 out of 6633 \t average loss: tensor(2.4865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3630 out of 6633 \t average loss: tensor(2.4830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3660 out of 6633 \t average loss: tensor(2.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3690 out of 6633 \t average loss: tensor(2.3606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3720 out of 6633 \t average loss: tensor(2.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3750 out of 6633 \t average loss: tensor(2.5610, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3780 out of 6633 \t average loss: tensor(2.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3810 out of 6633 \t average loss: tensor(2.4736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3840 out of 6633 \t average loss: tensor(2.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3870 out of 6633 \t average loss: tensor(2.4433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3900 out of 6633 \t average loss: tensor(2.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3930 out of 6633 \t average loss: tensor(2.4982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3960 out of 6633 \t average loss: tensor(2.4202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 3990 out of 6633 \t average loss: tensor(2.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5736732021698098 \t for 58807 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 4020 out of 6633 \t average loss: tensor(2.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4050 out of 6633 \t average loss: tensor(2.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4080 out of 6633 \t average loss: tensor(2.3814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4110 out of 6633 \t average loss: tensor(2.5357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4140 out of 6633 \t average loss: tensor(2.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4170 out of 6633 \t average loss: tensor(2.4388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4200 out of 6633 \t average loss: tensor(2.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4230 out of 6633 \t average loss: tensor(2.5020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4260 out of 6633 \t average loss: tensor(2.4172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4290 out of 6633 \t average loss: tensor(2.4638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4320 out of 6633 \t average loss: tensor(2.5232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4350 out of 6633 \t average loss: tensor(2.4267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4380 out of 6633 \t average loss: tensor(2.3541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4410 out of 6633 \t average loss: tensor(2.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4440 out of 6633 \t average loss: tensor(2.4451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4470 out of 6633 \t average loss: tensor(2.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4500 out of 6633 \t average loss: tensor(2.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4530 out of 6633 \t average loss: tensor(2.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4560 out of 6633 \t average loss: tensor(2.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4590 out of 6633 \t average loss: tensor(2.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4620 out of 6633 \t average loss: tensor(2.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4650 out of 6633 \t average loss: tensor(2.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5712981435769113 \t for 59146 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 4680 out of 6633 \t average loss: tensor(2.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4710 out of 6633 \t average loss: tensor(2.5191, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4740 out of 6633 \t average loss: tensor(2.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4770 out of 6633 \t average loss: tensor(2.5228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4800 out of 6633 \t average loss: tensor(2.4595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4830 out of 6633 \t average loss: tensor(2.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4860 out of 6633 \t average loss: tensor(2.4271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4890 out of 6633 \t average loss: tensor(2.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4920 out of 6633 \t average loss: tensor(2.5676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4950 out of 6633 \t average loss: tensor(2.4326, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 4980 out of 6633 \t average loss: tensor(2.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5010 out of 6633 \t average loss: tensor(2.4373, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5040 out of 6633 \t average loss: tensor(2.3699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5070 out of 6633 \t average loss: tensor(2.5019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5100 out of 6633 \t average loss: tensor(2.4891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5130 out of 6633 \t average loss: tensor(2.4704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5160 out of 6633 \t average loss: tensor(2.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5190 out of 6633 \t average loss: tensor(2.5561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5220 out of 6633 \t average loss: tensor(2.4964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5250 out of 6633 \t average loss: tensor(2.3919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5280 out of 6633 \t average loss: tensor(2.4201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5310 out of 6633 \t average loss: tensor(2.4648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5706249152772129 \t for 59016 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 5340 out of 6633 \t average loss: tensor(2.5242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5370 out of 6633 \t average loss: tensor(2.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5400 out of 6633 \t average loss: tensor(2.4008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5430 out of 6633 \t average loss: tensor(2.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5460 out of 6633 \t average loss: tensor(2.6322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5490 out of 6633 \t average loss: tensor(2.4089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5520 out of 6633 \t average loss: tensor(2.4772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5550 out of 6633 \t average loss: tensor(2.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5580 out of 6633 \t average loss: tensor(2.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5610 out of 6633 \t average loss: tensor(2.5523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5640 out of 6633 \t average loss: tensor(2.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5670 out of 6633 \t average loss: tensor(2.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5700 out of 6633 \t average loss: tensor(2.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5730 out of 6633 \t average loss: tensor(2.3101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5760 out of 6633 \t average loss: tensor(2.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5790 out of 6633 \t average loss: tensor(2.5245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5820 out of 6633 \t average loss: tensor(2.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5850 out of 6633 \t average loss: tensor(2.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5880 out of 6633 \t average loss: tensor(2.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5910 out of 6633 \t average loss: tensor(2.4091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5940 out of 6633 \t average loss: tensor(2.4705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 5970 out of 6633 \t average loss: tensor(2.4028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.572849530575996 \t for 59115 masks on validation data\n",
            "\n",
            "epoch: 2 out of 4 \t batch: 6000 out of 6633 \t average loss: tensor(2.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6030 out of 6633 \t average loss: tensor(2.4206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6060 out of 6633 \t average loss: tensor(2.5304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6090 out of 6633 \t average loss: tensor(2.4562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6120 out of 6633 \t average loss: tensor(2.4287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6150 out of 6633 \t average loss: tensor(2.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6180 out of 6633 \t average loss: tensor(2.4014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6210 out of 6633 \t average loss: tensor(2.5098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6240 out of 6633 \t average loss: tensor(2.5117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6270 out of 6633 \t average loss: tensor(2.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6300 out of 6633 \t average loss: tensor(2.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6330 out of 6633 \t average loss: tensor(2.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6360 out of 6633 \t average loss: tensor(2.3766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6390 out of 6633 \t average loss: tensor(2.4977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6420 out of 6633 \t average loss: tensor(2.3759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6450 out of 6633 \t average loss: tensor(2.3781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6480 out of 6633 \t average loss: tensor(2.5914, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6510 out of 6633 \t average loss: tensor(2.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6540 out of 6633 \t average loss: tensor(2.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6570 out of 6633 \t average loss: tensor(2.4269, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6600 out of 6633 \t average loss: tensor(2.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 2 out of 4 \t batch: 6630 out of 6633 \t average loss: tensor(2.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5740028791599627 \t for 59045 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 30 out of 6633 \t average loss: tensor(2.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 60 out of 6633 \t average loss: tensor(2.4554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 90 out of 6633 \t average loss: tensor(2.3820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 120 out of 6633 \t average loss: tensor(2.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 150 out of 6633 \t average loss: tensor(2.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 180 out of 6633 \t average loss: tensor(2.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 210 out of 6633 \t average loss: tensor(2.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 240 out of 6633 \t average loss: tensor(2.3957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 270 out of 6633 \t average loss: tensor(2.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 300 out of 6633 \t average loss: tensor(2.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 330 out of 6633 \t average loss: tensor(2.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 360 out of 6633 \t average loss: tensor(2.5131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 390 out of 6633 \t average loss: tensor(2.4095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 420 out of 6633 \t average loss: tensor(2.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 450 out of 6633 \t average loss: tensor(2.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 480 out of 6633 \t average loss: tensor(2.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 510 out of 6633 \t average loss: tensor(2.4652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 540 out of 6633 \t average loss: tensor(2.4774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 570 out of 6633 \t average loss: tensor(2.3873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 600 out of 6633 \t average loss: tensor(2.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 630 out of 6633 \t average loss: tensor(2.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 660 out of 6633 \t average loss: tensor(2.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5736965297330303 \t for 58958 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 690 out of 6633 \t average loss: tensor(2.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 720 out of 6633 \t average loss: tensor(2.3583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 750 out of 6633 \t average loss: tensor(2.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 780 out of 6633 \t average loss: tensor(2.4392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 810 out of 6633 \t average loss: tensor(2.4779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 840 out of 6633 \t average loss: tensor(2.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 870 out of 6633 \t average loss: tensor(2.4712, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 900 out of 6633 \t average loss: tensor(2.5305, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 930 out of 6633 \t average loss: tensor(2.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 960 out of 6633 \t average loss: tensor(2.5218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 990 out of 6633 \t average loss: tensor(2.5397, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1020 out of 6633 \t average loss: tensor(2.4247, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1050 out of 6633 \t average loss: tensor(2.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1080 out of 6633 \t average loss: tensor(2.5048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1110 out of 6633 \t average loss: tensor(2.4052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1140 out of 6633 \t average loss: tensor(2.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1170 out of 6633 \t average loss: tensor(2.3921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1200 out of 6633 \t average loss: tensor(2.5080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1230 out of 6633 \t average loss: tensor(2.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1260 out of 6633 \t average loss: tensor(2.4605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1290 out of 6633 \t average loss: tensor(2.4920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1320 out of 6633 \t average loss: tensor(2.3878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5731771229565011 \t for 59151 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 1350 out of 6633 \t average loss: tensor(2.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1380 out of 6633 \t average loss: tensor(2.4327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1410 out of 6633 \t average loss: tensor(2.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1440 out of 6633 \t average loss: tensor(2.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1470 out of 6633 \t average loss: tensor(2.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1500 out of 6633 \t average loss: tensor(2.5256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1530 out of 6633 \t average loss: tensor(2.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1560 out of 6633 \t average loss: tensor(2.3466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1590 out of 6633 \t average loss: tensor(2.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1620 out of 6633 \t average loss: tensor(2.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1650 out of 6633 \t average loss: tensor(2.4393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1680 out of 6633 \t average loss: tensor(2.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1710 out of 6633 \t average loss: tensor(2.5435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1740 out of 6633 \t average loss: tensor(2.5467, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1770 out of 6633 \t average loss: tensor(2.3075, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1800 out of 6633 \t average loss: tensor(2.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1830 out of 6633 \t average loss: tensor(2.4792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1860 out of 6633 \t average loss: tensor(2.4241, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1890 out of 6633 \t average loss: tensor(2.5465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1920 out of 6633 \t average loss: tensor(2.4627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1950 out of 6633 \t average loss: tensor(2.4988, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 1980 out of 6633 \t average loss: tensor(2.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5740750182701949 \t for 58839 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 2010 out of 6633 \t average loss: tensor(2.4443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2040 out of 6633 \t average loss: tensor(2.5143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2070 out of 6633 \t average loss: tensor(2.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2100 out of 6633 \t average loss: tensor(2.5458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2130 out of 6633 \t average loss: tensor(2.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2160 out of 6633 \t average loss: tensor(2.4013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2190 out of 6633 \t average loss: tensor(2.5191, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2220 out of 6633 \t average loss: tensor(2.4480, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2250 out of 6633 \t average loss: tensor(2.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2280 out of 6633 \t average loss: tensor(2.4103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2310 out of 6633 \t average loss: tensor(2.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2340 out of 6633 \t average loss: tensor(2.4239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2370 out of 6633 \t average loss: tensor(2.3828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2400 out of 6633 \t average loss: tensor(2.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2430 out of 6633 \t average loss: tensor(2.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2460 out of 6633 \t average loss: tensor(2.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2490 out of 6633 \t average loss: tensor(2.4893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2520 out of 6633 \t average loss: tensor(2.4398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2550 out of 6633 \t average loss: tensor(2.3369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2580 out of 6633 \t average loss: tensor(2.4359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2610 out of 6633 \t average loss: tensor(2.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2640 out of 6633 \t average loss: tensor(2.4334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5712187708123431 \t for 58559 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 2670 out of 6633 \t average loss: tensor(2.3087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2700 out of 6633 \t average loss: tensor(2.4083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2730 out of 6633 \t average loss: tensor(2.4307, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2760 out of 6633 \t average loss: tensor(2.3650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2790 out of 6633 \t average loss: tensor(2.4343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2820 out of 6633 \t average loss: tensor(2.5160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2850 out of 6633 \t average loss: tensor(2.5051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2880 out of 6633 \t average loss: tensor(2.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2910 out of 6633 \t average loss: tensor(2.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2940 out of 6633 \t average loss: tensor(2.5662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 2970 out of 6633 \t average loss: tensor(2.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3000 out of 6633 \t average loss: tensor(2.4228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3030 out of 6633 \t average loss: tensor(2.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3060 out of 6633 \t average loss: tensor(2.4759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3090 out of 6633 \t average loss: tensor(2.2993, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3120 out of 6633 \t average loss: tensor(2.4860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3150 out of 6633 \t average loss: tensor(2.3960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3180 out of 6633 \t average loss: tensor(2.4285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3210 out of 6633 \t average loss: tensor(2.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3240 out of 6633 \t average loss: tensor(2.4441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3270 out of 6633 \t average loss: tensor(2.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3300 out of 6633 \t average loss: tensor(2.3242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3330 out of 6633 \t average loss: tensor(2.5217, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5743905525094897 \t for 59275 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 3360 out of 6633 \t average loss: tensor(2.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3390 out of 6633 \t average loss: tensor(2.4043, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3420 out of 6633 \t average loss: tensor(2.3224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3450 out of 6633 \t average loss: tensor(2.3676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3480 out of 6633 \t average loss: tensor(2.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3510 out of 6633 \t average loss: tensor(2.5749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3540 out of 6633 \t average loss: tensor(2.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3570 out of 6633 \t average loss: tensor(2.5051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3600 out of 6633 \t average loss: tensor(2.4005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3630 out of 6633 \t average loss: tensor(2.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3660 out of 6633 \t average loss: tensor(2.4752, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3690 out of 6633 \t average loss: tensor(2.4055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3720 out of 6633 \t average loss: tensor(2.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3750 out of 6633 \t average loss: tensor(2.5015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3780 out of 6633 \t average loss: tensor(2.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3810 out of 6633 \t average loss: tensor(2.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3840 out of 6633 \t average loss: tensor(2.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3870 out of 6633 \t average loss: tensor(2.4185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3900 out of 6633 \t average loss: tensor(2.4582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3930 out of 6633 \t average loss: tensor(2.4884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3960 out of 6633 \t average loss: tensor(2.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 3990 out of 6633 \t average loss: tensor(2.4529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5740756409171672 \t for 59095 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 4020 out of 6633 \t average loss: tensor(2.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4050 out of 6633 \t average loss: tensor(2.4992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4080 out of 6633 \t average loss: tensor(2.4432, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4110 out of 6633 \t average loss: tensor(2.4027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4140 out of 6633 \t average loss: tensor(2.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4170 out of 6633 \t average loss: tensor(2.3510, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4200 out of 6633 \t average loss: tensor(2.5442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4230 out of 6633 \t average loss: tensor(2.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4260 out of 6633 \t average loss: tensor(2.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4290 out of 6633 \t average loss: tensor(2.4281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4320 out of 6633 \t average loss: tensor(2.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4350 out of 6633 \t average loss: tensor(2.4335, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4380 out of 6633 \t average loss: tensor(2.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4410 out of 6633 \t average loss: tensor(2.3776, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4440 out of 6633 \t average loss: tensor(2.3659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4470 out of 6633 \t average loss: tensor(2.6133, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4500 out of 6633 \t average loss: tensor(2.5012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4530 out of 6633 \t average loss: tensor(2.5055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4560 out of 6633 \t average loss: tensor(2.4991, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4590 out of 6633 \t average loss: tensor(2.3822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4620 out of 6633 \t average loss: tensor(2.4637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4650 out of 6633 \t average loss: tensor(2.3151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5731678245470644 \t for 58728 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 4680 out of 6633 \t average loss: tensor(2.4924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4710 out of 6633 \t average loss: tensor(2.3374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4740 out of 6633 \t average loss: tensor(2.3506, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4770 out of 6633 \t average loss: tensor(2.4215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4800 out of 6633 \t average loss: tensor(2.4305, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4830 out of 6633 \t average loss: tensor(2.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4860 out of 6633 \t average loss: tensor(2.5123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4890 out of 6633 \t average loss: tensor(2.4533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4920 out of 6633 \t average loss: tensor(2.4955, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4950 out of 6633 \t average loss: tensor(2.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 4980 out of 6633 \t average loss: tensor(2.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5010 out of 6633 \t average loss: tensor(2.4742, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5040 out of 6633 \t average loss: tensor(2.4481, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5070 out of 6633 \t average loss: tensor(2.3597, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5100 out of 6633 \t average loss: tensor(2.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5130 out of 6633 \t average loss: tensor(2.4156, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5160 out of 6633 \t average loss: tensor(2.4946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5190 out of 6633 \t average loss: tensor(2.4732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5220 out of 6633 \t average loss: tensor(2.3404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5250 out of 6633 \t average loss: tensor(2.4114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5280 out of 6633 \t average loss: tensor(2.4153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5310 out of 6633 \t average loss: tensor(2.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.570364196165819 \t for 58787 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 5340 out of 6633 \t average loss: tensor(2.4317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5370 out of 6633 \t average loss: tensor(2.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5400 out of 6633 \t average loss: tensor(2.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5430 out of 6633 \t average loss: tensor(2.3690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5460 out of 6633 \t average loss: tensor(2.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5490 out of 6633 \t average loss: tensor(2.3834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5520 out of 6633 \t average loss: tensor(2.4740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5550 out of 6633 \t average loss: tensor(2.4731, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5580 out of 6633 \t average loss: tensor(2.4721, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5610 out of 6633 \t average loss: tensor(2.5341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5640 out of 6633 \t average loss: tensor(2.3703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5670 out of 6633 \t average loss: tensor(2.3930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5700 out of 6633 \t average loss: tensor(2.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5730 out of 6633 \t average loss: tensor(2.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5760 out of 6633 \t average loss: tensor(2.4328, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5790 out of 6633 \t average loss: tensor(2.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5820 out of 6633 \t average loss: tensor(2.4635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5850 out of 6633 \t average loss: tensor(2.3276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5880 out of 6633 \t average loss: tensor(2.3897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5910 out of 6633 \t average loss: tensor(2.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5940 out of 6633 \t average loss: tensor(2.5293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 5970 out of 6633 \t average loss: tensor(2.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5698285444807492 \t for 59374 masks on validation data\n",
            "\n",
            "epoch: 3 out of 4 \t batch: 6000 out of 6633 \t average loss: tensor(2.4435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6030 out of 6633 \t average loss: tensor(2.4527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6060 out of 6633 \t average loss: tensor(2.4723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6090 out of 6633 \t average loss: tensor(2.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6120 out of 6633 \t average loss: tensor(2.5047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6150 out of 6633 \t average loss: tensor(2.4943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6180 out of 6633 \t average loss: tensor(2.4676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6210 out of 6633 \t average loss: tensor(2.4298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6240 out of 6633 \t average loss: tensor(2.4313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6270 out of 6633 \t average loss: tensor(2.5292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6300 out of 6633 \t average loss: tensor(2.4116, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6330 out of 6633 \t average loss: tensor(2.4312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6360 out of 6633 \t average loss: tensor(2.4954, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6390 out of 6633 \t average loss: tensor(2.4762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6420 out of 6633 \t average loss: tensor(2.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6450 out of 6633 \t average loss: tensor(2.3770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6480 out of 6633 \t average loss: tensor(2.4144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6510 out of 6633 \t average loss: tensor(2.5302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6540 out of 6633 \t average loss: tensor(2.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6570 out of 6633 \t average loss: tensor(2.5817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6600 out of 6633 \t average loss: tensor(2.4857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 3 out of 4 \t batch: 6630 out of 6633 \t average loss: tensor(2.3736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5725028304915761 \t for 59177 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 30 out of 6633 \t average loss: tensor(2.3023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 60 out of 6633 \t average loss: tensor(2.4494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 90 out of 6633 \t average loss: tensor(2.6128, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 120 out of 6633 \t average loss: tensor(2.4686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 150 out of 6633 \t average loss: tensor(2.3938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 180 out of 6633 \t average loss: tensor(2.4003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 210 out of 6633 \t average loss: tensor(2.3980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 240 out of 6633 \t average loss: tensor(2.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 270 out of 6633 \t average loss: tensor(2.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 300 out of 6633 \t average loss: tensor(2.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 330 out of 6633 \t average loss: tensor(2.3757, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 360 out of 6633 \t average loss: tensor(2.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 390 out of 6633 \t average loss: tensor(2.4382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 420 out of 6633 \t average loss: tensor(2.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 450 out of 6633 \t average loss: tensor(2.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 480 out of 6633 \t average loss: tensor(2.3600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 510 out of 6633 \t average loss: tensor(2.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 540 out of 6633 \t average loss: tensor(2.3825, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 570 out of 6633 \t average loss: tensor(2.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 600 out of 6633 \t average loss: tensor(2.3287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 630 out of 6633 \t average loss: tensor(2.4372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 660 out of 6633 \t average loss: tensor(2.5036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5717604761985517 \t for 58967 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 690 out of 6633 \t average loss: tensor(2.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 720 out of 6633 \t average loss: tensor(2.5036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 750 out of 6633 \t average loss: tensor(2.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 780 out of 6633 \t average loss: tensor(2.3129, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 810 out of 6633 \t average loss: tensor(2.4391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 840 out of 6633 \t average loss: tensor(2.4422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 870 out of 6633 \t average loss: tensor(2.5413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 900 out of 6633 \t average loss: tensor(2.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 930 out of 6633 \t average loss: tensor(2.3546, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 960 out of 6633 \t average loss: tensor(2.4639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 990 out of 6633 \t average loss: tensor(2.4459, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1020 out of 6633 \t average loss: tensor(2.3925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1050 out of 6633 \t average loss: tensor(2.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1080 out of 6633 \t average loss: tensor(2.4122, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1110 out of 6633 \t average loss: tensor(2.3924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1140 out of 6633 \t average loss: tensor(2.4607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1170 out of 6633 \t average loss: tensor(2.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1200 out of 6633 \t average loss: tensor(2.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1230 out of 6633 \t average loss: tensor(2.3693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1260 out of 6633 \t average loss: tensor(2.5351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1290 out of 6633 \t average loss: tensor(2.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1320 out of 6633 \t average loss: tensor(2.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5738237897460339 \t for 58748 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 1350 out of 6633 \t average loss: tensor(2.5124, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1380 out of 6633 \t average loss: tensor(2.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1410 out of 6633 \t average loss: tensor(2.4353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1440 out of 6633 \t average loss: tensor(2.5108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1470 out of 6633 \t average loss: tensor(2.4403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1500 out of 6633 \t average loss: tensor(2.3995, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1530 out of 6633 \t average loss: tensor(2.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1560 out of 6633 \t average loss: tensor(2.3844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1590 out of 6633 \t average loss: tensor(2.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1620 out of 6633 \t average loss: tensor(2.4490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1650 out of 6633 \t average loss: tensor(2.5314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1680 out of 6633 \t average loss: tensor(2.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1710 out of 6633 \t average loss: tensor(2.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1740 out of 6633 \t average loss: tensor(2.3114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1770 out of 6633 \t average loss: tensor(2.3974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1800 out of 6633 \t average loss: tensor(2.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1830 out of 6633 \t average loss: tensor(2.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1860 out of 6633 \t average loss: tensor(2.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1890 out of 6633 \t average loss: tensor(2.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1920 out of 6633 \t average loss: tensor(2.3976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1950 out of 6633 \t average loss: tensor(2.4802, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 1980 out of 6633 \t average loss: tensor(2.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5711706802002793 \t for 58718 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 2010 out of 6633 \t average loss: tensor(2.3373, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2040 out of 6633 \t average loss: tensor(2.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2070 out of 6633 \t average loss: tensor(2.5312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2100 out of 6633 \t average loss: tensor(2.4801, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2130 out of 6633 \t average loss: tensor(2.4431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2160 out of 6633 \t average loss: tensor(2.5090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2190 out of 6633 \t average loss: tensor(2.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2220 out of 6633 \t average loss: tensor(2.4068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2250 out of 6633 \t average loss: tensor(2.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2280 out of 6633 \t average loss: tensor(2.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2310 out of 6633 \t average loss: tensor(2.4093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2340 out of 6633 \t average loss: tensor(2.2860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2370 out of 6633 \t average loss: tensor(2.3794, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2400 out of 6633 \t average loss: tensor(2.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2430 out of 6633 \t average loss: tensor(2.5057, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2460 out of 6633 \t average loss: tensor(2.4717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2490 out of 6633 \t average loss: tensor(2.5067, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2520 out of 6633 \t average loss: tensor(2.4053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2550 out of 6633 \t average loss: tensor(2.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2580 out of 6633 \t average loss: tensor(2.4183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2610 out of 6633 \t average loss: tensor(2.4892, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2640 out of 6633 \t average loss: tensor(2.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5746718146718147 \t for 58275 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 2670 out of 6633 \t average loss: tensor(2.3095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2700 out of 6633 \t average loss: tensor(2.4000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2730 out of 6633 \t average loss: tensor(2.3669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2760 out of 6633 \t average loss: tensor(2.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2790 out of 6633 \t average loss: tensor(2.4645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2820 out of 6633 \t average loss: tensor(2.4128, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2850 out of 6633 \t average loss: tensor(2.5168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2880 out of 6633 \t average loss: tensor(2.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2910 out of 6633 \t average loss: tensor(2.5673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2940 out of 6633 \t average loss: tensor(2.4915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 2970 out of 6633 \t average loss: tensor(2.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3000 out of 6633 \t average loss: tensor(2.4636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3030 out of 6633 \t average loss: tensor(2.2889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3060 out of 6633 \t average loss: tensor(2.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3090 out of 6633 \t average loss: tensor(2.4463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3120 out of 6633 \t average loss: tensor(2.5303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3150 out of 6633 \t average loss: tensor(2.3396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3180 out of 6633 \t average loss: tensor(2.4031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3210 out of 6633 \t average loss: tensor(2.3567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3240 out of 6633 \t average loss: tensor(2.4651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3270 out of 6633 \t average loss: tensor(2.5210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3300 out of 6633 \t average loss: tensor(2.5121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3330 out of 6633 \t average loss: tensor(2.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5717983420740992 \t for 59110 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 3360 out of 6633 \t average loss: tensor(2.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3390 out of 6633 \t average loss: tensor(2.3599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3420 out of 6633 \t average loss: tensor(2.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3450 out of 6633 \t average loss: tensor(2.3915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3480 out of 6633 \t average loss: tensor(2.3648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3510 out of 6633 \t average loss: tensor(2.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3540 out of 6633 \t average loss: tensor(2.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3570 out of 6633 \t average loss: tensor(2.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3600 out of 6633 \t average loss: tensor(2.3719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3630 out of 6633 \t average loss: tensor(2.4367, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3660 out of 6633 \t average loss: tensor(2.2770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3690 out of 6633 \t average loss: tensor(2.4708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3720 out of 6633 \t average loss: tensor(2.4571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3750 out of 6633 \t average loss: tensor(2.4099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3780 out of 6633 \t average loss: tensor(2.4487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3810 out of 6633 \t average loss: tensor(2.4551, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3840 out of 6633 \t average loss: tensor(2.3223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3870 out of 6633 \t average loss: tensor(2.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3900 out of 6633 \t average loss: tensor(2.4125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3930 out of 6633 \t average loss: tensor(2.3939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3960 out of 6633 \t average loss: tensor(2.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 3990 out of 6633 \t average loss: tensor(2.3564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5719141021305377 \t for 59140 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 4020 out of 6633 \t average loss: tensor(2.3948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4050 out of 6633 \t average loss: tensor(2.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4080 out of 6633 \t average loss: tensor(2.4901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4110 out of 6633 \t average loss: tensor(2.3984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4140 out of 6633 \t average loss: tensor(2.5826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4170 out of 6633 \t average loss: tensor(2.3729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4200 out of 6633 \t average loss: tensor(2.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4230 out of 6633 \t average loss: tensor(2.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4260 out of 6633 \t average loss: tensor(2.5407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4290 out of 6633 \t average loss: tensor(2.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4320 out of 6633 \t average loss: tensor(2.4957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4350 out of 6633 \t average loss: tensor(2.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4380 out of 6633 \t average loss: tensor(2.4637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4410 out of 6633 \t average loss: tensor(2.3387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4440 out of 6633 \t average loss: tensor(2.3665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4470 out of 6633 \t average loss: tensor(2.4034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4500 out of 6633 \t average loss: tensor(2.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4530 out of 6633 \t average loss: tensor(2.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4560 out of 6633 \t average loss: tensor(2.4372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4590 out of 6633 \t average loss: tensor(2.4945, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4620 out of 6633 \t average loss: tensor(2.4291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4650 out of 6633 \t average loss: tensor(2.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5744209054003343 \t for 58626 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 4680 out of 6633 \t average loss: tensor(2.3534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4710 out of 6633 \t average loss: tensor(2.4404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4740 out of 6633 \t average loss: tensor(2.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4770 out of 6633 \t average loss: tensor(2.4090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4800 out of 6633 \t average loss: tensor(2.4242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4830 out of 6633 \t average loss: tensor(2.3657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4860 out of 6633 \t average loss: tensor(2.3751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4890 out of 6633 \t average loss: tensor(2.4445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4920 out of 6633 \t average loss: tensor(2.5265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4950 out of 6633 \t average loss: tensor(2.4138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 4980 out of 6633 \t average loss: tensor(2.4462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5010 out of 6633 \t average loss: tensor(2.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5040 out of 6633 \t average loss: tensor(2.4281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5070 out of 6633 \t average loss: tensor(2.4387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5100 out of 6633 \t average loss: tensor(2.3802, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5130 out of 6633 \t average loss: tensor(2.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5160 out of 6633 \t average loss: tensor(2.3839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5190 out of 6633 \t average loss: tensor(2.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5220 out of 6633 \t average loss: tensor(2.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5250 out of 6633 \t average loss: tensor(2.5003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5280 out of 6633 \t average loss: tensor(2.5227, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5310 out of 6633 \t average loss: tensor(2.4584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5737805085033436 \t for 58918 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 5340 out of 6633 \t average loss: tensor(2.3968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5370 out of 6633 \t average loss: tensor(2.3614, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5400 out of 6633 \t average loss: tensor(2.3309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5430 out of 6633 \t average loss: tensor(2.4757, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5460 out of 6633 \t average loss: tensor(2.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5490 out of 6633 \t average loss: tensor(2.3932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5520 out of 6633 \t average loss: tensor(2.5023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5550 out of 6633 \t average loss: tensor(2.4132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5580 out of 6633 \t average loss: tensor(2.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5610 out of 6633 \t average loss: tensor(2.4402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5640 out of 6633 \t average loss: tensor(2.4613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5670 out of 6633 \t average loss: tensor(2.3920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5700 out of 6633 \t average loss: tensor(2.4656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5730 out of 6633 \t average loss: tensor(2.4430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5760 out of 6633 \t average loss: tensor(2.2979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5790 out of 6633 \t average loss: tensor(2.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5820 out of 6633 \t average loss: tensor(2.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5850 out of 6633 \t average loss: tensor(2.4876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5880 out of 6633 \t average loss: tensor(2.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5910 out of 6633 \t average loss: tensor(2.4781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5940 out of 6633 \t average loss: tensor(2.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 5970 out of 6633 \t average loss: tensor(2.4325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5756029763216326 \t for 58999 masks on validation data\n",
            "\n",
            "epoch: 4 out of 4 \t batch: 6000 out of 6633 \t average loss: tensor(2.4378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6030 out of 6633 \t average loss: tensor(2.3727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6060 out of 6633 \t average loss: tensor(2.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6090 out of 6633 \t average loss: tensor(2.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6120 out of 6633 \t average loss: tensor(2.5140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6150 out of 6633 \t average loss: tensor(2.5539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6180 out of 6633 \t average loss: tensor(2.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6210 out of 6633 \t average loss: tensor(2.4903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6240 out of 6633 \t average loss: tensor(2.4549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6270 out of 6633 \t average loss: tensor(2.5267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6300 out of 6633 \t average loss: tensor(2.3714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6330 out of 6633 \t average loss: tensor(2.4190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6360 out of 6633 \t average loss: tensor(2.4077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6390 out of 6633 \t average loss: tensor(2.5130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6420 out of 6633 \t average loss: tensor(2.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6450 out of 6633 \t average loss: tensor(2.4061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6480 out of 6633 \t average loss: tensor(2.4408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6510 out of 6633 \t average loss: tensor(2.3875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6540 out of 6633 \t average loss: tensor(2.5288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6570 out of 6633 \t average loss: tensor(2.4178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6600 out of 6633 \t average loss: tensor(2.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 4 out of 4 \t batch: 6630 out of 6633 \t average loss: tensor(2.4193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "\n",
            "validation accuracy =  0.5710630655054391 \t for 59018 masks on validation data\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH18KXhzXNvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}