{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Roberta.ipynb","provenance":[{"file_id":"1PjtdDsvXQMtPdnuwQeq7BwB15v5AGKkE","timestamp":1582649473990},{"file_id":"https://github.com/SahilDhull/emphasis_selection/blob/master/model/bert_as_embedding_v3.ipynb","timestamp":1582481346645}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iFZ3HHuy1mx0","colab_type":"code","outputId":"24f7b3a2-371f-4388-d9b6-3de2aba51617","executionInfo":{"status":"ok","timestamp":1582740326071,"user_tz":-330,"elapsed":14896,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"source":["!pip install transformers\n","!pip install config"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n","Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n","Requirement already satisfied: config in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oZkDAFPU1ps2","colab_type":"code","outputId":"618407dd-d04e-4223-d711-34a1d9338074","executionInfo":{"status":"ok","timestamp":1582740328193,"user_tz":-330,"elapsed":16959,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","#from sklearn.model_selection import train_test_spl\n","from transformers import RobertaModel, RobertaConfig, RobertaTokenizer\n","from transformers import GPT2Model, GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n","from transformers import BertTokenizer, BertConfig\n","from transformers import BertForMaskedLM , BertModel ,WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n","from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import codecs\n","from torch.nn.utils.rnn import pack_padded_sequence"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"nhNFcgUa1w1k","colab_type":"code","outputId":"3f7e529c-16f8-4219-8cf8-29db5549fdbf","executionInfo":{"status":"ok","timestamp":1582740328198,"user_tz":-330,"elapsed":16917,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"kmLIQdgZ1zFP","colab_type":"code","outputId":"55b109a9-689c-431a-9c0b-f90800c00da9","executionInfo":{"status":"ok","timestamp":1582740328204,"user_tz":-330,"elapsed":16872,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","train_file = 'drive/My Drive/datasets/train.txt'\n","dev_file = 'drive/My Drive/datasets/dev.txt'\n","\n","quotes_file = 'drive/My Drive/datasets/all_quotes.txt'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IplzxoD111cP","colab_type":"code","colab":{}},"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-large', do_lower_case = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RM2bAwze2Ezt","colab_type":"code","colab":{}},"source":["def read_token_map(file, word_index = 1,prob_index = 4, caseless = False):\n","  \n","  with codecs.open(file, 'r', 'utf-8') as f:\n","      lines = f.readlines()\n","\n","  tokenized_texts = []\n","  token_map = []\n","  token_labels = []\n","  sent_length = []\n","\n","  roberta_tokens = []\n","  orig_to_tok_map = []\n","  labels = []\n","\n","  roberta_tokens.append(\"<s>\")\n","  \n","  for line in lines:\n","    if not (line.isspace()):\n","      feats = line.strip().split()\n","      word = feats[word_index].lower() if caseless else feats[word_index]\n","      label = feats[prob_index].lower() if caseless else feats[prob_index]\n","      labels.append((float)(label))\n","      orig_to_tok_map.append(len(roberta_tokens))\n","      \n","      if(word == \"n't\"):\n","        word = \"'t\"\n","        if(roberta_tokens[-1] != \"won\"):\n","          roberta_tokens[-1] = roberta_tokens[-1] +\"n\"\n","      if(word == \"wo\"):\n","        word == \"won\"\n","\n","      roberta_tokens.extend(tokenizer.tokenize(word))\n","\n","    elif len(orig_to_tok_map) > 0:\n","\n","      # lab = np.array(labels)\n","      # lab.sort()\n","      # if(len(labels)>=4):\n","      #   mini = lab[-4]\n","      # else:\n","      #   mini = lab[0]\n"," \n","      # for l in range(len(labels)):\n","      #   if(labels[l]<mini):\n","      #     labels[l] = 0.0\n","\n","      roberta_tokens.append(\"</s>\")\n","      tokenized_texts.append(roberta_tokens)\n","      token_map.append(orig_to_tok_map)\n","      token_labels.append(labels)\n","      sent_length.append(len(labels))\n","      roberta_tokens = []\n","      orig_to_tok_map = []\n","      labels = []\n","      length = 0\n","      roberta_tokens.append(\"<s>\")\n","          \n","  if len(orig_to_tok_map) > 0:\n","    roberta_tokens.append(\"</s>\")\n","    tokenized_texts.append(roberta_tokens)\n","    token_map.append(orig_to_tok_map)\n","    token_labels.append(labels)\n","    sent_length.append(len(labels))\n","  \n","  return tokenized_texts, token_map, token_labels, sent_length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IflGdsPR2LmX","colab_type":"code","outputId":"48143154-de48-4287-cf68-eb681ba177a7","executionInfo":{"status":"ok","timestamp":1582740331336,"user_tz":-330,"elapsed":19868,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["t_tokenized_texts, t_token_map, t_token_label, t_sent_length = read_token_map(train_file)\n","print(t_tokenized_texts[100])\n","print(t_token_map[100])\n","print(t_token_label[100])\n","print(t_sent_length[100])\n","\n","d_tokenized_texts, d_token_map, d_token_label, d_sent_length = read_token_map(dev_file)\n","print(d_tokenized_texts[50])\n","print(d_token_map[50])\n","print(d_token_label[50])\n","print(d_sent_length[50])\n","print(tokenizer.tokenize(\"Hello, my dog is cute\", add_prefix_space = True))\n","print(tokenizer.tokenize(\"won't\"))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['<s>', 'H', 'appiness', 'cons', 'ists', 'in', 'real', 'izing', 'it', 'is', 'all', 'a', 'great', 'str', 'ange', 'dream', '.', '</s>']\n","[1, 3, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16]\n","[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n","12\n","['<s>', '``', 'F', 'asc', 'inating', 'social', 'media', 'tip', 'or', 'fact', 'to', 'share', '.', \"''\", '@', 'Spe', 'aker', 'Name', '</s>']\n","[1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 17]\n","[0.0, 0.5555555555555556, 0.0, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.0, 0.2222222222222222, 0.2222222222222222]\n","13\n","['ĠHello', ',', 'Ġmy', 'Ġdog', 'Ġis', 'Ġcute']\n","['won', \"'t\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q8IsOd0i2PnP","colab_type":"code","outputId":"4d9ae642-c463-400c-9914-48adf9e6f507","executionInfo":{"status":"ok","timestamp":1582740331340,"user_tz":-330,"elapsed":19818,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["MAX_LEN = 72\n","\n","# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n","\n","# Pad our input tokens\n","t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n","\n","print(t_input_ids[100])\n","print(t_token_map[100])\n","print(t_token_label[100])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[    0   725 37055 10998  1952   179  8726  2787   405   354  1250   102\n"," 12338  6031 10987 24009     4     2     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0]\n","[ 1  3  5  6  8  9 10 11 12 13 15 16  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n","[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n"," 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1Sllf5eX2TJg","colab_type":"code","outputId":"9d9fb772-7b1e-49d3-bad0-9ede73036244","executionInfo":{"status":"ok","timestamp":1582740331344,"user_tz":-330,"elapsed":19767,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n","\n","# Pad our input tokens\n","d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n","\n","print(d_input_ids[50])\n","print(d_token_map[50])\n","print(d_token_label[50])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[    0 49519   597  8631 15647 19027  5535 39080   368 24905   560 12689\n","     4 17809  1039 29235  4218 31723     2     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0]\n","[ 1  2  5  6  7  8  9 10 11 12 13 14 17  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n","  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n","[0.         0.55555556 0.         0.11111111 0.22222222 0.11111111\n"," 0.11111111 0.         0.22222222 0.         0.         0.22222222\n"," 0.22222222 0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.        ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GWqYZ8vV2WYx","colab_type":"code","outputId":"739f7748-49e0-41be-847e-a5e11d9169c5","executionInfo":{"status":"ok","timestamp":1582740332944,"user_tz":-330,"elapsed":21284,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["t_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in t_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  t_attention_masks.append(seq_mask)\n","print(t_attention_masks[100])\n","\n","d_attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in d_input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  d_attention_masks.append(seq_mask)\n","print(d_attention_masks[50])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GtnslThr2ZnQ","colab_type":"code","colab":{}},"source":["t_input_ids = torch.tensor(t_input_ids)\n","t_token_map = torch.tensor(t_token_map )\n","t_token_label = torch.tensor(t_token_label)\n","t_attention_masks = torch.tensor(t_attention_masks)\n","t_sent_length = torch.tensor(t_sent_length)\n","\n","d_input_ids = torch.tensor(d_input_ids)\n","d_token_map = torch.tensor(d_token_map )\n","d_token_label = torch.tensor(d_token_label)\n","d_attention_masks = torch.tensor(d_attention_masks)\n","d_sent_length = torch.tensor(d_sent_length)\n","\n","# Select a batch size for training. \n","batch_size = 32\n","# print(t_token_labels)\n","# Create an iterator of our data with torch DataLoader \n","train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks, t_sent_length)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks, d_sent_length)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODH9sTED18Zf","colab_type":"code","colab":{}},"source":["class roberta_model(nn.Module):\n","  def __init__(self, final_size, drop_prob, data_parallel=True):\n","    super(roberta_model, self).__init__()\n","\n","    config = RobertaConfig.from_pretrained('roberta-large', output_hidden_states=True)\n","    roberta = RobertaModel.from_pretrained('roberta-large', output_hidden_states=True)\n","    \n","    #cnt=0\n","    #for child in roberta.children():\n","    #  cnt = cnt + 1\n","    #  if cnt<=12:\n","    #    for param in child.parameters():\n","    #      param.requires_grad = False\n","\n","    if data_parallel:\n","        self.roberta = nn.DataParallel(roberta)\n","    else:\n","        self.roberta = roberta\n","    roberta_dim = 24*1024\n","    hidden_dim1 = 900\n","    hidden_dim2 = 40\n","    hidden_dim3 = 20\n","\n","    self.fc1 = nn.Linear(roberta_dim, hidden_dim1)\n","    self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n","    #self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n","    self.fc4 = nn.Linear(hidden_dim2, final_size)\n","    self.dropout1 = nn.Dropout(p=drop_prob)\n","    self.dropout2 = nn.Dropout(p=drop_prob)\n","    self.dropout3 = nn.Dropout(p=drop_prob)\n","    self.dropout4 = nn.Dropout(p=drop_prob)\n","           \n","  def forward(self, roberta_ids, roberta_mask, labels = None, roberta_token_starts = None,lm_lengths = None):\n","    \n","    batch_size = roberta_ids.size()[0]\n","    pad_size = roberta_ids.size()[1]\n","    #print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n","\n","    if(roberta_token_starts == None):\n","      output = self.roberta(roberta_ids, attention_mask = roberta_mask, masked_lm_labels=labels)\n","      return output\n","    \n","    output = self.roberta(roberta_ids, attention_mask = roberta_mask)\n","    #print(len(hiddden_states))\n","    #print(len(hidden_states[1]))\n","    #print(hidden_states[1][0].size())\n","    #print(np.shape(output))\n","    #print(np.shape(output[0]))\n","    #print(np.shape(output[0][0]))\n","    #print(np.shape(output[1]))\n","    #print(np.shape(output[1][0]))\n","    #print(np.shape(output[2]))\n","    #print(np.shape(output[2][0]))\n","    #print(len(output[3][0]))\n","    #print(len(output[3][1]))\n","    #print(len(output[3][2]))\n","    #print(len(output[3][0][0]))\n","    #print(len(output[3][0][0][0]))\n","    #print(len(output))\n","    #print(len(output[1]))\n","    #print(output[1][0].size())\n","\n","    roberta_out = output[2][1]\n","    for layers in range(2,25,1):\n","      roberta_out = torch.cat((roberta_out, output[2][layers]), dim=2)\n","    \n","    #print(roberta_out.size())\n","    # bert_last_layer = output[1][0]\n","    # bert_second_last_layer = output[1][1]\n","    # bert_third_last_layer = output[1][2]\n","    # bert_fourth_last_layer = output[1][3]\n","    # bert_fifth_last_layer = output[1][4]\n","    # bert_sixth_last_layer = output[1][5]\n","\n","    # bert_out = torch.cat((bert_last_layer, bert_second_last_layer, bert_third_last_layer, bert_fourth_last_layer, bert_fifth_last_layer, bert_sixth_last_layer), dim=2)\n","    \n","    pred_logits = torch.relu(self.fc1(self.dropout1(roberta_out)))\n","    pred_logits = torch.relu(self.fc2(self.dropout2(pred_logits)))\n","    #pred_logits = torch.relu(self.fc3(self.dropout3(pred_logits)))\n","    pred_logits = torch.sigmoid(self.fc4(self.dropout4(pred_logits)))\n","    pred_logits = torch.squeeze(pred_logits,2)\n","    # print(pred_logits.size())\n","    # print(labels.size())\n","    # print(pred_logits[1])\n","    # print(labels[1])\n","    # print(bert_token_starts[1])\n","    # print(\"\\n\")\n","\n","    pred_labels = labels.clone()\n","    # print(pred_labels[1])\n","    # print(\"\\n\")\n","    \n","    for b in range(batch_size):\n","      for w in range(pad_size):\n","        if(roberta_token_starts[b][w]!=0):\n","          if(roberta_token_starts[b][w]>=pad_size):\n","            print(roberta_token_starts[b])\n","          else:\n","            pred_labels[b][w] = pred_logits[b][roberta_token_starts[b][w]]\n","\n","    # print(pred_labels[1])\n","    # print(labels[1])\n","    # print(\"\\n\")\n","\n","    lm_lengths, lm_sort_ind = lm_lengths.sort(dim=0, descending=True)\n","    scores = labels[lm_sort_ind]\n","    targets = pred_labels[lm_sort_ind]\n","    scores = pack_padded_sequence(scores, lm_lengths, batch_first=True).data\n","    targets = pack_padded_sequence(targets, lm_lengths, batch_first=True).data\n","    \n","    # mask = pred_labels!=0\n","    # total = mask[mask].size()[0]\n","\n","    # loss_fn = nn.BCELoss(reduction='sum').to(device) \n","    loss_fn = nn.BCELoss().to(device) \n","    loss = loss_fn(targets,scores)\n","    # print(loss)\n","\n","    # loss /= total \n","    # print(loss) \n","    return loss, pred_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"56hwBPs_2dUM","colab_type":"code","colab":{}},"source":["model = roberta_model(1,0.3,True).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJSJ0eki2gWU","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n","\n","epochs = 30\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-F1P6at2kGa","colab_type":"code","colab":{}},"source":["\n","def intersection(lst1, lst2):\n","    lst3 = [value for value in lst1 if value in lst2]\n","    return lst3\n","\n","def fix_padding(scores_numpy, label_probs,  mask_numpy):\n","    #if len(scores_numpy) != len(mask_numpy):\n","    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n","    #assert len(scores_numpy) == len(mask_numpy)\n","    #if len(label_probs) != len(mask_numpy):\n","    #    print(\"len(label_probs) != len(mask_numpy)\")\n","    #assert len(label_probs) == len(mask_numpy)\n","\n","    all_scores_no_padd = []\n","    all_labels_no_pad = []\n","    for i in range(len(mask_numpy)):\n","        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n","        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n","\n","    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n","    return all_scores_no_padd, all_labels_no_pad\n","\n","def match_M(batch_scores_no_padd, batch_labels_no_pad):\n","\n","    top_m = [1, 2, 3, 4]\n","    batch_num_m=[]\n","    batch_score_m=[]\n","    for m in top_m:\n","        intersects_lst = []\n","        # exact_lst = []\n","        score_lst = []\n","        ############################################### computing scores:\n","        for s in batch_scores_no_padd:\n","            if len(s) <=m:\n","                continue\n","            h = m\n","            # if len(s) > h:\n","            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n","            #         h += 1\n","\n","            # s = np.asarray(s.cpu())\n","            s = np.asarray(s)\n","            #ind_score = np.argsort(s)[-h:]\n","            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n","            score_lst.append(ind_score)\n","\n","        ############################################### computing labels:\n","        label_lst = []\n","        for l in batch_labels_no_pad:\n","            if len(l) <=m:\n","                continue\n","            # if it contains several top values with the same amount\n","            h = m\n","            # l = l.cpu()\n","            if len(l) > h:\n","                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n","                    h += 1\n","            l = np.asarray(l)\n","            ind_label = np.argsort(l)[-h:]\n","            label_lst.append(ind_label)\n","\n","        ############################################### :\n","\n","        for i in range(len(score_lst)):\n","            intersect = intersection(score_lst[i], label_lst[i])\n","            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n","            # sorted_score_lst = sorted(score_lst[i])\n","            # sorted_label_lst =  sorted(label_lst[i])\n","            # if sorted_score_lst==sorted_label_lst:\n","            #     exact_lst.append(1)\n","            # else:\n","            #     exact_lst.append(0)\n","        batch_num_m.append(len(score_lst))\n","        batch_score_m.append(sum(intersects_lst))\n","    return batch_num_m, batch_score_m"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRM_nU783HIc","colab_type":"code","colab":{}},"source":["\n","def validation(model, validation_dataloader):\n","  print(\"\")\n","  print(\"Running Validation...\")\n","\n","  model.eval()\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  num_m = [0, 0, 0, 0]\n","  score_m = [0, 0, 0, 0]\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","      \n","      # Add batch to GPU\n","      batch = tuple(t.to(device) for t in batch)\n","      \n","      # Unpack the inputs from our dataloader\n","      v_input_ids = batch[0].to(device)\n","      v_input_mask = batch[3].to(device)\n","      v_token_starts = batch[1].to(device)\n","      v_labels = batch[2].to(device)\n","      v_sent_length = batch[4]\n","            \n","      # Telling the model not to compute or store gradients, saving memory and\n","      # speeding up validation\n","      with torch.no_grad():        \n","          output = model(v_input_ids, v_input_mask, v_labels, v_token_starts, v_sent_length)\n","      \n","      pred_labels = output[1]\n","\n","      pred_labels = pred_labels.detach().cpu().numpy()\n","      v_labels = v_labels.to('cpu').numpy()\n","      # print(pred_labels[0])\n","      # print(v_labels[0])\n","      \n","      pred_labels, v_labels = fix_padding(pred_labels, v_labels, v_sent_length)\n","      # print(pred_labels[0])\n","      # print(v_labels[0])\n","\n","      batch_num_m, batch_score_m = match_M(pred_labels, v_labels)\n","      num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n","      score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n","  \n","  m_score = [i/j for i,j in zip(score_m, num_m)]\n","  print(\"Validation Accuracy: \")\n","  print(m_score)\n","  v_score = np.mean(m_score)\n","  print(v_score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMlk1zNN2ute","colab_type":"code","outputId":"7b0257c6-6692-4b51-c410-3b15e411d113","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1582742227209,"user_tz":-330,"elapsed":44297,"user":{"displayName":"Vipul Singhal","photoUrl":"","userId":"02136150336451900212"}}},"source":["\n","# import random\n","\n","# # Set the seed value all over the place to make this reproducible.\n","# seed_val = 42\n","\n","# random.seed(seed_val)\n","# np.random.seed(seed_val)\n","# torch.manual_seed(seed_val)\n","# torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","            \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[3].to(device)\n","        b_token_starts = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        b_sent_length = batch[4]\n","\n","        model.zero_grad()   \n","        model.train()     \n","\n","        output = model(b_input_ids, b_input_mask, b_labels, b_token_starts,b_sent_length)\n","        loss = output[0]\n","\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","        if step % 10 == 0:\n","          validation(model, validation_dataloader)\n","\n","    # Calculate the average loss over the training data.\n","    # print(\"total loss\",total_loss)\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.09948979591836735, 0.29045092838196285, 0.4431818181818183, 0.5492424242424242]\n","0.3455912416811432\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.44642857142857145, 0.6591511936339522, 0.7594696969696969, 0.7848484848484848]\n","0.6624744867201763\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.46683673469387754, 0.7002652519893899, 0.775568181818182, 0.8295454545454546]\n","0.693053905761726\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5, 0.7254641909814323, 0.7982954545454546, 0.8303030303030303]\n","0.7135156689574793\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5510204081632653, 0.7307692307692307, 0.7982954545454547, 0.843939393939394]\n","0.7310061218543362\n","\n","  Average training loss: 0.53\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5739795918367347, 0.7241379310344828, 0.7992424242424243, 0.8462121212121212]\n","0.7358930170814407\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5994897959183674, 0.7413793103448276, 0.8001893939393938, 0.8446969696969697]\n","0.7464388674748896\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.5994897959183674, 0.7506631299734748, 0.8106060606060607, 0.85]\n","0.7526897466244757\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6198979591836735, 0.7705570291777188, 0.8257575757575758, 0.8537878787878788]\n","0.7675001107267116\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6173469387755102, 0.7652519893899205, 0.8257575757575758, 0.8568181818181818]\n","0.766293671435297\n","\n","  Average training loss: 0.50\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6147959183673469, 0.7692307692307693, 0.8285984848484849, 0.8522727272727273]\n","0.7662244749298321\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6454081632653061, 0.7798408488063661, 0.8210227272727273, 0.8424242424242424]\n","0.7721739954421604\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.625, 0.7718832891246684, 0.8295454545454546, 0.8507575757575757]\n","0.7692965798569247\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6301020408163265, 0.7705570291777188, 0.8219696969696971, 0.85]\n","0.7681571917409357\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6505102040816326, 0.773209549071618, 0.8285984848484848, 0.85]\n","0.7755795595004339\n","\n","  Average training loss: 0.49\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6428571428571429, 0.7718832891246684, 0.8361742424242425, 0.8583333333333333]\n","0.7773120019348468\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6428571428571429, 0.7824933687002652, 0.8333333333333333, 0.8568181818181818]\n","0.7788755066772308\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6530612244897959, 0.7758620689655172, 0.8295454545454544, 0.853030303030303]\n","0.7778747627577677\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7758620689655172, 0.8304924242424243, 0.8545454545454545]\n","0.7791280481628389\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6428571428571429, 0.7798408488063661, 0.8295454545454547, 0.8545454545454545]\n","0.7766972251886045\n","\n","  Average training loss: 0.48\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7824933687002652, 0.8304924242424242, 0.8606060606060606]\n","0.7803877593055548\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6454081632653061, 0.7798408488063661, 0.8267045454545453, 0.8515151515151516]\n","0.7758671772603423\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7838196286472149, 0.8285984848484848, 0.853030303030303]\n","0.778351900049868\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6505102040816326, 0.7944297082228117, 0.831439393939394, 0.853030303030303]\n","0.7823524023185353\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6581632653061225, 0.7931034482758621, 0.8342803030303029, 0.8537878787878788]\n","0.7848337238500416\n","\n","  Average training loss: 0.47\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6607142857142857, 0.7877984084880637, 0.8285984848484849, 0.8553030303030303]\n","0.7831035523384662\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6581632653061225, 0.7758620689655172, 0.824810606060606, 0.8560606060606061]\n","0.7787241365982129\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.673469387755102, 0.7891246684350133, 0.8267045454545454, 0.8568181818181818]\n","0.7865291958657107\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7917771883289124, 0.8257575757575758, 0.85]\n","0.7807867522461118\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7970822281167109, 0.8285984848484849, 0.8598484848484849]\n","0.78528536067791\n","\n","  Average training loss: 0.47\n","\n","======== Epoch 7 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6683673469387755, 0.7944297082228117, 0.8295454545454547, 0.853030303030303]\n","0.7863432031843363\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6607142857142857, 0.7798408488063661, 0.8238636363636364, 0.8462121212121212]\n","0.7776577230241023\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6607142857142857, 0.7798408488063661, 0.8210227272727273, 0.8507575757575757]\n","0.7780838593877386\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6505102040816326, 0.7758620689655172, 0.8229166666666665, 0.8537878787878788]\n","0.7757692046254239\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7652519893899205, 0.8238636363636364, 0.8492424242424242]\n","0.7715793084173626\n","\n","  Average training loss: 0.46\n","\n","======== Epoch 8 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6428571428571429, 0.7718832891246684, 0.8219696969696968, 0.8537878787878788]\n","0.7726245019348468\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6632653061224489, 0.76657824933687, 0.8219696969696971, 0.8507575757575757]\n","0.775642707046648\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6632653061224489, 0.7679045092838196, 0.8267045454545454, 0.8477272727272728]\n","0.7764004083970216\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7851458885941645, 0.8342803030303031, 0.8522727272727273]\n","0.7799145256426661\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6505102040816326, 0.786472148541114, 0.831439393939394, 0.8522727272727273]\n","0.7801736184587169\n","\n","  Average training loss: 0.46\n","\n","======== Epoch 9 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6581632653061225, 0.7798408488063661, 0.8267045454545456, 0.8522727272727273]\n","0.7792453467099405\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.773209549071618, 0.8285984848484849, 0.8492424242424242]\n","0.7766656757651216\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7785145888594165, 0.8314393939393938, 0.85]\n","0.7788915569241924\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7798408488063661, 0.8219696969696971, 0.8431818181818181]\n","0.7751511522139601\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7904509283819628, 0.8267045454545454, 0.8469696969696969]\n","0.7780210886199186\n","\n","  Average training loss: 0.45\n","\n","======== Epoch 10 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6530612244897959, 0.7877984084880637, 0.8257575757575758, 0.8446969696969697]\n","0.7778285446081012\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6479591836734694, 0.7838196286472149, 0.8257575757575757, 0.85]\n","0.7768840970195651\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6505102040816326, 0.7745358090185677, 0.8162878787878789, 0.8454545454545455]\n","0.7716971093356562\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6556122448979592, 0.7745358090185677, 0.8143939393939396, 0.843939393939394]\n","0.7721203468124651\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6377551020408163, 0.7798408488063661, 0.8210227272727274, 0.8507575757575757]\n","0.7723440634693713\n","\n","  Average training loss: 0.45\n","\n","======== Epoch 11 / 30 ========\n","Training...\n","\n","Running Validation...\n","Validation Accuracy: \n","[0.6403061224489796, 0.7771883289124668, 0.8229166666666667, 0.8537878787878788]\n","0.773549749203998\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-469aaaf6151e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"YyrVHMBg3AW4","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwLxg7wN-nhf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}