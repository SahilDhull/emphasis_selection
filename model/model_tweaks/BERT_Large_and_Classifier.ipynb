{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Large_Bert_and_Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilDhull/emphasis_selection/blob/master/model/Large_Bert_and_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFZ3HHuy1mx0",
        "colab_type": "code",
        "outputId": "f1591f5d-ffbc-425c-cee9-75122f9a808f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install config"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: config in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkDAFPU1ps2",
        "colab_type": "code",
        "outputId": "ab73351a-f902-4643-d9ec-9ccb4c915e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForMaskedLM , BertModel ,WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import codecs\n",
        "from torch.nn.utils.rnn import pack_padded_sequence"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhNFcgUa1w1k",
        "colab_type": "code",
        "outputId": "9539aa1d-2a83-4943-b1b9-b74ef5416fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmLIQdgZ1zFP",
        "colab_type": "code",
        "outputId": "45d85db9-a904-44ab-e5e0-9600ccbf0a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/datasets/train.txt'\n",
        "dev_file = 'drive/My Drive/datasets/dev.txt'\n",
        "\n",
        "quotes_file = 'drive/My Drive/datasets/all_quotes.txt'\n",
        "model_file = 'drive/My Drive/datasets/large_bert_finetune/best/pytorch_model.bin'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IplzxoD111cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-large-cased', do_lower_case = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM2bAwze2Ezt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_token_map(file,word_index = 1,prob_index = 4, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  token_labels = []\n",
        "  sent_length = []\n",
        "\n",
        "  bert_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  labels = []\n",
        "\n",
        "  bert_tokens.append(\"[CLS]\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      label = feats[prob_index].lower() if caseless else feats[prob_index]\n",
        "      labels.append((float)(label))\n",
        "      orig_to_tok_map.append(len(bert_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        if(bert_tokens[-1] != \"won\"):\n",
        "          bert_tokens[-1] = bert_tokens[-1] +\"n\"\n",
        "      if(word == \"wo\"):\n",
        "        word == \"won\"\n",
        "\n",
        "      bert_tokens.extend(tokenizer.tokenize(word))\n",
        "     \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      bert_tokens.append(\"[SEP]\")\n",
        "      tokenized_texts.append(bert_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      token_labels.append(labels)\n",
        "      sent_length.append(len(labels))\n",
        "      bert_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      labels = []\n",
        "      length = 0\n",
        "      bert_tokens.append(\"[CLS]\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    bert_tokens.append(\"[SEP]\")\n",
        "    tokenized_texts.append(bert_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    token_labels.append(labels)\n",
        "    sent_length.append(len(labels))\n",
        "  \n",
        "  return tokenized_texts, token_map, token_labels, sent_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IflGdsPR2LmX",
        "colab_type": "code",
        "outputId": "031c0bdd-9f58-4e87-e372-45ea60c6e6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "t_tokenized_texts, t_token_map, t_token_label, t_sent_length = read_token_map(train_file)\n",
        "print(t_tokenized_texts[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])\n",
        "print(t_sent_length[100])\n",
        "\n",
        "d_tokenized_texts, d_token_map, d_token_label, d_sent_length = read_token_map(dev_file)\n",
        "print(d_tokenized_texts[50])\n",
        "print(d_token_map[50])\n",
        "print(d_token_label[50])\n",
        "print(d_sent_length[50])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Happiness', 'consists', 'in', 'realizing', 'it', 'is', 'all', 'a', 'great', 'strange', 'dream', '.', '[SEP]']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n",
            "12\n",
            "['[CLS]', '`', '`', 'F', '##as', '##cin', '##ating', 'social', 'media', 'tip', 'or', 'fact', 'to', 'share', '.', \"'\", \"'\", '@', 'Speaker', 'Name', '[SEP]']\n",
            "[1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19]\n",
            "[0.0, 0.5555555555555556, 0.0, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.0, 0.2222222222222222, 0.2222222222222222]\n",
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IsOd0i2PnP",
        "colab_type": "code",
        "outputId": "6a381000-61c8-4158-ff42-d6df920a0583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "MAX_LEN = 72\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(t_input_ids[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 25410  2923  1107 10459  1122  1110  1155   170  1632  4020  4185\n",
            "   119   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n",
            " 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sllf5eX2TJg",
        "colab_type": "code",
        "outputId": "ee436e9b-00de-43da-9d06-2da9a514339f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(d_input_ids[50])\n",
        "print(d_token_map[50])\n",
        "print(d_token_label[50])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101   169   169   143  2225 16430  3798  1934  2394  5580  1137  1864\n",
            "  1106  2934   119   112   112   137  9911 10208   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
            "[ 1  3  7  8  9 10 11 12 13 14 15 17 19  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0.         0.55555556 0.         0.11111111 0.22222222 0.11111111\n",
            " 0.11111111 0.         0.22222222 0.         0.         0.22222222\n",
            " 0.22222222 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWqYZ8vV2WYx",
        "colab_type": "code",
        "outputId": "8e2a07ba-381f-41a5-b5a4-71676be881ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "t_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in t_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  t_attention_masks.append(seq_mask)\n",
        "print(t_attention_masks[100])\n",
        "\n",
        "d_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in d_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  d_attention_masks.append(seq_mask)\n",
        "print(d_attention_masks[50])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtnslThr2ZnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_input_ids = torch.tensor(t_input_ids)\n",
        "t_token_map = torch.tensor(t_token_map )\n",
        "t_token_label = torch.tensor(t_token_label)\n",
        "t_attention_masks = torch.tensor(t_attention_masks)\n",
        "t_sent_length = torch.tensor(t_sent_length)\n",
        "\n",
        "d_input_ids = torch.tensor(d_input_ids)\n",
        "d_token_map = torch.tensor(d_token_map )\n",
        "d_token_label = torch.tensor(d_token_label)\n",
        "d_attention_masks = torch.tensor(d_attention_masks)\n",
        "d_sent_length = torch.tensor(d_sent_length)\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "# print(t_token_labels)\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks, t_sent_length)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks, d_sent_length)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-F1P6at2kGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3\n",
        "\n",
        "def fix_padding(scores_numpy, label_probs,  mask_numpy):\n",
        "    #if len(scores_numpy) != len(mask_numpy):\n",
        "    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n",
        "    #assert len(scores_numpy) == len(mask_numpy)\n",
        "    #if len(label_probs) != len(mask_numpy):\n",
        "    #    print(\"len(label_probs) != len(mask_numpy)\")\n",
        "    #assert len(label_probs) == len(mask_numpy)\n",
        "\n",
        "    all_scores_no_padd = []\n",
        "    all_labels_no_pad = []\n",
        "    for i in range(len(mask_numpy)):\n",
        "        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n",
        "        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n",
        "\n",
        "    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n",
        "    return all_scores_no_padd, all_labels_no_pad\n",
        "\n",
        "def match_M(batch_scores_no_padd, batch_labels_no_pad):\n",
        "\n",
        "    top_m = [1, 2, 3, 4]\n",
        "    batch_num_m=[]\n",
        "    batch_score_m=[]\n",
        "    for m in top_m:\n",
        "        intersects_lst = []\n",
        "        # exact_lst = []\n",
        "        score_lst = []\n",
        "        ############################################### computing scores:\n",
        "        for s in batch_scores_no_padd:\n",
        "            if len(s) <=m:\n",
        "                continue\n",
        "            h = m\n",
        "            # if len(s) > h:\n",
        "            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n",
        "            #         h += 1\n",
        "\n",
        "            # s = np.asarray(s.cpu())\n",
        "            s = np.asarray(s)\n",
        "            #ind_score = np.argsort(s)[-h:]\n",
        "            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n",
        "            score_lst.append(ind_score)\n",
        "\n",
        "        ############################################### computing labels:\n",
        "        label_lst = []\n",
        "        for l in batch_labels_no_pad:\n",
        "            if len(l) <=m:\n",
        "                continue\n",
        "            # if it contains several top values with the same amount\n",
        "            h = m\n",
        "            # l = l.cpu()\n",
        "            if len(l) > h:\n",
        "                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n",
        "                    h += 1\n",
        "            l = np.asarray(l)\n",
        "            ind_label = np.argsort(l)[-h:]\n",
        "            label_lst.append(ind_label)\n",
        "\n",
        "        ############################################### :\n",
        "\n",
        "        for i in range(len(score_lst)):\n",
        "            intersect = intersection(score_lst[i], label_lst[i])\n",
        "            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n",
        "            # sorted_score_lst = sorted(score_lst[i])\n",
        "            # sorted_label_lst =  sorted(label_lst[i])\n",
        "            # if sorted_score_lst==sorted_label_lst:\n",
        "            #     exact_lst.append(1)\n",
        "            # else:\n",
        "            #     exact_lst.append(0)\n",
        "        batch_num_m.append(len(score_lst))\n",
        "        batch_score_m.append(sum(intersects_lst))\n",
        "    return batch_num_m, batch_score_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRM_nU783HIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_val_accuracy = 0.0\n",
        "\n",
        "def validation(model, validation_dataloader):\n",
        "  global max_val_accuracy\n",
        "  print(\"\\n --> Running Validation...\")\n",
        "\n",
        "  model.eval()\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  num_m = [0, 0, 0, 0]\n",
        "  score_m = [0, 0, 0, 0]\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "      \n",
        "      # Add batch to GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      \n",
        "      # Unpack the inputs from our dataloader\n",
        "      v_input_ids = batch[0].to(device)\n",
        "      v_input_mask = batch[3].to(device)\n",
        "      v_token_starts = batch[1].to(device)\n",
        "      v_labels = batch[2].to(device)\n",
        "      v_sent_length = batch[4]\n",
        "            \n",
        "      # Telling the model not to compute or store gradients, saving memory and\n",
        "      # speeding up validation\n",
        "      with torch.no_grad():        \n",
        "          output = model(v_input_ids, v_input_mask, v_labels, v_token_starts, v_sent_length)\n",
        "      \n",
        "      pred_labels = output[1]\n",
        "\n",
        "      pred_labels = pred_labels.detach().cpu().numpy()\n",
        "      v_labels = v_labels.to('cpu').numpy()\n",
        "      # print(pred_labels[0])\n",
        "      # print(v_labels[0])\n",
        "      \n",
        "      pred_labels, v_labels = fix_padding(pred_labels, v_labels, v_sent_length)\n",
        "      # print(pred_labels[0])\n",
        "      # print(v_labels[0])\n",
        "\n",
        "      batch_num_m, batch_score_m = match_M(pred_labels, v_labels)\n",
        "      num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n",
        "      score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n",
        "  \n",
        "  m_score = [i/j for i,j in zip(score_m, num_m)]\n",
        "  print(\"Validation Accuracy: \")\n",
        "  print(m_score)\n",
        "  v_score = np.mean(m_score)\n",
        "  print(v_score)\n",
        "  max_val_accuracy = max(max_val_accuracy,v_score)\n",
        "  print(\"\\nMax Accuracy:\")\n",
        "  print(max_val_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODH9sTED18Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avg(a, st, end):\n",
        "  k = a\n",
        "  lis = []\n",
        "  for i in range(st,end):\n",
        "    lis.append(a[i])\n",
        "  x = torch.mean(torch.stack(lis),dim=0)\n",
        "  return x\n",
        "\n",
        "class bert_model(nn.Module):\n",
        "  def __init__(self, model_name, final_size, drop_prob, data_parallel=True):\n",
        "    super(bert_model, self).__init__()\n",
        "\n",
        "    config = BertConfig.from_pretrained('bert-large-cased', output_hidden_states=True)\n",
        "    bert = BertForMaskedLM.from_pretrained(model_name, config = config)\n",
        "\n",
        "    # for name, param in bert.bert.named_parameters():\n",
        "    #   if name.startswith('embeddings'):\n",
        "    #     param.requires_grad = False\n",
        "\n",
        "    # for i in range(0,12):\n",
        "    #   for name, param in bert.bert.encoder.layer[i].named_parameters():\n",
        "    #       param.requires_grad = False\n",
        "\n",
        "    # for name, param in bert.named_parameters():                \n",
        "    #   if param.requires_grad:\n",
        "    #     print(name)\n",
        "\n",
        "    if data_parallel:\n",
        "        self.bert = nn.DataParallel(bert)\n",
        "    else:\n",
        "        self.bert = bert\n",
        "    bert_emb_dim = 1024\n",
        "    # 768 for bert-base-cased, 1024 for bert-large-cased\n",
        "    bert_dim = 24*bert_emb_dim\n",
        "    hidden_dim1 = 900\n",
        "    # hidden_dim2 = 200\n",
        "    hidden_dim3 = 50\n",
        "\n",
        "    self.fc1 = nn.Linear(bert_dim, hidden_dim1)\n",
        "    self.fc2 = nn.Linear(hidden_dim1, hidden_dim3)\n",
        "    # self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
        "    self.fc4 = nn.Linear(hidden_dim3, final_size)\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "           \n",
        "  def forward(self, bert_ids, bert_mask, labels = None, bert_token_starts = None,lm_lengths = None):\n",
        "    \n",
        "    batch_size = bert_ids.size()[0]\n",
        "    pad_size = bert_ids.size()[1]\n",
        "    # print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n",
        "\n",
        "    if(bert_token_starts == None):\n",
        "      output = self.bert(bert_ids, attention_mask = bert_mask, masked_lm_labels=labels)\n",
        "      return output\n",
        "    \n",
        "    output = self.bert(bert_ids, attention_mask = bert_mask)\n",
        "\n",
        "    bert_out = output[1][0]\n",
        "    for layers in range(1,24,1):\n",
        "      bert_out = torch.cat((bert_out, output[1][layers]), dim=2)\n",
        "    \n",
        "    \n",
        "    pred_logits = torch.relu(self.fc1(self.dropout(bert_out)))\n",
        "    pred_logits = torch.relu(self.fc2(self.dropout(pred_logits)))\n",
        "    # pred_logits = torch.relu(self.fc3(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.sigmoid(self.fc4(self.dropout(pred_logits)))\n",
        "    pred_logits = torch.squeeze(pred_logits,2)\n",
        "\n",
        "    pred_labels = labels.clone()\n",
        "    # print(pred_labels[1])\n",
        "    # print(\"\\n\")\n",
        "    \n",
        "    for b in range(batch_size):\n",
        "      for w in range(pad_size):\n",
        "        if(bert_token_starts[b][w]!=0):\n",
        "          if(bert_token_starts[b][w]>=pad_size):\n",
        "            print(bert_token_starts[b])\n",
        "          else:\n",
        "            pred_labels[b][w] = pred_logits[b][bert_token_starts[b][w]]\n",
        "            # st = bert_token_starts[b][w]\n",
        "            # end = bert_token_starts[b][w+1]\n",
        "            # if(end==0):\n",
        "            #   # break\n",
        "            #   end = st+1\n",
        "            #   while(bert_mask[b][end]!=0):\n",
        "            #     end = end+1\n",
        "            # pred_labels[b][w] = avg(pred_logits[b],st,end)\n",
        "\n",
        "    lm_lengths, lm_sort_ind = lm_lengths.sort(dim=0, descending=True)\n",
        "    scores = labels[lm_sort_ind]\n",
        "    targets = pred_labels[lm_sort_ind]\n",
        "    scores = pack_padded_sequence(scores, lm_lengths, batch_first=True).data\n",
        "    targets = pack_padded_sequence(targets, lm_lengths, batch_first=True).data\n",
        "\n",
        "    loss_fn = nn.BCELoss().to(device) \n",
        "    loss = loss_fn(targets,scores)\n",
        "\n",
        "    return loss, pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJSJ0eki2gWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = bert_model('bert-large-cased', 1, 0.3, True).to(device)\n",
        "model = bert_model(model_file, 1, 0.3, True).to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n",
        "\n",
        "epochs = 15\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMlk1zNN2ute",
        "colab_type": "code",
        "outputId": "158b430e-93c2-4c49-b634-87fac23c57e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_val_accuracy = 0.0\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "            \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[3].to(device)\n",
        "        b_token_starts = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_sent_length = batch[4]\n",
        "\n",
        "        model.zero_grad()   \n",
        "        model.train()     \n",
        "\n",
        "        output = model(b_input_ids, b_input_mask, b_labels, b_token_starts,b_sent_length)\n",
        "        loss = output[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "        if step % 20 == 0:\n",
        "          validation(model, validation_dataloader)\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.5f}\".format(avg_train_loss))\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.3622448979591837, 0.46684350132625996, 0.5568181818181818, 0.6075757575757575]\n",
            "0.49837058466984574\n",
            "\n",
            "Max Accuracy:\n",
            "0.49837058466984574\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5331632653061225, 0.7122015915119363, 0.7869318181818183, 0.8143939393939394]\n",
            "0.7116726535984541\n",
            "\n",
            "Max Accuracy:\n",
            "0.7116726535984541\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5510204081632653, 0.7506631299734748, 0.7982954545454547, 0.8340909090909091]\n",
            "0.733517475443276\n",
            "\n",
            "Max Accuracy:\n",
            "0.733517475443276\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.5841836734693877, 0.7506631299734748, 0.806818181818182, 0.8446969696969697]\n",
            "0.7465904887395036\n",
            "\n",
            "Max Accuracy:\n",
            "0.7465904887395036\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.625, 0.7625994694960212, 0.8134469696969696, 0.8469696969696969]\n",
            "0.762004034040672\n",
            "\n",
            "Max Accuracy:\n",
            "0.762004034040672\n",
            "\n",
            "  Average training loss: 0.52081\n",
            "\n",
            "======== Epoch 2 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6301020408163265, 0.7705570291777188, 0.8153409090909091, 0.8575757575757575]\n",
            "0.768393934165178\n",
            "\n",
            "Max Accuracy:\n",
            "0.768393934165178\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7785145888594165, 0.8333333333333333, 0.8553030303030303]\n",
            "0.7794152891443532\n",
            "\n",
            "Max Accuracy:\n",
            "0.7794152891443532\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7771883289124668, 0.8352272727272727, 0.8507575757575757]\n",
            "0.778420845369737\n",
            "\n",
            "Max Accuracy:\n",
            "0.7794152891443532\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.7838196286472149, 0.8333333333333333, 0.8560606060606061]\n",
            "0.7815686981327375\n",
            "\n",
            "Max Accuracy:\n",
            "0.7815686981327375\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7877984084880637, 0.8323863636363636, 0.8553030303030303]\n",
            "0.7846882771374767\n",
            "\n",
            "Max Accuracy:\n",
            "0.7846882771374767\n",
            "\n",
            "  Average training loss: 0.48597\n",
            "\n",
            "======== Epoch 3 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6658163265306123, 0.7904509283819628, 0.8304924242424243, 0.8522727272727273]\n",
            "0.7847581016069316\n",
            "\n",
            "Max Accuracy:\n",
            "0.7847581016069316\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.673469387755102, 0.7891246684350133, 0.8285984848484845, 0.8477272727272728]\n",
            "0.7847299534414681\n",
            "\n",
            "Max Accuracy:\n",
            "0.7847581016069316\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.786472148541114, 0.8323863636363636, 0.8522727272727273]\n",
            "0.785512401699286\n",
            "\n",
            "Max Accuracy:\n",
            "0.785512401699286\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6658163265306123, 0.7824933687002652, 0.8361742424242425, 0.8598484848484849]\n",
            "0.7860831056259012\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6760204081632653, 0.7811671087533156, 0.8257575757575758, 0.8553030303030303]\n",
            "0.7845620307442968\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.47084\n",
            "\n",
            "======== Epoch 4 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6811224489795918, 0.7718832891246684, 0.8276515151515151, 0.8469696969696969]\n",
            "0.781906737556368\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.673469387755102, 0.7758620689655172, 0.819128787878788, 0.8507575757575757]\n",
            "0.7798044550892457\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6658163265306123, 0.7838196286472149, 0.8238636363636364, 0.8575757575757575]\n",
            "0.7827688372793052\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.786472148541114, 0.8276515151515151, 0.8560606060606061]\n",
            "0.783362393968921\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6607142857142857, 0.76657824933687, 0.8219696969696969, 0.8484848484848485]\n",
            "0.7744367701264253\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.45921\n",
            "\n",
            "======== Epoch 5 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6709183673469388, 0.7692307692307693, 0.8248106060606062, 0.8507575757575757]\n",
            "0.7789293295989725\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7705570291777188, 0.8219696969696971, 0.8522727272727273]\n",
            "0.777016189885648\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7639257294429708, 0.8200757575757577, 0.85]\n",
            "0.7724034329791719\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7758620689655172, 0.8238636363636364, 0.8522727272727273]\n",
            "0.7756271591708783\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7758620689655172, 0.8210227272727274, 0.8462121212121212]\n",
            "0.7746772905870812\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.45178\n",
            "\n",
            "======== Epoch 6 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7745358090185677, 0.8267045454545454, 0.8515151515151516]\n",
            "0.7758164275174744\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7758620689655172, 0.8276515151515151, 0.8515151515151516]\n",
            "0.7795735104386582\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6428571428571429, 0.773209549071618, 0.8257575757575758, 0.8575757575757575]\n",
            "0.7748500063155235\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.7771883289124668, 0.824810606060606, 0.8553030303030303]\n",
            "0.7775907974414747\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6581632653061225, 0.7705570291777188, 0.8267045454545454, 0.8537878787878788]\n",
            "0.7773031796815664\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.44555\n",
            "\n",
            "======== Epoch 7 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6607142857142857, 0.773209549071618, 0.831439393939394, 0.8507575757575757]\n",
            "0.7790302011207183\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6581632653061225, 0.7679045092838196, 0.8267045454545453, 0.85]\n",
            "0.7756930800111219\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6454081632653061, 0.7705570291777188, 0.8314393939393938, 0.8522727272727273]\n",
            "0.7749193284137865\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7705570291777188, 0.8219696969696969, 0.8492424242424242]\n",
            "0.7743453488219497\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6556122448979592, 0.7705570291777188, 0.824810606060606, 0.8515151515151516]\n",
            "0.7756237579128589\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.44182\n",
            "\n",
            "======== Epoch 8 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7718832891246684, 0.8181818181818182, 0.85]\n",
            "0.7726438278470299\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6403061224489796, 0.7705570291777188, 0.8200757575757575, 0.8515151515151516]\n",
            "0.7706135151794018\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6403061224489796, 0.7679045092838196, 0.819128787878788, 0.8522727272727273]\n",
            "0.7699030367210786\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7718832891246684, 0.8285984848484849, 0.8522727272727273]\n",
            "0.7758161763318783\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.773209549071618, 0.8285984848484848, 0.85]\n",
            "0.7762173146024747\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.43789\n",
            "\n",
            "======== Epoch 9 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6505102040816326, 0.7705570291777188, 0.8285984848484849, 0.8560606060606061]\n",
            "0.7764315810421106\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6479591836734694, 0.773209549071618, 0.8285984848484848, 0.8568181818181818]\n",
            "0.7766463498529386\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6632653061224489, 0.7745358090185677, 0.8229166666666667, 0.8522727272727273]\n",
            "0.7782476272701027\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6607142857142857, 0.7679045092838196, 0.8191287878787878, 0.8507575757575757]\n",
            "0.7746262896586171\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6581632653061225, 0.773209549071618, 0.8153409090909091, 0.853030303030303]\n",
            "0.7749360066247382\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.43571\n",
            "\n",
            "======== Epoch 10 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6530612244897959, 0.7692307692307693, 0.8172348484848487, 0.85]\n",
            "0.7723817105513535\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6454081632653061, 0.7679045092838196, 0.8172348484848485, 0.8515151515151516]\n",
            "0.7705156681372815\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6454081632653061, 0.7679045092838196, 0.8162878787878788, 0.8522727272727273]\n",
            "0.7704683196524329\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6454081632653061, 0.7705570291777188, 0.8219696969696971, 0.853030303030303]\n",
            "0.7727412981107563\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6454081632653061, 0.7692307692307693, 0.8162878787878789, 0.8507575757575757]\n",
            "0.7704210967603825\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            "  Average training loss: 0.43341\n",
            "\n",
            "======== Epoch 11 / 15 ========\n",
            "Training...\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6428571428571429, 0.7679045092838196, 0.8172348484848487, 0.8507575757575757]\n",
            "0.7696885190958467\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n",
            "Validation Accuracy: \n",
            "[0.6428571428571429, 0.7705570291777188, 0.819128787878788, 0.8537878787878788]\n",
            "0.7715827096753822\n",
            "\n",
            "Max Accuracy:\n",
            "0.7860831056259012\n",
            "\n",
            " --> Running Validation...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4b854073c482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m           \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5f1254a233aa>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(model, validation_dataloader)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# speeding up validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_input_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_token_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_sent_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b5bd48adbabe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, bert_ids, bert_mask, labels, bert_token_starts, lm_lengths)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_token_starts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m           \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_token_starts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mpad_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_token_starts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyrVHMBg3AW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}