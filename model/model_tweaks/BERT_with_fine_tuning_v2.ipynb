{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_with_fine_tuning_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2HD+PsG0BC9dvwoN8p0hz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b4c553c919a42949ac803ea56d19642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec4611b133cf487fb4ec6b1afc9cfa66",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4edcbc7015340d9a8966c293bc7ea6a",
              "IPY_MODEL_88c9880fcfde44838ca2730d5e3be6b6"
            ]
          }
        },
        "ec4611b133cf487fb4ec6b1afc9cfa66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4edcbc7015340d9a8966c293bc7ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_851a278b826c460a8d836f01417dafab",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fea4241e8b947cd9aba19f970aa1167"
          }
        },
        "88c9880fcfde44838ca2730d5e3be6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc8fd141529e4131b91acef5a671b3ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 213k/213k [00:00&lt;00:00, 2.39MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_184f74ec31cf4d6e94512620bf618cab"
          }
        },
        "851a278b826c460a8d836f01417dafab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fea4241e8b947cd9aba19f970aa1167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc8fd141529e4131b91acef5a671b3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "184f74ec31cf4d6e94512620bf618cab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilDhull/emphasis_selection/blob/master/model/bert_with_fine_tuning_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw-WHt68c4q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "ce58e6c4-d618-46d5-ef5a-e7d974a93b74"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install config"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: config in /usr/local/lib/python3.6/dist-packages (0.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m55-6V8SdEhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForMaskedLM , BertModel ,WEIGHTS_NAME, AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer , BertPreTrainedModel\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Kg45-AdHcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3facec0-ff78-4551-d1ce-fa7bf8c8ec08"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ThL71gXdKlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b8a72e2-c20f-4b25-e737-822b648b57c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file = 'drive/My Drive/datasets/train.txt'\n",
        "dev_file = 'drive/My Drive/datasets/dev.txt'\n",
        "\n",
        "quotes_file = 'drive/My Drive/datasets/all_quotes.txt'"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Oj5o9adYRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_sent(file, caseless = False):\n",
        "    \n",
        "    with codecs.open(file, 'r', 'utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    #print(lines)\n",
        "    sent = \"\"\n",
        "    sents = []\n",
        "    \n",
        "    for line in lines:\n",
        "        if not (line.isspace()):\n",
        "            feats = line.strip().split()\n",
        "            word = feats[0].lower() if caseless else feats[0]\n",
        "            if(word == \"n't\"):\n",
        "              word = \"'t\"\n",
        "              sent = sent + \"n\"\n",
        "            sent = sent + \" \" + word\n",
        "        elif len(sent) > 0:\n",
        "            sents.append(sent.strip())\n",
        "            sent = \"\"\n",
        "            \n",
        "    if len(sent) > 0:\n",
        "        sents.append(sent)\n",
        "    \n",
        "    return sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mncat6NVuwdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOVwHCdUdj8E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "1b4c553c919a42949ac803ea56d19642",
            "ec4611b133cf487fb4ec6b1afc9cfa66",
            "b4edcbc7015340d9a8966c293bc7ea6a",
            "88c9880fcfde44838ca2730d5e3be6b6",
            "851a278b826c460a8d836f01417dafab",
            "5fea4241e8b947cd9aba19f970aa1167",
            "cc8fd141529e4131b91acef5a671b3ad",
            "184f74ec31cf4d6e94512620bf618cab"
          ]
        },
        "outputId": "8381a037-f470-49e9-d0a5-7edc29469b6f"
      },
      "source": [
        "sentences = read_sent(quotes_file)\n",
        "print(sentences[0])\n",
        "print(sentences[100])\n",
        "\n",
        "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in sentences]\n",
        "print(sentences[0])\n",
        "print(sentences[100])\n",
        "\n",
        "# Tokenize with BERT tokenizer\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (tokenized_texts[0])\n",
        "print (tokenized_texts[100])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You know you 're in love when you can 't fall asleep because reality is finally better than your dreams .\n",
            "A half-read book is a half-finished love affair .\n",
            "[CLS] You know you 're in love when you can 't fall asleep because reality is finally better than your dreams . [SEP]\n",
            "[CLS] A half-read book is a half-finished love affair . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b4c553c919a42949ac803ea56d19642",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "['[CLS]', 'You', 'know', 'you', \"'\", 're', 'in', 'love', 'when', 'you', 'can', \"'\", 't', 'fall', 'asleep', 'because', 'reality', 'is', 'finally', 'better', 'than', 'your', 'dreams', '.', '[SEP]']\n",
            "['[CLS]', 'A', 'half', '-', 'read', 'book', 'is', 'a', 'half', '-', 'finished', 'love', 'affair', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63A92mIqdnZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "24880a59-08fc-41b9-e5f5-0976286fb672"
      },
      "source": [
        "MAX_LEN = 36\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "print(input_ids[0])\n",
        "print(input_ids[100])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 101 1192 1221 1128  112 1231 1107 1567 1165 1128 1169  112  189 2303\n",
            " 6153 1272 3958 1110 1921 1618 1190 1240 6149  119  102    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "[ 101  138 1544  118 2373 1520 1110  170 1544  118 1845 1567 7033  119\n",
            "  102    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic9QrWZ7fIhB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ade35c15-a9ae-4290-8ba2-99d10619443a"
      },
      "source": [
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)\n",
        "print(attention_masks[0])\n",
        "print(attention_masks[100])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPm_54FwfL0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs = train_test_split(input_ids, random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)\n",
        "                                             \n",
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# Select a batch size for training. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVqKx1jmVfig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mask_tokens(inputs, tokenizer, mlm_probability = 0.15):\n",
        "    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n",
        "    labels = inputs.clone()\n",
        "    # print(inputs[0])\n",
        "\n",
        "    # We sample a few tokens in each sequence for masked-LM training (with probability mlm_probability defaults to 0.15 in Bert/RoBERTa)\n",
        "    probability_matrix = torch.full(labels.shape, mlm_probability)\n",
        "    special_tokens_mask = [tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()]\n",
        "    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n",
        " \n",
        "    if tokenizer._pad_token is not None:\n",
        "        padding_mask = labels.eq(tokenizer.pad_token_id)\n",
        "        probability_matrix.masked_fill_(padding_mask, value=0.0)\n",
        "\n",
        "    masked_indices = torch.bernoulli(probability_matrix).bool()\n",
        "    labels[~masked_indices] = -100  # We only compute loss on masked tokens\n",
        "\n",
        "    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n",
        "    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\n",
        "    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
        "\n",
        "    # 10% of the time, we replace masked input tokens with random word\n",
        "    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\n",
        "    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)\n",
        "    inputs[indices_random] = random_words[indices_random]\n",
        "\n",
        "    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n",
        "    return inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrHN1mVqeUVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mtR-BOWyn2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bert_model(nn.Module):\n",
        "  def __init__(self, final_size, drop_prob, data_parallel=True):\n",
        "    super(bert_model, self).__init__()\n",
        "\n",
        "    config = BertConfig.from_pretrained('bert-base-cased', output_hidden_states=True)\n",
        "    bert = BertForMaskedLM.from_pretrained('bert-base-cased', config = config)\n",
        "    \n",
        "    if data_parallel:\n",
        "        self.bert = nn.DataParallel(bert)\n",
        "    else:\n",
        "        self.bert = bert\n",
        "    bert_dim = 768\n",
        "    \n",
        "    self.fc = nn.Linear(bert_dim, final_size)\n",
        "    self.dropout = nn.Dropout(p=drop_prob)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "           \n",
        "  def forward(self, bert_ids, bert_mask, labels = None, bert_token_starts = None):\n",
        "    \n",
        "    batch_size = bert_ids.size()[0]\n",
        "    pad_size = bert_ids.size()[1]\n",
        "    # print(\"batch size\",batch_size,\"\\t\\tpad_size\",pad_size)\n",
        "\n",
        "    if(bert_token_starts == None):\n",
        "      output = self.bert(bert_ids, attention_mask = bert_mask, masked_lm_labels=labels)\n",
        "      return output\n",
        "    \n",
        "    output = self.bert(bert_ids, attention_mask = bert_mask)\n",
        "    # print(len(output))\n",
        "    # print(len(output[1]))\n",
        "    # print(output[1][0].size())\n",
        "    bert_last_layer = output[1][0]\n",
        "    \n",
        "    pred_logits = self.sigmoid(self.fc(self.dropout(bert_last_layer)))\n",
        "    pred_logits = torch.squeeze(pred_logits,2)\n",
        "    # print(pred_logits.size())\n",
        "    # print(labels.size())\n",
        "    # print(pred_logits[1])\n",
        "    # print(labels[1])\n",
        "    # print(bert_token_starts[1])\n",
        "    # print(\"\\n\")\n",
        "\n",
        "    pred_labels = labels.clone()\n",
        "    # print(pred_labels[1])\n",
        "    # print(\"\\n\")\n",
        "    \n",
        "    for b in range(batch_size):\n",
        "      for w in range(pad_size):\n",
        "        if(bert_token_starts[b][w]!=0):\n",
        "          if(bert_token_starts[b][w]>=pad_size):\n",
        "            print(bert_token_starts[b])\n",
        "          else:\n",
        "            pred_labels[b][w] = pred_logits[b][bert_token_starts[b][w]]\n",
        "\n",
        "    # print(pred_labels[1])\n",
        "    # print(labels[1])\n",
        "    # print(\"\\n\")\n",
        "    \n",
        "    \n",
        "    mask = pred_labels!=0\n",
        "    total = mask[mask].size()[0]\n",
        "\n",
        "    loss_fn = nn.BCELoss(reduction='sum').to(device) \n",
        "    loss = loss_fn(pred_labels, labels)\n",
        "    # print(loss)\n",
        "\n",
        "    loss /= total \n",
        "    print(loss) \n",
        "    return loss, pred_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGMNHPlz1MY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = bert_model(1,0.3,True).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gU-4T0d4Jjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig.from_pretrained('bert-base-cased', output_hidden_states=True)\n",
        "\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-cased', config = config)\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHyzgYhKG3WC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 4\n",
        "max_steps = len(train_dataloader)*max_epochs\n",
        "\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=max_steps/20, num_training_steps=max_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcGSLSve3DJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, tokenizer, validation_dataloader):\n",
        "  total_loss = 0\n",
        "  steps = len(validation_dataloader)\n",
        "  model.eval()\n",
        "  \n",
        "  corrects = 0\n",
        "  errors = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (val_inputs, val_masks) in enumerate(validation_dataloader):\n",
        "      inputs, labels = mask_tokens(val_inputs, tokenizer)\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      val_masks = val_masks.to(device)\n",
        "      \n",
        "      output = model(inputs,val_masks)\n",
        "      predict = output[0]\n",
        "\n",
        "      batch_size = predict.size()[0]\n",
        "\n",
        "      for bs in range(batch_size):\n",
        "        ii = 0\n",
        "        for ls in labels[bs]:\n",
        "          ls = ls.item()\n",
        "          if ls!=-100:\n",
        "            predicted = torch.argmax(predict[bs][ii]).item()\n",
        "            if(ls == predicted):\n",
        "              corrects = corrects + 1\n",
        "            else:\n",
        "              errors = errors + 1\n",
        "          ii = ii + 1\n",
        "\n",
        "  total = corrects + errors\n",
        "  accuracy = corrects/total\n",
        "  print(\"\\nvalidation accuracy = \",accuracy,\"\\t for\",total,\"masks on validation data\\n\")\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N4kQ8kXFOrfY",
        "colab": {}
      },
      "source": [
        "def train(train_dataloader,validation_dataloader, model, tokenizer, optimizer, scheduler, max_epochs, print_freq = 30,val_freq = 666):\n",
        "  \n",
        "  model.zero_grad()\n",
        "  steps = len(train_dataloader)\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    \n",
        "    evaluate(model, tokenizer, validation_dataloader)\n",
        "    total_loss = 0\n",
        "    \n",
        "    for i, (train_inputs, train_masks) in enumerate(train_dataloader):\n",
        "      inputs, labels = mask_tokens(train_inputs, tokenizer)\n",
        "      model.train()\n",
        "      \n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      train_masks = train_masks.to(device)\n",
        "      \n",
        "      output = model(inputs,train_masks, labels=labels)\n",
        "      \n",
        "      loss = output[0]\n",
        "      total_loss = total_loss + loss\n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      model.zero_grad()\n",
        "\n",
        "      if((i+1)%print_freq==0):\n",
        "        avg_loss = total_loss/print_freq\n",
        "        total_loss = 0\n",
        "        print(\"epoch:\",(epoch+1),\"out of\",max_epochs,\"\\t batch:\",(i+1),\"out of\",steps,\"\\t average loss:\",avg_loss)   \n",
        "      \n",
        "      if((i+1)%val_freq==0):\n",
        "        evaluate(model, tokenizer, validation_dataloader)\n",
        "  \n",
        "  evaluate(model, tokenizer, validation_dataloader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPRSboo07YL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "5e1a28cd-1bde-4b90-e6fb-ef8c07151b6b"
      },
      "source": [
        "train(train_dataloader,validation_dataloader, model, tokenizer, optimizer, scheduler, max_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation accuracy =  0.5304349259735549 \t for 60654 masks on validation data\n",
            "\n",
            "epoch: 1 out of 4 \t batch: 30 out of 6633 \t average loss: tensor(2.9017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 60 out of 6633 \t average loss: tensor(2.8847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 90 out of 6633 \t average loss: tensor(3.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 120 out of 6633 \t average loss: tensor(2.7733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 150 out of 6633 \t average loss: tensor(2.9001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 180 out of 6633 \t average loss: tensor(2.9081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 210 out of 6633 \t average loss: tensor(2.8629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 240 out of 6633 \t average loss: tensor(2.8670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 270 out of 6633 \t average loss: tensor(2.5869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 300 out of 6633 \t average loss: tensor(2.7931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 330 out of 6633 \t average loss: tensor(2.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 360 out of 6633 \t average loss: tensor(2.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 390 out of 6633 \t average loss: tensor(2.6285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch: 1 out of 4 \t batch: 420 out of 6633 \t average loss: tensor(2.5533, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-0644ccae4a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-a028d13c6741>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, validation_dataloader, model, tokenizer, optimizer, scheduler, max_epochs, print_freq, val_freq)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RExZHuTz7LVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_token_map(file,word_index = 1,prob_index = 4, caseless = False):\n",
        "  \n",
        "  with codecs.open(file, 'r', 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "\n",
        "  tokenized_texts = []\n",
        "  token_map = []\n",
        "  token_labels = []\n",
        "\n",
        "  bert_tokens = []\n",
        "  orig_to_tok_map = []\n",
        "  labels = []\n",
        "\n",
        "  bert_tokens.append(\"[CLS]\")\n",
        "  \n",
        "  for line in lines:\n",
        "    if not (line.isspace()):\n",
        "      feats = line.strip().split()\n",
        "      word = feats[word_index].lower() if caseless else feats[word_index]\n",
        "      label = feats[prob_index].lower() if caseless else feats[prob_index]\n",
        "      labels.append((float)(label))\n",
        "      orig_to_tok_map.append(len(bert_tokens))\n",
        "      \n",
        "      if(word == \"n't\"):\n",
        "        word = \"'t\"\n",
        "        if(bert_tokens[-1] != \"won\"):\n",
        "          bert_tokens[-1] = bert_tokens[-1] +\"n\"\n",
        "      if(word == \"wo\"):\n",
        "        word == \"won\"\n",
        "\n",
        "      bert_tokens.extend(tokenizer.tokenize(word))\n",
        "      \n",
        "    elif len(orig_to_tok_map) > 0:\n",
        "      bert_tokens.append(\"[SEP]\")\n",
        "      tokenized_texts.append(bert_tokens)\n",
        "      token_map.append(orig_to_tok_map)\n",
        "      token_labels.append(labels)\n",
        "      bert_tokens = []\n",
        "      orig_to_tok_map = []\n",
        "      labels = []\n",
        "      bert_tokens.append(\"[CLS]\")\n",
        "          \n",
        "  if len(orig_to_tok_map) > 0:\n",
        "    bert_tokens.append(\"[SEP]\")\n",
        "    tokenized_texts.append(bert_tokens)\n",
        "    token_map.append(orig_to_tok_map)\n",
        "    token_labels.append(labels)\n",
        "  \n",
        "  return tokenized_texts, token_map, token_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UBnIXiL7stu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a05d3cce-cc4e-4151-f054-e6231c83e1e3"
      },
      "source": [
        "t_tokenized_texts, t_token_map, t_token_label = read_token_map(train_file)\n",
        "print(t_tokenized_texts[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])\n",
        "\n",
        "d_tokenized_texts, d_token_map, d_token_label = read_token_map(dev_file)\n",
        "print(d_tokenized_texts[50])\n",
        "print(d_token_map[50])\n",
        "print(d_token_label[50])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'Happiness', 'consists', 'in', 'realizing', 'it', 'is', 'all', 'a', 'great', 'strange', 'dream', '.', '[SEP]']\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "[0.6666666666666666, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.3333333333333333, 0.3333333333333333, 0.1111111111111111]\n",
            "['[CLS]', '`', '`', 'F', '##as', '##cin', '##ating', 'social', 'media', 'tip', 'or', 'fact', 'to', 'share', '.', \"'\", \"'\", '@', 'Speaker', 'Name', '[SEP]']\n",
            "[1, 3, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19]\n",
            "[0.0, 0.5555555555555556, 0.0, 0.1111111111111111, 0.2222222222222222, 0.1111111111111111, 0.1111111111111111, 0.0, 0.2222222222222222, 0.0, 0.0, 0.2222222222222222, 0.2222222222222222]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecVcCS3077Mn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2767b913-6cf1-404a-9463-55140491dd3c"
      },
      "source": [
        "MAX_LEN = 52\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "t_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in t_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "t_input_ids = pad_sequences(t_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_map = pad_sequences(t_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "t_token_label = pad_sequences(t_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(t_input_ids[100])\n",
        "print(t_token_map[100])\n",
        "print(t_token_label[100])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101 25410  2923  1107 10459  1122  1110  1155   170  1632  4020  4185\n",
            "   119   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[ 1  2  3  4  5  6  7  8  9 10 11 12  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0]\n",
            "[0.66666667 0.11111111 0.         0.22222222 0.         0.11111111\n",
            " 0.11111111 0.         0.22222222 0.33333333 0.33333333 0.11111111\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqzlSGGtAlx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7f3df9de-5363-46cb-e582-b94aa6ad032f"
      },
      "source": [
        "d_input_ids = [tokenizer.convert_tokens_to_ids(x) for x in d_tokenized_texts]\n",
        "\n",
        "# Pad our input tokens\n",
        "d_input_ids = pad_sequences(d_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_map = pad_sequences(d_token_map, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "d_token_label = pad_sequences(d_token_label, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(d_input_ids[50])\n",
        "print(d_token_map[50])\n",
        "print(d_token_label[50])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  101   169   169   143  2225 16430  3798  1934  2394  5580  1137  1864\n",
            "  1106  2934   119   112   112   137  9911 10208   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[ 1  3  7  8  9 10 11 12 13 14 15 17 19  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0]\n",
            "[0.         0.55555556 0.         0.11111111 0.22222222 0.11111111\n",
            " 0.11111111 0.         0.22222222 0.         0.         0.22222222\n",
            " 0.22222222 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4P9kr3cAoal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "774034b7-9e02-4aa6-ba22-6b16d236cefc"
      },
      "source": [
        "t_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in t_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  t_attention_masks.append(seq_mask)\n",
        "print(t_attention_masks[100])\n",
        "\n",
        "d_attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in d_input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  d_attention_masks.append(seq_mask)\n",
        "print(d_attention_masks[50])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgWugxCdArU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t_input_ids = torch.tensor(t_input_ids)\n",
        "t_token_map = torch.tensor(t_token_map )\n",
        "t_token_label = torch.tensor(t_token_label)\n",
        "t_attention_masks = torch.tensor(t_attention_masks)\n",
        "\n",
        "d_input_ids = torch.tensor(d_input_ids)\n",
        "d_token_map = torch.tensor(d_token_map )\n",
        "d_token_label = torch.tensor(d_token_label)\n",
        "d_attention_masks = torch.tensor(d_attention_masks)\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "# print(t_token_labels)\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(t_input_ids, t_token_map, t_token_label, t_attention_masks)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(d_input_ids, d_token_map, d_token_label, d_attention_masks)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6lh_ECgAuNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr=2e-4, eps = 1e-8)\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H7cTPb_A2vL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoZnP_xUBAB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def intersection(lst1, lst2):\n",
        "    lst3 = [value for value in lst1 if value in lst2]\n",
        "    return lst3\n",
        "\n",
        "def fix_padding(scores_numpy, label_probs,  mask_numpy):\n",
        "    #if len(scores_numpy) != len(mask_numpy):\n",
        "    #    print(\"Error: len(scores_numpy) != len(mask_numpy)\")\n",
        "    #assert len(scores_numpy) == len(mask_numpy)\n",
        "    #if len(label_probs) != len(mask_numpy):\n",
        "    #    print(\"len(label_probs) != len(mask_numpy)\")\n",
        "    #assert len(label_probs) == len(mask_numpy)\n",
        "\n",
        "    all_scores_no_padd = []\n",
        "    all_labels_no_pad = []\n",
        "    for i in range(len(mask_numpy)):\n",
        "        all_scores_no_padd.append(scores_numpy[i][:int(mask_numpy[i])])\n",
        "        all_labels_no_pad.append(label_probs[i][:int(mask_numpy[i])])\n",
        "\n",
        "    assert len(all_scores_no_padd) == len(all_labels_no_pad)\n",
        "    return all_scores_no_padd, all_labels_no_pad\n",
        "\n",
        "def match_M(batch_scores_no_padd, batch_labels_no_pad):\n",
        "\n",
        "    top_m = [1, 2, 3, 4]\n",
        "    batch_num_m=[]\n",
        "    batch_score_m=[]\n",
        "    for m in top_m:\n",
        "        intersects_lst = []\n",
        "        # exact_lst = []\n",
        "        score_lst = []\n",
        "        ############################################### computing scores:\n",
        "        for s in batch_scores_no_padd:\n",
        "            if len(s) <=m:\n",
        "                continue\n",
        "            h = m\n",
        "            # if len(s) > h:\n",
        "            #     while (s[np.argsort(s)[-h]] == s[np.argsort(s)[-(h + 1)]] and h < (len(s) - 1)):\n",
        "            #         h += 1\n",
        "\n",
        "            # s = np.asarray(s.cpu())\n",
        "            s = np.asarray(s)\n",
        "            #ind_score = np.argsort(s)[-h:]\n",
        "            ind_score = sorted(range(len(s)), key = lambda sub: s[sub])[-h:]\n",
        "            score_lst.append(ind_score)\n",
        "\n",
        "        ############################################### computing labels:\n",
        "        label_lst = []\n",
        "        for l in batch_labels_no_pad:\n",
        "            if len(l) <=m:\n",
        "                continue\n",
        "            # if it contains several top values with the same amount\n",
        "            h = m\n",
        "            l = l.cpu()\n",
        "            if len(l) > h:\n",
        "                while (l[np.argsort(l)[-h]] == l[np.argsort(l)[-(h + 1)]] and h < (len(l) - 1)):\n",
        "                    h += 1\n",
        "            l = np.asarray(l)\n",
        "            ind_label = np.argsort(l)[-h:]\n",
        "            label_lst.append(ind_label)\n",
        "\n",
        "        ############################################### :\n",
        "\n",
        "        for i in range(len(score_lst)):\n",
        "            intersect = intersection(score_lst[i], label_lst[i])\n",
        "            intersects_lst.append((len(intersect))/(min(m, len(score_lst[i]))))\n",
        "            # sorted_score_lst = sorted(score_lst[i])\n",
        "            # sorted_label_lst =  sorted(label_lst[i])\n",
        "            # if sorted_score_lst==sorted_label_lst:\n",
        "            #     exact_lst.append(1)\n",
        "            # else:\n",
        "            #     exact_lst.append(0)\n",
        "        batch_num_m.append(len(score_lst))\n",
        "        batch_score_m.append(sum(intersects_lst))\n",
        "    return batch_num_m, batch_score_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxedK3EBFmr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a59962e4-ffb8-4915-d172-1158aa896178"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[3].to(device)\n",
        "        b_token_starts = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        output = model(b_input_ids, b_input_mask, b_labels, b_token_starts)\n",
        "        loss = output[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    # print(\"total loss\",total_loss)\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    num_m = [0, 0, 0, 0]\n",
        "    score_m = [0, 0, 0, 0]\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        t_input_ids = batch[0].to(device)\n",
        "        t_input_mask = batch[3].to(device)\n",
        "        t_token_starts = batch[1].to(device)\n",
        "        t_labels = batch[2].to(device)\n",
        "        # b_input_ids, b_input_mask, b_token_starts, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            output = model(t_input_ids, t_input_mask,  t_labels,t_token_starts)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = output[1]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = t_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        # tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        mask = torch.sum(t_labels,dim=1)\n",
        "        # print(t_input_mask.size())\n",
        "        # print(mask.size())\n",
        "        mask = mask.cpu().data.numpy()\n",
        "        t_scores, t_labels_new = fix_padding(logits, t_labels,mask)\n",
        "\n",
        "        batch_num_m, batch_score_m = match_M(t_scores, t_labels_new)\n",
        "        num_m = [sum(i) for i in zip(num_m, batch_num_m)]\n",
        "        score_m = [sum(i) for i in zip(score_m, batch_score_m)]\n",
        "    \n",
        "    m_score = [i/j for i,j in zip(score_m, num_m)]\n",
        "    print(\"Validation Accuracy: \")\n",
        "    print(m_score)\n",
        "    v_score = np.mean(m_score)\n",
        "    print(v_score)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        # eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        # nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    # print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    # print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "tensor(0.6593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6608, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6510, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6560, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6449, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6665, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6513, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6686, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6572, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6523, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6624, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6504, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6649, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6401, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6666, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6667, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6498, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6534, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6462, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    40  of     86.    Elapsed: 0:00:12.\n",
            "tensor(0.6447, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6620, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6452, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6584, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6539, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6587, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6526, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6574, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6534, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6742, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6630, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6526, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6662, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6701, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6528, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6693, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6765, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6595, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6601, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6630, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6536, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6696, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6404, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6482, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    80  of     86.    Elapsed: 0:00:23.\n",
            "tensor(0.6488, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6645, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6655, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epoch took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "tensor(0.6440, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6469, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6527, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6497, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6472, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6444, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6605, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6522, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6658, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6400, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6683, device='cuda:0', dtype=torch.float64)\n",
            "Validation Accuracy: \n",
            "[0.5515151515151515, 0.7222222222222222, 0.7987421383647798, 0.8465909090909091]\n",
            "0.7297676052982657\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "tensor(0.6760, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6456, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6667, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6607, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6625, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6554, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6593, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6573, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6560, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6682, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6437, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6718, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6665, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6737, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6608, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6557, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6644, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6610, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6613, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6814, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6468, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6777, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6463, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6685, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6465, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    40  of     86.    Elapsed: 0:00:12.\n",
            "tensor(0.6669, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6671, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6629, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6665, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6502, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6551, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6657, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6536, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6635, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6512, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6641, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6547, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6563, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6391, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6507, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6546, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6509, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6506, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6663, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6632, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6748, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6710, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6570, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6514, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6605, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6516, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6552, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6634, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6626, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    80  of     86.    Elapsed: 0:00:24.\n",
            "tensor(0.6553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6629, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6532, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6594, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6432, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epoch took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "tensor(0.6440, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6469, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6527, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6497, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6472, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6444, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6605, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6522, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6658, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6400, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6683, device='cuda:0', dtype=torch.float64)\n",
            "Validation Accuracy: \n",
            "[0.5515151515151515, 0.7222222222222222, 0.7987421383647798, 0.8465909090909091]\n",
            "0.7297676052982657\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "tensor(0.6499, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6567, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6503, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6556, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6508, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6491, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6681, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6421, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6581, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6655, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6511, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6497, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6496, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6468, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6533, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6676, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6535, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6517, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6518, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6536, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6536, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6636, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6608, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6627, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6596, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6620, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    40  of     86.    Elapsed: 0:00:12.\n",
            "tensor(0.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6668, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6481, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6702, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6589, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6576, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6561, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6552, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6774, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6433, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6757, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6618, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6543, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6289, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6530, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6585, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6801, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6417, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6682, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6619, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6631, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6620, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6524, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6601, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6592, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6604, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6822, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6683, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6484, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6710, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6720, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6677, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    80  of     86.    Elapsed: 0:00:24.\n",
            "tensor(0.6500, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6448, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6653, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6427, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6746, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6590, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epoch took: 0:00:26\n",
            "\n",
            "Running Validation...\n",
            "tensor(0.6440, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6469, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6527, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6497, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6472, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6444, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6605, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6522, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6658, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6400, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6683, device='cuda:0', dtype=torch.float64)\n",
            "Validation Accuracy: \n",
            "[0.5515151515151515, 0.7222222222222222, 0.7987421383647798, 0.8465909090909091]\n",
            "0.7297676052982657\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "tensor(0.6510, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6559, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6538, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6614, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6569, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6795, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6505, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6527, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6656, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6617, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6444, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6773, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6586, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6661, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6637, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6540, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6622, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6396, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6582, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6413, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6476, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6640, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6564, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6628, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6529, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6566, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6545, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6788, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6638, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6494, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6548, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6447, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6511, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    40  of     86.    Elapsed: 0:00:12.\n",
            "tensor(0.6474, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6487, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6426, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6411, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6580, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6767, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6639, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6662, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6542, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6680, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6588, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6774, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6654, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6721, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6687, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6678, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6487, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6715, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6504, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6606, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6615, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6602, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6725, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6706, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6609, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6583, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6600, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6699, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6537, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6419, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6446, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6521, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6707, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6531, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6562, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6520, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6524, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "  Batch    80  of     86.    Elapsed: 0:00:24.\n",
            "tensor(0.6712, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6664, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6726, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6553, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6480, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "tensor(0.6735, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epoch took: 0:00:25\n",
            "\n",
            "Running Validation...\n",
            "tensor(0.6440, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6469, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6527, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6497, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6472, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6591, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6444, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6605, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6522, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6658, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6475, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6400, device='cuda:0', dtype=torch.float64)\n",
            "tensor(0.6683, device='cuda:0', dtype=torch.float64)\n",
            "Validation Accuracy: \n",
            "[0.5515151515151515, 0.7222222222222222, 0.7987421383647798, 0.8465909090909091]\n",
            "0.7297676052982657\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMVdzCxGBRBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}